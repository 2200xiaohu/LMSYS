{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c51126aa-e724-49ec-b4c7-b71a5c1165d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "from typing import Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    PeftModel,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import random\n",
    "def seed_everything(seed=None):\n",
    "    '''\n",
    "    固定seed\n",
    "    :param seed: int, 随机种子\n",
    "    '''\n",
    "    max_seed_value = np.iinfo(np.uint32).max\n",
    "    min_seed_value = np.iinfo(np.uint32).min\n",
    "\n",
    "    if (seed is None) or not (min_seed_value <= seed <= max_seed_value):\n",
    "        seed = random.randint(np.iinfo(np.uint32).min, np.iinfo(np.uint32).max)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return seed\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1015804f-1c5b-40e5-942e-af225971ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95028/95028 [00:50<00:00, 1882.63it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"dataset/non_overlap/train_33k.json\"\n",
    "prompt_type = 3\n",
    "MAX_INPUT = 1900\n",
    "if_train = True\n",
    "split = False\n",
    "if_drop_duplicate = False\n",
    "keep = 'last'\n",
    "df_train , df_valid = load_split_data(data_path, prompt_type, MAX_INPUT, if_train, split, False, if_drop_duplicate, keep)\n",
    "test = df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac05030-270e-42f3-885d-e78b798a63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train.length >= 1900 * 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52352da9-51c6-40c4-82f5-a14e1e238dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe09a5-a9f7-4af4-a663-4c0e05cc004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data = pd.read_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac84eadd-93be-4e2b-94b2-255834cdd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['length'] = test['prompt_response'].apply(lambda x: len(x.split(\" \")))\n",
    "# test = test.sort_values(by = ['length'], ascending = False).reset_index(drop = True)\n",
    "# data = test[:5]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedd0e8-10ad-449a-b544-5dbf0237981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.length >= 1900 * 0.75].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60ede5ae-82fd-4b67-a723-01a6bf859bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "      <th>overflow_prompt</th>\n",
       "      <th>over_max_length</th>\n",
       "      <th>overflow_response_a</th>\n",
       "      <th>overflow_response_b</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3254113</td>\n",
       "      <td>#Prompt\\nCan you help create Dan's thoughts as...</td>\n",
       "      <td>C</td>\n",
       "      <td>Can you help create Dan's thoughts as Liz cane...</td>\n",
       "      <td>1</td>\n",
       "      <td>As Liz leads Dan to the room where he will rec...</td>\n",
       "      <td>As Liz begins to describe the details of the p...</td>\n",
       "      <td>2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16748032</td>\n",
       "      <td>#Prompt\\nwrite a clickable and graphic tic tac...</td>\n",
       "      <td>B</td>\n",
       "      <td>write a clickable and graphic tic tac toe prog...</td>\n",
       "      <td>1</td>\n",
       "      <td>import  graphics  from  pygame  import  image,...</td>\n",
       "      <td>Creating a full graphical and clickable Tic Ta...</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35088788</td>\n",
       "      <td>#Prompt\\nplease write a nice casual and friend...</td>\n",
       "      <td>C</td>\n",
       "      <td>please write a nice casual and friendly reply ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear [username],\\n\\nThank you for sharing your...</td>\n",
       "      <td>Hey there!\\n\\nI couldn't help but resonate wit...</td>\n",
       "      <td>1767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37697874</td>\n",
       "      <td>#Prompt\\nRole: You are an Enterprise AI system...</td>\n",
       "      <td>C</td>\n",
       "      <td>Role: You are an Enterprise AI system designed...</td>\n",
       "      <td>1</td>\n",
       "      <td>AI: {\\n\"reply\": \"I'm just an AI, I don't have ...</td>\n",
       "      <td>Role: You are an Enterprise AI system designed...</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43053669</td>\n",
       "      <td>#Prompt\\nSummarize this article:\\n\\nAmabel Hol...</td>\n",
       "      <td>A</td>\n",
       "      <td>Summarize this article:\\n\\nAmabel Holland, a f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amabel Holland, an autistic board-game designe...</td>\n",
       "      <td>The article highlights the rise in popularity ...</td>\n",
       "      <td>2356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>8af51cda208b4b62986f62beadccfed8</td>\n",
       "      <td>#Prompt\\nHey! Write a tic-tac toy game on pyth...</td>\n",
       "      <td>B</td>\n",
       "      <td>Hey! Write a tic-tac toy game on python please.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sure, here's an example of a tic-tac-toe game ...</td>\n",
       "      <td>Sure! Here's a simple implementation of a Tic ...</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0724e6e2022c4ca18bbb97937bd8ee47</td>\n",
       "      <td>#Prompt\\nrefactor this code : \\npublic class T...</td>\n",
       "      <td>A</td>\n",
       "      <td>refactor this code : \\npublic class TennisGame...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sure, here's a refactored version of the code:...</td>\n",
       "      <td>Sure, here is an updated version of the`Tennis...</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>d8ae2cc49fe4465aaee9706e6220bc38</td>\n",
       "      <td>#Prompt\\nimport { Link } from 'preact-router/m...</td>\n",
       "      <td>C</td>\n",
       "      <td>import { Link } from 'preact-router/match';\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>To make the links work in your full response f...</td>\n",
       "      <td>You're looking to make the rest of the links i...</td>\n",
       "      <td>1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>75f89aaf9cec44509ba54780712d025e</td>\n",
       "      <td>#Prompt\\n{\\n    \"ai_tutor\": {\\n        \"Author...</td>\n",
       "      <td>C</td>\n",
       "      <td>{\\n    \"ai_tutor\": {\\n        \"Author\": \"JushB...</td>\n",
       "      <td>1</td>\n",
       "      <td>Your chatbot, Mr. Ranedeer, can assist you wit...</td>\n",
       "      <td>The AI tutor's author has put a lot of thought...</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>51c1e32e54c94a0daf70794b26aefe3c</td>\n",
       "      <td>#Prompt\\nI want you to act as a stackoverflow ...</td>\n",
       "      <td>B</td>\n",
       "      <td>I want you to act as a stackoverflow post. I w...</td>\n",
       "      <td>1</td>\n",
       "      <td>To create a new column for fiscal months, you ...</td>\n",
       "      <td>Here is the updated code for the new fiscal mo...</td>\n",
       "      <td>1432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  \\\n",
       "0                             3254113   \n",
       "1                            16748032   \n",
       "2                            35088788   \n",
       "3                            37697874   \n",
       "4                            43053669   \n",
       "..                                ...   \n",
       "829  8af51cda208b4b62986f62beadccfed8   \n",
       "830  0724e6e2022c4ca18bbb97937bd8ee47   \n",
       "831  d8ae2cc49fe4465aaee9706e6220bc38   \n",
       "832  75f89aaf9cec44509ba54780712d025e   \n",
       "833  51c1e32e54c94a0daf70794b26aefe3c   \n",
       "\n",
       "                                       prompt_response label  \\\n",
       "0    #Prompt\\nCan you help create Dan's thoughts as...     C   \n",
       "1    #Prompt\\nwrite a clickable and graphic tic tac...     B   \n",
       "2    #Prompt\\nplease write a nice casual and friend...     C   \n",
       "3    #Prompt\\nRole: You are an Enterprise AI system...     C   \n",
       "4    #Prompt\\nSummarize this article:\\n\\nAmabel Hol...     A   \n",
       "..                                                 ...   ...   \n",
       "829  #Prompt\\nHey! Write a tic-tac toy game on pyth...     B   \n",
       "830  #Prompt\\nrefactor this code : \\npublic class T...     A   \n",
       "831  #Prompt\\nimport { Link } from 'preact-router/m...     C   \n",
       "832  #Prompt\\n{\\n    \"ai_tutor\": {\\n        \"Author...     C   \n",
       "833  #Prompt\\nI want you to act as a stackoverflow ...     B   \n",
       "\n",
       "                                       overflow_prompt  over_max_length  \\\n",
       "0    Can you help create Dan's thoughts as Liz cane...                1   \n",
       "1    write a clickable and graphic tic tac toe prog...                1   \n",
       "2    please write a nice casual and friendly reply ...                1   \n",
       "3    Role: You are an Enterprise AI system designed...                1   \n",
       "4    Summarize this article:\\n\\nAmabel Holland, a f...                1   \n",
       "..                                                 ...              ...   \n",
       "829    Hey! Write a tic-tac toy game on python please.                1   \n",
       "830  refactor this code : \\npublic class TennisGame...                1   \n",
       "831  import { Link } from 'preact-router/match';\\n\\...                1   \n",
       "832  {\\n    \"ai_tutor\": {\\n        \"Author\": \"JushB...                1   \n",
       "833  I want you to act as a stackoverflow post. I w...                1   \n",
       "\n",
       "                                   overflow_response_a  \\\n",
       "0    As Liz leads Dan to the room where he will rec...   \n",
       "1    import  graphics  from  pygame  import  image,...   \n",
       "2    Dear [username],\\n\\nThank you for sharing your...   \n",
       "3    AI: {\\n\"reply\": \"I'm just an AI, I don't have ...   \n",
       "4    Amabel Holland, an autistic board-game designe...   \n",
       "..                                                 ...   \n",
       "829  Sure, here's an example of a tic-tac-toe game ...   \n",
       "830  Sure, here's a refactored version of the code:...   \n",
       "831  To make the links work in your full response f...   \n",
       "832  Your chatbot, Mr. Ranedeer, can assist you wit...   \n",
       "833  To create a new column for fiscal months, you ...   \n",
       "\n",
       "                                   overflow_response_b  length  \n",
       "0    As Liz begins to describe the details of the p...    2302  \n",
       "1    Creating a full graphical and clickable Tic Ta...    1634  \n",
       "2    Hey there!\\n\\nI couldn't help but resonate wit...    1767  \n",
       "3    Role: You are an Enterprise AI system designed...    1987  \n",
       "4    The article highlights the rise in popularity ...    2356  \n",
       "..                                                 ...     ...  \n",
       "829  Sure! Here's a simple implementation of a Tic ...    1659  \n",
       "830  Sure, here is an updated version of the`Tennis...    1845  \n",
       "831  You're looking to make the rest of the links i...    1508  \n",
       "832  The AI tutor's author has put a lot of thought...    1789  \n",
       "833  Here is the updated code for the new fiscal mo...    1432  \n",
       "\n",
       "[834 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over = test.loc[test.over_max_length == 1].reset_index(drop = True)\n",
    "over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae0086c-2867-48a6-92c9-b863a0d6df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "over['over_prompt_response'] = \"#Prompt\\n\" + over['overflow_prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + over['overflow_response_a'] + \"\\n\\n\" + \"##Model B\\n\" + over['overflow_response_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6af194-316a-47cc-8492-c3350a569180",
   "metadata": {},
   "outputs": [],
   "source": [
    "over.loc[over['over_prompt_response'] == over['prompt_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82250137-7c0b-41c4-8077-14bbeb2a22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = o_data.loc[o_data.id.isin(over.id)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eab059-06a9-4c37-925f-98dca219891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(over.loc[3,'overflow_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7534d05-e517-47eb-a976-20037cded2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(over.loc[4,'prompt_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509e479-cb5e-4569-ab1b-98c994bd2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.loc[test.over_max_length == 0,'prompt_response'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5bf9a-3828-4a2c-94bf-95f94d9ea411",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.over_max_length == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89307689-0dfb-45cc-9c36-b3ed5e3cce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = test.loc[test.id == 16748032]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9b144-888f-44ae-8c39-062554aba417",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check.prompt_response.values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb771d9c-224b-4e3b-a6ca-1985b24af5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.loc[o_data.id==16748032].prompt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec561a-2aaa-4226-97a6-d366532f4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.loc[o_data.id==16748032].prompt.values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b31ee-4b84-4785-822b-86b0cd89ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.loc[o_data.id==16748032].response_a.values[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f1674-f1e6-4428-ad40-158678eccc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.loc[o_data.id==16748032].response_b.values[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def908c2-0ad2-4c52-b01b-d8371c6a1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.loc[o_data.id=='26dc950ef0'].prompt.values[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316455c-2275-4057-8e07-9c27f766adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.loc[test.id == '39036b3a02'].prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43afc589-a55e-4ecb-890b-01120fcf9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.loc[o_data.id == '39036b3a02'].prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0bfc8b-9bd2-4e93-bf6c-12de80a132c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26298e21-a484-4ca0-8125-11cea74f6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.prompt_response.values[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f29566-bf5c-4c5a-89db-d64c6df84d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[17,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a18774-a19b-4f12-ac85-7392d5c54e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.loc[o_data.id == '240a03e332'].prompt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767fcf8a-b3ec-4f5c-96f4-912688432584",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "base_model = 'google/gemma-2-9b-it'\n",
    "model_path = \"output/morning-waterfall-460/checkpoint-5200_888\"\n",
    "MAX_LENGTH = 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22c656-f64d-408a-9422-509bab9f5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, truncation_side = 'left')\n",
    "config = AutoConfig.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c70d5-d11c-4696-9357-46b8a29316f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = check.prompt_response.values[0]\n",
    "len(tokenizer(t)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "174b6136-018a-40d9-847a-522f9672bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_values(A, B, a_space, b_space, ex_space):\n",
    "    # 计算A和a_space的差值\n",
    "    a_diff = a_space - A\n",
    "    b_diff = b_space - B\n",
    "    \n",
    "    # 第一种情况：A小于a_space，B小于b_space\n",
    "    if A < a_space and B < b_space:\n",
    "        ex_space += a_diff + b_diff\n",
    "        return A, B, ex_space\n",
    "\n",
    "    # 第二种情况：如果A和B都各自大于自己的space\n",
    "    elif A > a_space and B > b_space:\n",
    "        total_extra_needed = (A - a_space) + (B - b_space)\n",
    "        if total_extra_needed > ex_space:\n",
    "            A = int(a_space + ex_space / 2)\n",
    "            B = int(b_space + ex_space / 2)\n",
    "            ex_space = 0\n",
    "        else:\n",
    "            a_space = A\n",
    "            b_space = B\n",
    "            ex_space -= total_extra_needed\n",
    "            \n",
    "        return A, B, ex_space\n",
    "        \n",
    "    # 第三种情况：A或者B其中有一个大于a_space, b_space\n",
    "    elif A > a_space or B > b_space:\n",
    "        # 如果A大于a_space但是B小于b_space\n",
    "        if A > a_space and B < b_space:\n",
    "            extra_needed = A - a_space\n",
    "            ex_space += b_space - B\n",
    "            #够用\n",
    "            if ex_space >= extra_needed:\n",
    "                ex_space -= extra_needed\n",
    "                \n",
    "            else:\n",
    "                #不够用\n",
    "                #b_space = B + available_space\n",
    "                A = a_space + ex_space\n",
    "                ex_space = 0\n",
    "\n",
    "        # 如果B大于b_space但是A小于a_space\n",
    "        elif B > b_space and A < a_space:\n",
    "            extra_needed = B - b_space\n",
    "            ex_space += a_space - A\n",
    "            \n",
    "            if ex_space >= extra_needed:\n",
    "                ex_space -= extra_needed\n",
    "                \n",
    "            else:\n",
    "                B = b_space + ex_space\n",
    "                ex_space = 0\n",
    "\n",
    "        return A, B, ex_space\n",
    "    \n",
    "\n",
    "def adjust(current_lengths, prompt_length_space=300, response_length_space=800):\n",
    "    prompt_length = current_lengths[0]\n",
    "    response_a_length = current_lengths[1]\n",
    "    response_b_length = current_lengths[2]\n",
    "    #先看prompt的额度\n",
    "    ex_space = max(0, prompt_length_space - prompt_length)\n",
    "    response_a_length, response_b_length, ex_space = adjust_values(response_a_length, response_b_length, response_length_space, response_length_space, ex_space)\n",
    "    prompt_length = min(prompt_length, prompt_length_space)\n",
    "    prompt_length += ex_space\n",
    "\n",
    "    return prompt_length, response_a_length, response_b_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5f1c7ec6-b707-4032-ae14-648a203c8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class InstructionDataSet(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_source_length, max_target_length):\n",
    "        super(InstructionDataSet, self).__init__()\n",
    "        #self.data = data.sample(len(data), random_state=0).reset_index(drop=True)\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "        # self.A_token = self.tokenizer.encode(text='A', add_special_tokens=False, truncation=True, )\n",
    "        # self.B_token = self.tokenizer.encode(text='B', add_special_tokens=False, truncation=True, )\n",
    "        # self.C_token = self.tokenizer.encode(text='C', add_special_tokens=False, truncation=True, )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        now_data = self.data.loc[index]\n",
    "        over_max_length = now_data['over_max_length']\n",
    "        \n",
    "        templete_part1 = \"<start_of_turn>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\\n\"\n",
    "        templete_part1_input_ids = self.tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "        \n",
    "        templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<end_of_turn>\\n\"\n",
    "        templete_part2_input_ids = self.tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "        #print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "        templete_part3 = \"<start_of_turn>model\\n\"\n",
    "        templete_part3_input_ids = self.tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "        \n",
    "        templete_part4_input_ids = self.tokenizer(text=\"\\n\\n\", add_special_tokens=False, padding=False)['input_ids']\n",
    "        \n",
    "        if over_max_length:\n",
    "            prompt = \"#Prompt\\n\" + now_data['overflow_prompt']\n",
    "            r_a = \"#Response\\n\" + \"##Model A\\n\" + now_data['overflow_response_a']\n",
    "            r_b = \"##Model B\\n\" + now_data['overflow_response_b']\n",
    "            \n",
    "            prompt_ids = self.tokenizer(text=prompt, add_special_tokens=False, truncation=False, padding=False)['input_ids']\n",
    "            model_a_input_ids = self.tokenizer(text=r_a, add_special_tokens=False, truncation=False, padding=False)['input_ids']\n",
    "            model_b_input_ids = self.tokenizer(text=r_b, add_special_tokens=False, truncation=False, padding=False)['input_ids']\n",
    "\n",
    "            if len(prompt_ids) + len(model_a_input_ids) + len(model_b_input_ids) <= self.max_source_length:\n",
    "                prompt_response_ids = prompt_ids + model_a_input_ids + model_b_input_ids\n",
    "            \n",
    "            else:\n",
    "                '''\n",
    "                prompt 和 response 按照 300， 800， 800\n",
    "                response 优先\n",
    "                多的再给prompt\n",
    "                '''\n",
    "                length = [len(prompt_ids), len(model_a_input_ids), len(model_b_input_ids)]\n",
    "                print(f\"before {length}\")\n",
    "                prompt_max_length, a_max_length, b_max_length = adjust(length)\n",
    "                prompt_ids = prompt_ids[:prompt_max_length] + templete_part4_input_ids\n",
    "                model_a_input_ids = model_a_input_ids[:a_max_length] + templete_part4_input_ids\n",
    "                model_b_input_ids = model_a_input_ids[:b_max_length] + templete_part4_input_ids\n",
    "                print(f\"after {[prompt_max_length, a_max_length, b_max_length]}\")\n",
    "                prompt_response_ids = prompt_ids + model_a_input_ids + model_b_input_ids\n",
    "        \n",
    "        else:\n",
    "            prompt_response = now_data['prompt_response']\n",
    "            #print(f\"id is {now_data['id']}\")\n",
    "            #print(prompt_response)\n",
    "            prompt_response_ids = self.tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                              max_length=self.max_source_length, padding=False)['input_ids'][1:]\n",
    "            #print(prompt_response_ids)        \n",
    "            \n",
    "            \n",
    "        label = now_data['label']\n",
    "        label_ids = self.tokenizer.encode(text=label, add_special_tokens=False)\n",
    "        input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [self.tokenizer.eos_token_id]\n",
    "        labels = [-100] * (len(input_ids) - 2) + label_ids + [self.tokenizer.eos_token_id]\n",
    "        #print(f\"input is {self.tokenizer.decode(input_ids)}\")\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e133b4eb-88cd-4131-abaf-724cc3e8750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 600, 600)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = [500,600,600]\n",
    "adjust(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b7e43704-1019-48ac-bdcb-92ac0708c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = InstructionDataSet(over,tokenizer, 1900, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c7569c0-c4c2-4e2c-bdd9-90cc97dfa0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "      <th>overflow_prompt</th>\n",
       "      <th>over_max_length</th>\n",
       "      <th>overflow_response_a</th>\n",
       "      <th>overflow_response_b</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>#Prompt\\nIs it morally right to try to have a ...</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>#Prompt\\nWhat is the difference between marria...</td>\n",
       "      <td>B</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>#Prompt\\nexplain function calling. how would y...</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>#Prompt\\nHow can I create a test set for a ver...</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370945</td>\n",
       "      <td>#Prompt\\n\"Bacteria is life on Mars but a heart...</td>\n",
       "      <td>B</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79697</th>\n",
       "      <td>8777c4945d85469d96cd26fc2ea6f64a</td>\n",
       "      <td>#Prompt\\nwho is the president of the U.S.A?\\n\\...</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79698</th>\n",
       "      <td>86063a921be548989c55b85497ab009a</td>\n",
       "      <td>#Prompt\\nhow to train lora for stable diffusio...</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79699</th>\n",
       "      <td>6685a3b3863f4554887e432f7dbbe8a5</td>\n",
       "      <td>#Prompt\\n남녀 섹스 체위 자세 10가지를 적어줘\\n\\n#Response\\n#...</td>\n",
       "      <td>B</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79700</th>\n",
       "      <td>f72930b382e949ea879e7abf3cb1e587</td>\n",
       "      <td>#Prompt\\nhow to evaluate a language model outp...</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79701</th>\n",
       "      <td>a147958b2bd049229facdbffa72a4662</td>\n",
       "      <td>#Prompt\\ngenerate a detailed description on ho...</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79702 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0                                 30192   \n",
       "1                                 53567   \n",
       "2                                 65089   \n",
       "3                                 96401   \n",
       "4                                370945   \n",
       "...                                 ...   \n",
       "79697  8777c4945d85469d96cd26fc2ea6f64a   \n",
       "79698  86063a921be548989c55b85497ab009a   \n",
       "79699  6685a3b3863f4554887e432f7dbbe8a5   \n",
       "79700  f72930b382e949ea879e7abf3cb1e587   \n",
       "79701  a147958b2bd049229facdbffa72a4662   \n",
       "\n",
       "                                         prompt_response label  \\\n",
       "0      #Prompt\\nIs it morally right to try to have a ...     A   \n",
       "1      #Prompt\\nWhat is the difference between marria...     B   \n",
       "2      #Prompt\\nexplain function calling. how would y...     C   \n",
       "3      #Prompt\\nHow can I create a test set for a ver...     A   \n",
       "4      #Prompt\\n\"Bacteria is life on Mars but a heart...     B   \n",
       "...                                                  ...   ...   \n",
       "79697  #Prompt\\nwho is the president of the U.S.A?\\n\\...     C   \n",
       "79698  #Prompt\\nhow to train lora for stable diffusio...     A   \n",
       "79699  #Prompt\\n남녀 섹스 체위 자세 10가지를 적어줘\\n\\n#Response\\n#...     B   \n",
       "79700  #Prompt\\nhow to evaluate a language model outp...     A   \n",
       "79701  #Prompt\\ngenerate a detailed description on ho...     C   \n",
       "\n",
       "      overflow_prompt  over_max_length overflow_response_a  \\\n",
       "0                None                0                None   \n",
       "1                None                0                None   \n",
       "2                None                0                None   \n",
       "3                None                0                None   \n",
       "4                None                0                None   \n",
       "...               ...              ...                 ...   \n",
       "79697            None                0                None   \n",
       "79698            None                0                None   \n",
       "79699            None                0                None   \n",
       "79700            None                0                None   \n",
       "79701            None                0                None   \n",
       "\n",
       "      overflow_response_b  length  \n",
       "0                    None     890  \n",
       "1                    None    1167  \n",
       "2                    None     432  \n",
       "3                    None     819  \n",
       "4                    None     144  \n",
       "...                   ...     ...  \n",
       "79697                None      39  \n",
       "79698                None     698  \n",
       "79699                None      79  \n",
       "79700                None     545  \n",
       "79701                None     558  \n",
       "\n",
       "[79702 rows x 8 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "817eab04-fa4e-474e-a8dd-9e9805eb473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before [2204, 373, 282]\n",
      "after [1245, 373, 282]\n",
      "1955\n",
      "before [2204, 373, 282]\n",
      "after [1245, 373, 282]\n",
      "<bos><start_of_turn>user\n",
      "Here are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\n",
      "\n",
      "#Prompt\n",
      "Can you help create Dan's thoughts as Liz canes him? \n",
      "Although she has warned him that her role as Justice of the Peace required her to deliver the cane strokes iof his sentence with severity (and that someone at the Ministry would review the video of her administration of the caning to ensure she did, so she could not go easy on him),  Dan is surprised at the harshness with which Liz delivers his caning. She  is compelled by her professional duties to adhere strictly to the protocol, ensuring that the punishment is carried out to the letter to avoid reprimand or disciplinary action from her own supervisors, Dan somehow did not expect it to be as harsh as it was.   The fact that the punishment is being recorded and will be reviewed adds to the pressure Liz feels to perform her duties flawlessly, further distancing her from any personal feelings she might have.\n",
      "\n",
      "Here is the story to provide context:\n",
      "\n",
      "\n",
      "\"Good morning, Dan! I was wondering if I would run into you this morning. Can you walk with me?”\n",
      "\n",
      "It was Liz, a parent of one of the other boys in my son's class. We often spoke at afternoon pickup as we waited for school to let out.  Seeing her at morning drop off was unusual.  Also a single parent, I was attracted by her friendly demeanor, easygoing nature, and captivating smile.   I'd been thinking about asking her out, but hadn't mustered the courage yet.   I had, however, been subtly trying to encourage my boy to become friends with her son, hoping this could lead us to move beyond brief conversations about the weather and our kids' reading levels.\n",
      "\n",
      "\"Sorry, I, er... have an appointment.\"\n",
      "\n",
      "\"Yes, Dan, I know.  4317 Butterfield Drive.\"\n",
      "\n",
      "I could only stare at her, my mind spinning. How did she know? As if reading my thoughts, she explained, \"I suppose you may not know, but I am a Justice of the Peace for our District. You are my  9:30 appointment.\"\n",
      "\n",
      "E. Watson was the  JP  named on my Judicial Notice.  I hadn't made the connection because I didn't know her last name or what type of work she did.   To me, she was just Liz, the mother of one of Ben's classmates. \n",
      "\n",
      " \"Oh, of course,\" I replied, my voice unconvincing as I tried to hide my shock.\n",
      "\n",
      "Disbelief and panic washed over me. Liz, the woman I had been subtly trying to impress for weeks, was the Justice of the Peace assigned to administer my sentence.\n",
      "\n",
      "She reached out, touching my arm gently.  \"I'm really sorry about this.  I know it's a bit scary, but you'll get through it.” I couldn't decide if she was genuinely trying to be reassuring or if the words were a standard part of her professional protocol.  \"Would you like to just come with me now? We can have a cup of tea first and I can walk you through what to expect.\"\n",
      "\n",
      "\"Sure,\" I said trying to act like nothing was amiss. \"Yes, thanks.\"\n",
      "\n",
      "After a student going to school was struck by a car in nearby Leeds, a new law was enacted targeting individuals who sped in school zones. Exceeding the speed limit by 6 kph or more incurred a £350 fine and a six-month driving suspension.   I unintentionally violated this law when a vigilant speed camera caught me driving too fast by my son's school and I was summoned to court.  Understanding my situation as a single parent who relied on driving for my job, the judge offered an unconventional alternative sentence: pay the fine and endure a one-time caning administered by a local Justice of the Peace .  The choice was entirely mine.   I readily accepted the alternative, opting for temporary discomfort rather than a lengthy license suspension.  \n",
      "\n",
      "\n",
      "\n",
      "Not long after my court appearance, I located a YouTube of the BBC corporal punishment segment online. Watching it, particularly the participants describing their experiences, filled me with genuine concern about my ability to bear the '12 hard cane strokes' part of my sentence. This had been a significant source of distress for me for the past few days. Now, learning that Liz would be the Justice of the Peace administering the humiliating beating, my anxiety rose to a new level.  How could I ever face her after this?  \n",
      "\n",
      "Interestingly, a majority of the Justices of the Peace certified for corporal punishment administration were women. Many were attracted to the role due to the extra pay and flexible schedule it offered, allowing them to balance other responsibilities such as home duties.  Not all were lucky enough to have a set-up that allowed them to work out of their homes.\n",
      "\n",
      "\n",
      "This was our reality, a strange mix of personal familiarity and professional duty. The conversation had eased the tension somewhat, but the looming event was still there, unavoidable and imminent. \n",
      "\n",
      "\"And it doesn't trouble you?  Caning people, I mean,\" I asked, my question adding a sudden tension to the conversation. \n",
      "\n",
      "She faced me calmly, the morning light casting a gentle glow on her features. \n",
      "\"I won't say it's easy,\" Liz confessed, her voice hinting at her struggle with the responsibility. \"But I constantly remind myself that we're doing this to enforce the law and ultimately to safeguard the public.\"  \n",
      "\n",
      "Liz found contentment in her decision to take on this role.  As a strong advocate of the law, she believed corporal punishment had the potential to effect positive change in her community, while also providing her the flexibility she needed as a single mom.\n",
      " \n",
      "\"Do you really believe that it works?\" I asked, genuinely interested in her beliefs. Liz considered her response carefully before voicing her thoughts. I do.  If I doubted its effectiveness, I couldn't support it ,\" she asserted. After a moment's pause her voice sounded somewhat irritated, perhaps because I had put her on the defensive.  \n",
      "\n",
      "#Response\n",
      "##Model A\n",
      "As Liz leads Dan to the room where he will receive his caning, he can't help but think about how different this situation is from their usual interactions. He's used to seeing her at school pickups, exchanging pleasantries and talking about their children's progress. Now, she's about to administer a harsh punishment to him, a role she takes very seriously as a Justice of the Peace.\n",
      "\n",
      "As they enter the room, Dan can't help but feel a wave of anxiety. He knows that the caning will be recorded and reviewed by her superiors, which makes him even more nervous. He's also concerned about how this will affect their relationship going forward. \n",
      "\n",
      "As Liz begins to explain the procedure, her voice is calm and professional, but Dan can sense a hint of empathy underlying her words. He knows that she's not enjoying this situation any more than he is, but she's obligated to carry out her duties as required by law.\n",
      "\n",
      "When she demonstrates the force of the cane on a throw pillow, Dan is taken aback. He hadn't expected it to be so loud and powerful, and he realizes that the punishment will be far more severe than he had anticipated.\n",
      "\n",
      "Liz's warning about not being able to remain still for twelve strokes and the potential for her to hit the wrong place, causing even more harm, only adds to Dan's anxiety. He is now fully aware of the gravity of his situation and the harsh reality of his punishment. \n",
      "\n",
      "Despite his fear and apprehension, Dan understands that Liz is only doing her job, and he tries to put his trust in her professionalism. He knows that she's trying to make this ordeal as bearable as possible for him, even though the situation is far from ideal for both of them.\n",
      "\n",
      "#Response\n",
      "##Model A\n",
      "As Liz leads Dan to the room where he will receive his caning, he can't help but think about how different this situation is from their usual interactions. He's used to seeing her at school pickups, exchanging pleasantries and talking about their children's progress. Now, she's about to administer a harsh punishment to him, a role she takes very seriously as a Justice of the Peace.\n",
      "\n",
      "As they enter the room, Dan can't help but feel a wave of anxiety. He knows that the caning will be recorded and reviewed by her superiors, which makes him even more nervous. He's also concerned about how this will affect their relationship going forward. \n",
      "\n",
      "As Liz begins to explain the procedure, her voice is calm and professional, but Dan can sense a hint of empathy underlying her words. He knows that she's not enjoying this situation any more than he is, but she's obligated to carry out her duties as required by law.\n",
      "\n",
      "When she demonstrates the force of the cane on a throw pillow, Dan is taken aback. He hadn't expected it to be so loud and powerful, and he realizes that the punishment will be far more severe than he had anticipated.\n",
      "\n",
      "Liz's warning about not being able to remain still for twelve strokes and the potential for her to hit the wrong place, causing even\n",
      "\n",
      "\n",
      "###options\n",
      "A. Model A\n",
      "B. Model B\n",
      "C. Tie\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "C<eos>\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_dataset[0]['input_ids']))\n",
    "print(tokenizer.decode(tokenized_dataset[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce27de-52d3-4f0e-9c9f-29e5f8976954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
