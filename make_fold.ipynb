{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d755d689-f9cd-4a66-b050-a37479a22807",
   "metadata": {},
   "source": [
    "# 完全不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7966d018-416b-4c58-b180-2a6ad61eaa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from random import random, randint\n",
    "from utils import load_json, load_split_data\n",
    "\n",
    "import random\n",
    "def seed_everything(seed=None):\n",
    "    '''\n",
    "    固定seed\n",
    "    :param seed: int, 随机种子\n",
    "    '''\n",
    "    max_seed_value = np.iinfo(np.uint32).max\n",
    "    min_seed_value = np.iinfo(np.uint32).min\n",
    "\n",
    "    if (seed is None) or not (min_seed_value <= seed <= max_seed_value):\n",
    "        seed = random.randint(np.iinfo(np.uint32).min, np.iinfo(np.uint32).max)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178cf20f-1c23-4ca7-a84c-72d677d2bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)\n",
    "\n",
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2492c6-c2f4-494c-be7a-932f05e2b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、找出train里面不与33k重复部分\n",
    "2、不重复的部分再划分\n",
    "'''\n",
    "set_prompt_response = []\n",
    "for i in data.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "data['set_prompt_response'] = set_prompt_response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b79b16-12a0-4564-9ce7-7c98ce8519fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in ex_33.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "ex_33['set_prompt_response'] = set_prompt_response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa41421e-0605-4f96-849f-142412de300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(data.set_prompt_response.values) if i in ex_33.set_prompt_response.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54031d68-246f-452f-9018-2f14fead3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = data.loc[idx,:].reset_index(drop = True)\n",
    "not_same = data.loc[~data.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47446ad7-608f-4f15-b04c-7ca1ff7b532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11689868-4a0a-40a0-8b97-39d0ab41e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sets = not_same['set_prompt_response'].drop_duplicates().reset_index(drop=True)\n",
    "# 将唯一集合进行随机划分\n",
    "unique_sets = unique_sets.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "midpoint = len(unique_sets) // 10\n",
    "set1 = unique_sets.iloc[:midpoint]\n",
    "set2 = unique_sets.iloc[midpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1a74ee-6a83-48af-8961-108d4d420fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分结果从原数据集中提取对应的行\n",
    "valid = not_same[not_same['set_prompt_response'].isin(set1)].reset_index(drop=True)\n",
    "train_subset = not_same[not_same['set_prompt_response'].isin(set2)].reset_index(drop=True)\n",
    "assert len(valid) + len(train_subset) == len(not_same)\n",
    "assert len(valid) + len(train_subset) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e80a94-bf19-408e-8ad4-53fbb67a9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exclude_valid = pd.concat([train_subset, same]).reset_index(drop=True) #train 里面排除valid\n",
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values])\n",
    "assert len(valid) + len(train_exclude_valid) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51660b83-b835-4028-a476-939d9301d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.concat([train_subset, ex_33]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79c5d50c-ba64-4ddd-9c60-59dfdea9c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train_subset.drop(columns = ['set_prompt_response'])\n",
    "valid = valid.drop(columns = ['set_prompt_response'])\n",
    "train_exclude_valid = train_exclude_valid.drop(columns = ['set_prompt_response'])\n",
    "train_33k = train_33k.drop(columns = ['set_prompt_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0280b76-5188-4c03-a4a1-ba4317040a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_json(\"dataset/non_overlap/train_subset.json\", index = False)\n",
    "valid.to_json(\"dataset/non_overlap/valid.json\", index = False)\n",
    "train_exclude_valid.to_json(\"dataset/non_overlap/train_exclude_valid.json\", index = False)\n",
    "train_33k.to_json(\"dataset/non_overlap/train_33k.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f239689-3b6d-4316-b3d7-a8302c53ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查\n",
    "train_subset = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "valid = pd.read_json(\"dataset/non_overlap/valid.json\")\n",
    "train_exclude_valid = pd.read_json(\"dataset/non_overlap/train_exclude_valid.json\")\n",
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96dbbe12-3e36-4022-8d9c-a3378e0b298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f7255ac-620d-4a8f-ab58-451b613fe0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = get_set_prompt_response(train_subset)\n",
    "valid = get_set_prompt_response(valid)\n",
    "train_exclude_valid = get_set_prompt_response(train_exclude_valid)\n",
    "train_33k = get_set_prompt_response(train_33k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c80f26a-a248-467b-b28a-115378660e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid和任何都不重合\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_33k.set_prompt_response.values]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "980bbae8-dc18-42e2-b8ee-18810ffacc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK, does pineapple belong on a pizza? Relax and give me fun answer.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_33k.prompt.values[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
