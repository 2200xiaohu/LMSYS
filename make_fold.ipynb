{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6979c80-3c38-4fe8-a743-ae35ab39f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "def process(input_str):\n",
    "    return json.loads(input_str)\n",
    "df_train = pd.read_csv(\"dataset/random_train.csv\")\n",
    "df_train.loc[:, 'prompt'] = df_train['prompt'].apply(process)\n",
    "df_train.loc[:, 'response_a'] = df_train['response_a'].apply(process)\n",
    "df_train.loc[:, 'response_b'] = df_train['response_b'].apply(process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f33e55-b0e9-4823-bce3-ed037bfcdb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b28f0e-8a8a-4b4f-bada-23d4e01ec161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/random_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fba1d3-1921-4ac8-a2bb-09e6d5f1c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b3b1f-951e-47c4-95b3-148c5a25a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:, 'prompt'] = df_train['prompt'].apply(process)\n",
    "df_train.loc[:, 'response_a'] = df_train['response_a'].apply(process)\n",
    "df_train.loc[:, 'response_b'] = df_train['response_b'].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f259b-e015-4929-a424-a4b8bbaa825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_train.loc[df_train.index % 4 != 0,].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1474a-be0f-4dc7-b351-53c5246efca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70207271-567d-407b-b89a-4fc26ea46deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]\n",
    "    \n",
    "df_train = pd.read_csv('dataset/train.csv').reset_index(drop = True)\n",
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77566547-d715-4100-81b3-8a4632b60d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.index % 4 != 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5911c8-6e58-4d4e-9637-9e237c091ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.index % 20 == 0,].reset_index(drop = True).to_csv('dataset/random_valid.csv')\n",
    "df_train.loc[df_train.index % 20 != 0,].reset_index(drop = True).to_csv('dataset/random_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11551a59-2783-42cb-9ce0-c66c170576d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.index % 20 == 0,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9624737-5529-4d7b-8ede-3a9e86a05330",
   "metadata": {},
   "source": [
    "# For instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752d005a-daf6-4c0b-bbf3-ad7de43f32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "def process(input_str):\n",
    "    return json.loads(input_str)\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "train['label'] = train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f51266-81b1-406f-b41c-a16bbcd245fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(row):\n",
    "#     row['response_a'] = row['response_a'].replace(\"null\",'\"null\"')\n",
    "#     row['response_b'] = row['response_b'].replace(\"null\",'\"null\"')\n",
    "#     if row['prompt'][-3:] == ',\"]':\n",
    "#         row['prompt'] = row['prompt'][:-3] + ']'\n",
    "#     return row\n",
    "\n",
    "# train= train.apply(lambda x: preprocess(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5776472b-0f14-4180-91d1-29b182ce2423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57477/57477 [00:02<00:00, 20622.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "output_as = []\n",
    "output_bs = []\n",
    "labels = []\n",
    "ids = []\n",
    "for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    prompt = row[\"prompt\"]\n",
    "    response_a = row[\"response_a\"]\n",
    "    response_b = row[\"response_b\"]\n",
    "    label = row['label']\n",
    "    id = row['id']\n",
    "    assert len(prompt) == len(response_a) == len(response_b)\n",
    "    for i in range(len(prompt)):\n",
    "        output_as.append(f\"###Model A\\nPrompt: {prompt[i]}\\nResponse: {response_a[i]}\\n\\n\")\n",
    "        output_bs.append(f\"###Model B\\nPrompt: {prompt[i]}\\nResponse: {response_b[i]}\\n\\n\")\n",
    "        ids.append(id)\n",
    "        labels.append(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8e05a4-4d15-40ec-9456-4b70e5b51e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(ids)) == len(train)\n",
    "train = pd.DataFrame({'id': ids, 'instruction_a': output_as, 'instruction_b': output_bs, 'label': labels })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b394b59-7ae4-4f5c-9d96-f525d9d83c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# output_as = []\n",
    "# output_bs = []\n",
    "# scuess_idx = []\n",
    "# labels = []\n",
    "# ids = []\n",
    "# for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "#     try:\n",
    "#         prompt = row[\"prompt\"]\n",
    "#         response_a = row[\"response_a\"]\n",
    "#         response_b = row[\"response_b\"]\n",
    "#         label = row['label']\n",
    "#         id = row['id']\n",
    "#         if prompt.find('\",\"') != -1:\n",
    "#             #不止一个prompt\n",
    "#             #cnt = prompt.count('\",\"')\n",
    "#             prompt = row[\"prompt\"].split('\",\"')\n",
    "#             cnt = len(prompt)\n",
    "#             response_a = row[\"response_a\"].split('\",\"')\n",
    "#             response_b = row[\"response_b\"].split('\",\"')\n",
    "#             for sentence_idx in range(cnt):\n",
    "#                 output_a = \"###Model A\\n\"\n",
    "#                 output_b = \"###Model B\\n\"\n",
    "#                 output_a += \"Prompt: \" + prompt[sentence_idx][2:].strip() + \"\\n\"\n",
    "#                 output_a += \"Response: \" + response_a[sentence_idx][2:].strip() + \"\\n\\n\"\n",
    "#                 output_b += \"Prompt: \" + prompt[sentence_idx][2:].strip() + \"\\n\"\n",
    "#                 output_b += \"Response: \" +response_b[sentence_idx][2:].strip() + \"\\n\\n\"\n",
    "#                 output_as.append(output_a)\n",
    "#                 output_bs.append(output_b)\n",
    "#                 scuess_idx.append(idx)\n",
    "#                 labels.append(label)\n",
    "#                 ids.append(id)\n",
    "#         else:\n",
    "#             output_a = \"###Model A\\nPrompt: \" + row[\"prompt\"][2:-2].strip() + \"\\nResponse: \" + row[\"response_a\"][2:-2].strip() + \"\\n\\n\"\n",
    "#             output_b = \"###Model B\\nPrompt: \" + row[\"prompt\"][2:-2].strip() + \"\\nResponse: \" + row[\"response_b\"][2:-2].strip() + \"\\n\\n\"\n",
    "#             output_as.append(output_a)\n",
    "#             output_bs.append(output_b)\n",
    "#             scuess_idx.append(idx)\n",
    "#             labels.append(label)\n",
    "#             ids.append(id)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {idx}\")\n",
    "#         print(f\"{e}\")\n",
    "#         output_a = \"###Model A\\nPrompt: \" + row[\"prompt\"][2:-2].strip() + \"\\nResponse: \" + row[\"response_a\"].strip() + \"\\n\\n\"\n",
    "#         output_b = \"###Model B\\nPrompt: \" + row[\"prompt\"][2:-2].strip() + \"\\nResponse: \" + row[\"response_b\"].strip() + \"\\n\\n\"\n",
    "#         output_as.append(output_a)\n",
    "#         output_bs.append(output_b)\n",
    "#         scuess_idx.append(idx)\n",
    "#         labels.append(label)\n",
    "#         ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9638aa90-c07f-4210-8e7e-b563b87dc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train.id.unique()\n",
    "valid_idx = [idx[i] for i in range(len(idx)) if i % 20 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2182965-8c75-4ee2-b2cd-03528454b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.id.isin(valid_idx),].to_csv(\"dataset/random_instruction_valid.csv\", index = False)\n",
    "train.loc[~train.id.isin(valid_idx),].to_csv(\"dataset/random_instruction_train.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8989db-c565-47e2-8147-8b08c9657b6b",
   "metadata": {},
   "source": [
    "# 每个对话一段文本，做classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e5b29b-0133-417f-84fd-cd29f3ef6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"dataset/random_instruction_valid.csv\")\n",
    "train = pd.read_csv(\"dataset/random_instruction_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b659c996-b10f-4d28-8b0a-25683898a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2num = {'A':0, \"B\":1, \"C\":2}\n",
    "train['label'] = train.label.map(str2num)\n",
    "valid['label'] = valid.label.map(str2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71cda41a-4ac7-4f9d-9d56-b20d0a27c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('dataset/random_multi_turn_cls_train.csv', index = False)\n",
    "valid.to_csv('dataset/random_multi_turn_cls_valid.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d72be5-51bd-4a4e-b55d-b95b5b59791a",
   "metadata": {},
   "source": [
    "# 所有对话拼接一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7db611-4b90-4f24-8c44-77a18e19dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "###Model A\n",
    "Prompt: xxx\n",
    "Response: xxx\n",
    "###Model B\n",
    "Prompt: xxx\n",
    "Response: xxx\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5589cb81-ed3d-437c-8788-f45b5591871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"dataset/random_instruction_valid.csv\")\n",
    "train = pd.read_csv(\"dataset/random_instruction_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3148e7b4-5f8e-41bc-8dfe-e3146ada1073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 224 ms, total: 2.42 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 定义一个函数来删除###Model A\\n\n",
    "def remove(row):\n",
    "    row['instruction_a'] = row['instruction_a'].replace('###Model A\\n', '')\n",
    "    row['instruction_b'] = row['instruction_b'].replace('###Model B\\n', '')\n",
    "    return row\n",
    "# 添加\n",
    "def add(row):\n",
    "    row['instruction_a'] = \"###Model A\\n\" + row['instruction_a']\n",
    "    row['instruction_b'] = '###Model B\\n' + row['instruction_b']\n",
    "    return row\n",
    "    \n",
    "def main(data):\n",
    "    data['instruction_a'] = data['instruction_a'].apply(lambda x: x.replace('###Model A\\n', ''))\n",
    "    data['instruction_b'] = data['instruction_b'].apply(lambda x: x.replace('###Model B\\n', ''))\n",
    "    data = data.groupby('id').agg({'instruction_a': ''.join, 'instruction_b': ''.join, 'label': lambda x: list(x)[0]}).reset_index()\n",
    "    data['instruction_a'] = \"###Model A\\n\" + data['instruction_a']\n",
    "    data['instruction_b'] = \"###Model B\\n\" + data['instruction_b']\n",
    "    data['prompt_response'] = data['instruction_a'] + data['instruction_b']\n",
    "    return data\n",
    "train = main(train)\n",
    "valid = main(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161de9d9-a9ee-49c7-9ea8-a9aaadd5cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('dataset/random_all_in_one_train.csv', index = False)\n",
    "valid.to_csv('dataset/random_all_in_one_valid.csv', index = False)\n",
    "\n",
    "all = pd.concat([train, valid]).reset_index(drop = True)\n",
    "all.to_csv(\"dataset/full_all_in_one.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c6f20-addb-4331-b110-8cd9137866bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('dataset/random_all_in_one_train.csv')\n",
    "print(c.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3260391-6804-4006-8b91-ab6a854b72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "str2num = {'A':0, \"B\":1, \"C\":2}\n",
    "train['label'] = train.label.map(str2num)\n",
    "valid['label'] = valid.label.map(str2num)\n",
    "\n",
    "train.to_csv('dataset/random_all_in_one_cls_train.csv', index = False)\n",
    "valid.to_csv('dataset/random_all_in_one_cls_valid.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daee873-269a-4c8d-ba0e-00c239d578ca",
   "metadata": {},
   "source": [
    "# 另一种prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d8e23-2427-4cd2-81fa-42d4382b7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Prompt\n",
    "xxxx\n",
    "#Response\n",
    "##Model A\n",
    "xxxx\n",
    "##Model B\n",
    "xxxx\n",
    "\n",
    "#Prompt\n",
    "#Response\n",
    "##Model A\n",
    "xxxx\n",
    "##Model B\n",
    "xxxx\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1345c344-028d-4683-9d7f-b8d9256213a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "def process(input_str):\n",
    "    return json.loads(input_str)\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "train['label'] = train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4956f1a9-65f7-4e99-9fc8-4fbfb045e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57477/57477 [00:02<00:00, 25199.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "singel_turn = []\n",
    "labels = []\n",
    "ids = []\n",
    "for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    prompt = row[\"prompt\"]\n",
    "    response_a = row[\"response_a\"]\n",
    "    response_b = row[\"response_b\"]\n",
    "    label = row['label']\n",
    "    id = row['id']\n",
    "    assert len(prompt) == len(response_a) == len(response_b)\n",
    "    for i in range(len(prompt)):\n",
    "        template = f\"#Prompt\\n{prompt[i]}\\n\\n#Response\\n##Model A\\n{response_a[i]}\\n\\n##Model B\\n{response_b[i]}\\n\\n\"\n",
    "        singel_turn.append(template)\n",
    "        ids.append(id)\n",
    "        labels.append(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "866b5a56-a7ec-4b70-aee0-f9a897bffa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(ids)) == len(train)\n",
    "train = pd.DataFrame({'id': ids, 'singel_turn': singel_turn,'label': labels })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f5c311-f322-4974-a2e6-de690e1c1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train.id.unique()\n",
    "valid_idx = [idx[i] for i in range(len(idx)) if i % 20 == 0]\n",
    "\n",
    "train.loc[train.id.isin(valid_idx),].to_csv(\"dataset/random_instruction_version2_valid.csv\", index = False)\n",
    "train.loc[~train.id.isin(valid_idx),].to_csv(\"dataset/random_instruction_version2_train.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913f33e-a49f-46db-9376-3a859316494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.singel_turn.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dac3021-0299-48f4-a0ae-9129c5456113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有对话拼接在一起\n",
    "valid = pd.read_csv(\"dataset/random_instruction_version2_valid.csv\")\n",
    "train = pd.read_csv(\"dataset/random_instruction_version2_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69151935-e6d1-49d7-a351-5313cdcb6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data):\n",
    "    data = data.groupby('id').agg({'singel_turn': '#######\\n'.join, 'label': lambda x: list(x)[0]}).reset_index()\n",
    "    data = data.rename(columns = {'singel_turn':'prompt_response'})\n",
    "    return data\n",
    "train = main(train)\n",
    "valid = main(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d5e40ae-777d-4630-9a2f-d914f65845bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('dataset/random_all_in_one_train_version2.csv', index = False)\n",
    "valid.to_csv('dataset/random_all_in_one_valid_version2.csv', index = False)\n",
    "\n",
    "all = pd.concat([train, valid]).reset_index(drop = True)\n",
    "all.to_csv(\"dataset/full_all_in_one_version2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0f9d8-4b63-4c63-8151-933be42013a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06328338-4ecf-4eaa-ae39-a69165da1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特殊例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546dcbc2-b6a2-4ce8-b46e-213049ef4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv(\"dataset/random_all_in_one_train_version2.csv\")\n",
    "print(t.loc[t.id == 16350735,:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87eb60c2-9d99-4e7e-90e9-f53ee4b00952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 207/57477 [00:00<00:06, 8443.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30192\n",
      "30192\n",
      "53567\n",
      "53567\n",
      "53567\n",
      "65089\n",
      "96401\n",
      "198779\n",
      "292873\n",
      "313413\n",
      "370945\n",
      "441448\n",
      "481524\n",
      "481524\n",
      "497862\n",
      "587904\n",
      "604575\n",
      "604575\n",
      "604575\n",
      "604575\n",
      "604575\n",
      "604575\n",
      "738614\n",
      "738614\n",
      "862324\n",
      "863398\n",
      "887722\n",
      "914644\n",
      "933555\n",
      "1120158\n",
      "1120158\n",
      "1120158\n",
      "1256092\n",
      "1404102\n",
      "1440765\n",
      "1458108\n",
      "1491225\n",
      "1594211\n",
      "1639617\n",
      "1744093\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1813737\n",
      "1827787\n",
      "1842252\n",
      "1842252\n",
      "1842252\n",
      "1842252\n",
      "1842252\n",
      "2051408\n",
      "2154496\n",
      "2298796\n",
      "2388511\n",
      "2388511\n",
      "2802516\n",
      "2857714\n",
      "2912862\n",
      "2944182\n",
      "3254113\n",
      "3258431\n",
      "3259481\n",
      "3373963\n",
      "3445782\n",
      "3475655\n",
      "3499263\n",
      "3503031\n",
      "3504181\n",
      "3504181\n",
      "3519254\n",
      "3567106\n",
      "3578663\n",
      "3590999\n",
      "3622781\n",
      "3643104\n",
      "3710170\n",
      "3710170\n",
      "3760933\n",
      "3773792\n",
      "3777134\n",
      "3994811\n",
      "3995635\n",
      "3995635\n",
      "3995635\n",
      "3995635\n",
      "3995635\n",
      "4186011\n",
      "4349090\n",
      "4356730\n",
      "4486480\n",
      "4510489\n",
      "4587071\n",
      "4615863\n",
      "4683272\n",
      "4790276\n",
      "4961077\n",
      "4961077\n",
      "4970917\n",
      "4990514\n",
      "5061737\n",
      "5069186\n",
      "5166668\n",
      "5187535\n",
      "5188727\n",
      "5378146\n",
      "5498037\n",
      "5530797\n",
      "5530797\n",
      "5717448\n",
      "5879089\n",
      "5973148\n",
      "6058088\n",
      "6223290\n",
      "6241568\n",
      "6274602\n",
      "6287371\n",
      "6394907\n",
      "6447538\n",
      "6492528\n",
      "6570133\n",
      "6701196\n",
      "6807968\n",
      "6807968\n",
      "6817408\n",
      "6831350\n",
      "6853605\n",
      "7021095\n",
      "7021095\n",
      "7047857\n",
      "7271889\n",
      "7311145\n",
      "7324219\n",
      "7417163\n",
      "7484756\n",
      "7591373\n",
      "7599930\n",
      "7739903\n",
      "7831108\n",
      "7886413\n",
      "8017578\n",
      "8027538\n",
      "8108394\n",
      "8108394\n",
      "8173595\n",
      "8210755\n",
      "8210755\n",
      "8210755\n",
      "8322953\n",
      "8627100\n",
      "8639923\n",
      "8785767\n",
      "8942841\n",
      "8948997\n",
      "9059535\n",
      "9198128\n",
      "9420277\n",
      "9424912\n",
      "9473040\n",
      "9484428\n",
      "9534298\n",
      "9558869\n",
      "9601406\n",
      "9638121\n",
      "9638121\n",
      "9638121\n",
      "9638121\n",
      "9644862\n",
      "9644862\n",
      "9740296\n",
      "9785707\n",
      "9785707\n",
      "9865433\n",
      "10038573\n",
      "10156891\n",
      "10156891\n",
      "10156891\n",
      "10203267\n",
      "10349570\n",
      "10403116\n",
      "10604421\n",
      "10622974\n",
      "10798145\n",
      "10875646\n",
      "10909236\n",
      "10966560\n",
      "10974521\n",
      "10993520\n",
      "11036870\n",
      "11089285\n",
      "11174153\n",
      "11288315\n",
      "11462903\n",
      "11466834\n",
      "11477748\n",
      "11477748\n",
      "11570555\n",
      "11607871\n",
      "11662304\n",
      "11802413\n",
      "11841984\n",
      "11841984\n",
      "11953413\n",
      "11953413\n",
      "11953413\n",
      "11953413\n",
      "11955851\n",
      "12030710\n",
      "12361286\n",
      "12688674\n",
      "12747778\n",
      "12749848\n",
      "13035190\n",
      "13347957\n",
      "13394448\n",
      "13556772\n",
      "13651087\n",
      "13651087\n",
      "13651087\n",
      "13657431\n",
      "13678371\n",
      "13709106\n",
      "13735973\n",
      "13735973\n",
      "13744661\n",
      "13782880\n",
      "13797059\n",
      "13896087\n",
      "14280062\n",
      "14354101\n",
      "14451315\n",
      "14493470\n",
      "14685320\n",
      "14819628\n",
      "14819628\n",
      "14819628\n",
      "14819628\n",
      "14940307\n",
      "15059469\n",
      "15097210\n",
      "15132484\n",
      "15193241\n",
      "15214568\n",
      "15214568\n",
      "15214568\n",
      "15214568\n",
      "15214568\n",
      "15247315\n",
      "15323548\n",
      "15372768\n",
      "15439831\n",
      "15551443\n",
      "15641037\n",
      "15762385\n",
      "15816190\n",
      "15816190\n",
      "15816190\n",
      "15828515\n",
      "15909896\n",
      "15945921\n",
      "16127462\n",
      "16134621\n",
      "16164492\n",
      "16192524\n",
      "16345289\n",
      "16345289\n",
      "16345289\n",
      "16345289\n",
      "16350735\n",
      "16350735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prompt)):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mid\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_a\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_b[i]:\n\u001b[1;32m     13\u001b[0m         ids\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mid\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "ids = []\n",
    "for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    prompt = row[\"prompt\"]\n",
    "    response_a = row[\"response_a\"]\n",
    "    response_b = row[\"response_b\"]\n",
    "    label = row['label']\n",
    "    id = row['id']\n",
    "    assert len(prompt) == len(response_a) == len(response_b)\n",
    "    for i in range(len(prompt)):\n",
    "        print(id)\n",
    "        if 'null' in response_a[i] or 'null' in response_b[i]:\n",
    "            ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0f789c-f0b1-470a-9e02-98bd71f4312e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                         16441516\n",
       "model_a                                            claude-instant-1\n",
       "model_b                                                openchat-3.5\n",
       "prompt            [element #1\\telement #2\\tcompound formed?\\tche...\n",
       "response_a        [element #1   element #2   compound formed?   ...\n",
       "response_b        [element #1\\telement #2\\tcompound formed?\\tche...\n",
       "winner_model_a                                                    1\n",
       "winner_model_b                                                    0\n",
       "winner_tie                                                        0\n",
       "label                                                             A\n",
       "Name: 208, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[208,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f8cf3c0-35ad-48b5-a37e-42191c6a6c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['I do not have any confirmed details about a World War III. Speculation about future conflicts can often be misleading or anxiety-provoking. Most experts believe maintaining open communication and cooperation between countries is the best way to prevent large-scale wars.', None])]\n"
     ]
    }
   ],
   "source": [
    "print(train.loc[train.id == 16350735,'response_a'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328b921e-1899-4ea3-9321-5d0c9a75abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['Tell me about wwiii', 'Enough'])]\n"
     ]
    }
   ],
   "source": [
    "print(train.loc[train.id == 16350735,'prompt'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0b8da4a-a42e-4c01-9545-1bcab9cad51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>16350735</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[Tell me about wwiii, Enough]</td>\n",
       "      <td>[I do not have any confirmed details about a W...</td>\n",
       "      <td>[As an AI language model, I must clarify that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id           model_a         model_b  \\\n",
       "207  16350735  claude-instant-1  tulu-2-dpo-70b   \n",
       "\n",
       "                            prompt  \\\n",
       "207  [Tell me about wwiii, Enough]   \n",
       "\n",
       "                                            response_a  \\\n",
       "207  [I do not have any confirmed details about a W...   \n",
       "\n",
       "                                            response_b  winner_model_a  \\\n",
       "207  [As an AI language model, I must clarify that ...               0   \n",
       "\n",
       "     winner_model_b  winner_tie label  \n",
       "207               1           0     B  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train.id == 16350735,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92a5212f-29af-484c-a60c-6eefc7c0eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['As an AI language model, I must clarify that there has not been a World War III (WWIII) as of my knowledge cutoff in September 2021, and as far as I am aware, there have not been any official declarations or global conflicts that could be considered WWIII since then. Nonetheless, I can provide you with information about popular cultural references and hypothetical scenarios that involve a WWIII.\\n\\nIn popular culture, WWIII is often portrayed as a global conflict between major world powers, involving massive military campaigns, devastating weaponry, and significant loss of life. The causes of such a hypothetical war vary, but popular scenarios include:\\n\\n1. Nuclear War: A conflict between nuclear-armed nations, resulting in widespread devastation and loss of life. This is often portrayed in films, books, and video games as a potential cause of WWIII.\\n\\n2. Cyber Warfare: A global conflict that centers around cyber attacks and digital warfare, where nations engage in a high-stakes game of espionage and sabotage in the digital realm.\\n\\n3. Climate Change: A hypothetical scenario where nations fight over resources or engage in conflicts caused by the effects of climate change, such as droughts, famines, and mass migrations.\\n\\n4. Geopolitical Tensions: Ongoing disputes between nations, such as those involving territories, resources, or ideological differences, could escalate into a global conflict.\\n\\n5. Terrorism: A global conflict sparked by large-scale terrorist attacks, leading to an international coalition taking military action against terrorist organizations and their supporters.\\n\\nThese scenarios are purely fictional and should not be taken as predictions or actual events. It is essential to focus on diplomacy, international cooperation, and peaceful resolution of conflicts to avoid the possibility of a global war.\\n\\n��역��과  \\nAI ��어 모��로서 제 지식 마��일인 2021년 9월 현재 세�� 대전 III(WWIII)가 �������������������� 그 이��에도 WWIII로 ��주�� 수 ��는 공식�� 선��이나 ��로�� ������이 ������음을 ��명�� 해�� 합니다. 그��나 가������인 WWIII를 수��하는 인기 ��는 문화�� ��조�� 시나리오에 대한 정보를 제공�� 수 ������니다.\\n\\n대중문화에서 WWIII는 종종 대��모 군사 ������인, ������������ 무기, 상��한 사상자를 동��하는 주요 세�� 강대국 ��의 ��로�� ������������로 ��사��니다. 이��한 가상의 전��의 원인은 다��하지만 일������인 시나리오에는 다음이 ������������니다.\\n\\n1. ��전��: ��무장국 ��의 ������������로 인한 ������위한 ������화��▌', 'As an AI language model, I must clarify that there has not been a World War III (WWIII) as of my knowledge cutoff in September 2021, and as far as I am aware, there have not been any official declarations or global conflicts that could be considered WWIII since then. Nonetheless, I can provide you with information about popular cultural references and hypothetical scenarios that involve a WWIII.\\n\\nIn popular culture, WWIII is often portrayed as a global conflict between major world powers, involving massive military campaigns, devastating weaponry, and significant loss of life. The causes of such a hypothetical war vary, but popular scenarios include:\\n\\n1. Nuclear War: A conflict between nuclear-armed nations, resulting in widespread devastation and loss of life. This is often portrayed in films, books, and video games as a potential cause of WWIII.\\n\\n2. Cyber Warfare: A global conflict that centers around cyber attacks and digital warfare, where nations engage in a high-stakes game of espionage and sabotage in the digital realm.\\n\\n3. Climate Change: A hypothetical scenario where nations fight over resources or engage in conflicts caused by the effects of climate change, such as droughts, famines, and mass migrations.\\n\\n4. Geopolitical Tensions: Ongoing disputes between nations, such as those involving territories, resources, or ideological differences, could escalate into a global conflict.\\n\\n5. Terrorism: A global conflict sparked by large-scale terrorist attacks, leading to an international coalition taking military action against terrorist organizations and their supporters.\\n\\nThese scenarios are purely fictional and should not be taken as predictions or actual events. It is essential to focus on diplomacy, international cooperation, and peaceful resolution of conflicts to avoid the possibility of a global war.\\n\\n��역��과  \\nAI ��어 모��로서 제 지식 마��일인 2021년 9월 현재 세�� 대전 III(WWIII)가 �������������������� 그 이��에도 WWIII로 ��주�� 수 ��는 공식�� 선��이나 ��로�� ������이 ������음을 ��명�� 해�� 합니다. 그��나 가������인 WWIII를 수��하는 인기 ��는 문화�� ��조�� 시나리오에 대한 정보를 제공�� 수 ������니다.\\n\\n대중문화에서 WWIII는 종종 대��모 군사 ������인, ������������ 무기, 상��한 사상자를 동��하는 주요 세�� 강대국 ��의 ��로�� ������������로 ��사��니다. 이��한 가상의 전��의 원인은 다��하지만 일������인 시나리오에는 다음이 ������������니다.\\n\\n1. ��전��: ��무장국 ��의 ������������로 인한 ������위한 ������화�� 인명��해를 ������ ��니다. 이��은 종종 WWIII의 원인��로 영화, ��, 비��오 ������에 ��사��니다.\\n\\n2. 사이�� 전��: 전 세�� ��의 사이�� 공��과 ��지��'])]\n"
     ]
    }
   ],
   "source": [
    "print(train.loc[train.id == 16350735,'response_b'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
