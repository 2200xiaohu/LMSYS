{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4301579c-9b27-4180-96c4-d7d921bdb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa143e6b-b246-4240-b2cd-a47127b66d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_data = './dataset/demo_train.csv'\n",
    "    MAX_INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9cb8663-a48b-4484-95e6-030f2b06bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(args.train_data).reset_index(drop = True)\n",
    "#df_valid = pd.read_csv(args.valid_data).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a96b93e-d2a1-4d19-b9b3-e507723d7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34566812-f99a-48b9-bcd7-051a4cff8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1ae8dfb-4b8f-41e3-aa6a-c35ed2e20497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6d4245f-0814-4e75-b331-d1f1dd74acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['prompt'] ] * 2\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in ['response_a','response_b']]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='longest_first', \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953f1e96-9cf9-4039-83ad-4f34bb69643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example['response_a'] + \" [SEP]\" +  \" #### \" + example['prompt'] + \" [SEP] \" + example['response_b'] + \" [SEP]\"]\n",
    "    tokenized_example = tokenizer(sentences, truncation=True, \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ded5e1b3-d2fe-4c4d-ae98-401615cb54db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df_train)\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefcd2e8-74f0-4918-98d5-4790cf54bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'label'],\n",
       "    num_rows: 1001\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7921b57-ffd9-432d-a200-3ef4d64aa53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7098e566174316a08ca8a68958efd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b'])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871078b7-fc9f-4d8f-aa1a-afaefb54ac3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'winner_model_a', 'winner_model_b', 'winner_tie', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1001\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e662d-18dc-4bb6-8004-feb62a45800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "759cd8f4-89f1-4119-ba28-20d748dbf098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                       40\n",
       "id                                                          3258431\n",
       "model_a                                     stablelm-tuned-alpha-7b\n",
       "model_b                                                  vicuna-13b\n",
       "prompt            [\"The following is a command that the user is ...\n",
       "response_a                                                  [\"Yes\"]\n",
       "response_b                                                   [\"NO\"]\n",
       "winner_model_a                                                    1\n",
       "winner_model_b                                                    0\n",
       "winner_tie                                                        0\n",
       "label                                                             0\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "954cb1a5-81e0-4aec-811f-4266c1091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:1000,].reset_index(drop = True).to_csv('demo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff107e9b-505b-4a35-b371-abc989431e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[1000:1200,].reset_index(drop = True).to_csv('demo_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9cdb18f-3bd3-4da0-9a92-dd0a6379ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice, AutoModelForSequenceClassification, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff703200-17d7-4dba-b1f5-4930041f30a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = 'meta-llama/llama-3-transformers-8b-hf-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917eee09-f821-4697-bfe0-052896b9595c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<pad>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322e199e-c8fb-4235-a8be-b6588c43a73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128256 in tokenizer(\"<pad>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d2e05f-33ec-4fe2-b480-c559c688b960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997cdd28d95f4a6db3d39c3fd2ae24eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/llama-3-transformers-8b-hf-v1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef17c6d1-ef34-49b9-946f-1546054b097a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.embed_tokens.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.0.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.0.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.1.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.1.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.2.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.2.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.3.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.3.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.4.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.4.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.5.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.5.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.6.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.6.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.7.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.7.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.8.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.8.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.9.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.9.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.10.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.10.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.11.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.11.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.12.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.12.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.13.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.13.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.14.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.14.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.15.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.15.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.16.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.16.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.17.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.17.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.18.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.18.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.19.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.19.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.20.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.20.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.21.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.21.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.22.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.22.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.23.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.23.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.24.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.24.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.25.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.25.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.26.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.26.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.27.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.27.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.28.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.28.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.29.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.29.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.30.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.30.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.31.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.31.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.norm.weight, dtype: torch.bfloat16\n",
      "Layer: score.weight, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f513d894-9d5a-456a-9156-0d80c4a33cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7c8f25c8f246bea0d64f2268143ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/llama-3-transformers-8b-hf-v1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128257, 4096)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# config.hidden_dropout_prob = args.dropout_rate\n",
    "# config.attention_probs_dropout_prob = args.dropout_rate\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "#     inference_mode=False,\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias = 'none',\n",
    "#     target_modules=[\"q_proj\",\"k_proj\",\"v_proj\"]  # Target specific modules\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5ae33e-53db-4e13-ab78-324866c4a071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight, torch.Size([128257, 4096]), torch.bfloat16\n",
      "model.layers.0.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.0.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.0.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.0.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.0.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.0.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.0.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.0.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.0.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.0.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.0.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.0.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.0.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.0.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.0.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.0.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.0.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.0.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.0.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.0.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.0.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.0.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.0.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.0.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.0.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.0.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.0.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.0.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.0.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.0.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.1.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.1.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.1.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.1.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.1.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.1.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.1.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.1.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.1.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.1.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.1.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.1.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.1.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.1.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.1.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.1.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.1.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.1.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.1.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.1.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.1.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.1.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.1.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.1.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.1.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.1.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.1.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.1.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.1.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.1.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.2.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.2.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.2.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.2.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.2.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.2.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.2.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.2.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.2.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.2.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.2.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.2.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.2.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.2.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.2.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.2.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.2.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.2.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.2.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.2.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.2.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.2.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.2.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.2.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.2.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.2.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.2.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.2.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.2.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.2.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.3.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.3.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.3.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.3.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.3.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.3.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.3.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.3.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.3.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.3.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.3.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.3.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.3.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.3.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.3.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.3.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.3.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.3.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.3.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.3.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.3.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.3.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.3.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.3.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.3.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.3.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.3.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.3.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.3.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.3.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.4.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.4.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.4.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.4.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.4.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.4.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.4.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.4.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.4.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.4.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.4.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.4.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.4.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.4.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.4.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.4.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.4.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.4.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.4.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.4.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.4.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.4.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.4.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.4.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.4.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.4.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.4.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.4.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.4.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.4.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.5.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.5.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.5.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.5.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.5.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.5.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.5.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.5.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.5.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.5.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.5.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.5.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.5.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.5.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.5.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.5.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.5.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.5.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.5.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.5.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.5.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.5.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.5.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.5.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.5.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.5.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.5.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.5.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.5.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.5.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.6.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.6.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.6.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.6.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.6.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.6.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.6.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.6.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.6.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.6.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.6.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.6.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.6.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.6.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.6.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.6.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.6.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.6.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.6.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.6.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.6.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.6.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.6.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.6.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.6.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.6.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.6.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.6.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.6.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.6.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.7.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.7.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.7.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.7.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.7.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.7.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.7.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.7.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.7.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.7.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.7.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.7.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.7.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.7.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.7.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.7.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.7.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.7.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.7.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.7.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.7.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.7.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.7.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.7.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.7.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.7.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.7.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.7.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.7.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.7.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.8.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.8.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.8.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.8.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.8.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.8.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.8.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.8.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.8.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.8.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.8.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.8.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.8.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.8.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.8.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.8.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.8.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.8.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.8.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.8.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.8.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.8.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.8.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.8.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.8.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.8.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.8.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.8.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.8.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.8.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.9.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.9.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.9.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.9.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.9.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.9.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.9.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.9.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.9.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.9.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.9.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.9.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.9.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.9.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.9.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.9.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.9.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.9.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.9.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.9.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.9.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.9.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.9.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.9.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.9.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.9.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.9.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.9.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.9.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.9.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.10.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.10.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.10.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.10.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.10.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.10.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.10.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.10.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.10.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.10.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.10.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.10.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.10.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.10.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.10.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.10.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.10.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.10.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.10.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.10.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.10.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.10.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.10.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.10.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.10.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.10.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.10.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.10.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.10.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.10.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.11.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.11.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.11.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.11.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.11.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.11.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.11.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.11.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.11.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.11.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.11.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.11.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.11.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.11.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.11.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.11.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.11.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.11.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.11.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.11.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.11.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.11.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.11.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.11.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.11.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.11.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.11.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.11.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.11.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.11.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.12.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.12.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.12.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.12.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.12.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.12.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.12.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.12.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.12.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.12.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.12.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.12.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.12.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.12.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.12.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.12.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.12.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.12.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.12.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.12.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.12.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.12.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.12.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.12.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.12.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.12.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.12.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.12.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.12.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.12.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.13.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.13.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.13.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.13.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.13.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.13.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.13.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.13.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.13.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.13.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.13.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.13.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.13.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.13.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.13.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.13.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.13.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.13.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.13.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.13.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.13.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.13.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.13.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.13.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.13.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.13.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.13.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.13.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.13.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.13.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.14.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.14.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.14.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.14.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.14.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.14.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.14.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.14.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.14.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.14.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.14.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.14.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.14.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.14.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.14.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.14.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.14.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.14.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.14.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.14.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.14.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.14.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.14.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.14.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.14.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.14.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.14.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.14.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.14.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.14.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.15.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.15.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.15.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.15.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.15.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.15.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.15.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.15.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.15.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.15.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.15.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.15.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.15.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.15.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.15.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.15.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.15.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.15.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.15.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.15.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.15.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.15.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.15.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.15.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.15.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.15.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.15.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.15.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.15.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.15.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.16.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.16.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.16.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.16.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.16.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.16.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.16.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.16.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.16.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.16.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.16.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.16.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.16.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.16.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.16.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.16.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.16.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.16.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.16.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.16.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.16.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.16.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.16.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.16.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.16.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.16.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.16.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.16.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.16.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.16.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.17.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.17.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.17.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.17.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.17.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.17.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.17.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.17.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.17.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.17.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.17.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.17.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.17.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.17.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.17.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.17.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.17.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.17.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.17.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.17.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.17.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.17.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.17.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.17.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.17.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.17.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.17.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.17.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.17.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.17.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.18.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.18.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.18.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.18.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.18.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.18.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.18.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.18.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.18.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.18.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.18.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.18.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.18.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.18.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.18.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.18.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.18.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.18.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.18.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.18.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.18.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.18.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.18.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.18.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.18.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.18.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.18.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.18.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.18.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.18.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.19.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.19.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.19.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.19.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.19.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.19.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.19.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.19.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.19.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.19.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.19.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.19.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.19.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.19.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.19.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.19.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.19.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.19.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.19.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.19.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.19.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.19.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.19.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.19.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.19.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.19.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.19.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.19.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.19.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.19.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.20.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.20.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.20.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.20.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.20.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.20.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.20.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.20.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.20.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.20.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.20.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.20.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.20.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.20.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.20.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.20.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.20.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.20.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.20.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.20.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.20.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.20.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.20.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.20.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.20.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.20.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.20.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.20.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.20.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.20.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.21.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.21.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.21.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.21.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.21.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.21.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.21.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.21.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.21.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.21.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.21.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.21.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.21.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.21.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.21.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.21.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.21.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.21.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.21.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.21.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.21.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.21.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.21.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.21.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.21.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.21.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.21.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.21.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.21.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.21.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.22.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.22.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.22.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.22.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.22.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.22.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.22.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.22.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.22.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.22.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.22.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.22.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.22.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.22.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.22.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.22.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.22.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.22.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.22.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.22.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.22.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.22.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.22.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.22.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.22.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.22.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.22.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.22.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.22.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.22.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.23.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.23.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.23.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.23.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.23.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.23.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.23.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.23.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.23.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.23.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.23.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.23.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.23.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.23.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.23.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.23.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.23.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.23.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.23.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.23.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.23.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.23.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.23.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.23.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.23.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.23.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.23.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.23.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.23.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.23.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.24.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.24.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.24.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.24.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.24.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.24.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.24.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.24.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.24.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.24.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.24.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.24.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.24.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.24.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.24.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.24.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.24.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.24.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.24.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.24.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.24.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.24.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.24.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.24.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.24.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.24.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.24.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.24.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.24.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.24.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.25.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.25.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.25.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.25.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.25.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.25.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.25.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.25.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.25.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.25.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.25.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.25.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.25.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.25.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.25.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.25.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.25.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.25.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.25.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.25.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.25.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.25.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.25.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.25.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.25.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.25.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.25.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.25.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.25.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.25.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.26.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.26.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.26.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.26.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.26.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.26.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.26.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.26.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.26.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.26.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.26.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.26.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.26.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.26.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.26.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.26.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.26.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.26.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.26.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.26.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.26.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.26.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.26.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.26.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.26.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.26.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.26.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.26.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.26.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.26.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.27.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.27.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.27.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.27.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.27.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.27.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.27.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.27.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.27.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.27.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.27.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.27.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.27.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.27.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.27.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.27.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.27.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.27.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.27.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.27.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.27.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.27.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.27.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.27.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.27.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.27.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.27.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.27.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.27.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.27.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.28.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.28.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.28.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.28.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.28.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.28.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.28.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.28.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.28.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.28.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.28.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.28.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.28.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.28.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.28.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.28.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.28.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.28.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.28.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.28.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.28.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.28.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.28.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.28.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.28.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.28.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.28.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.28.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.28.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.28.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.29.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.29.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.29.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.29.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.29.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.29.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.29.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.29.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.29.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.29.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.29.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.29.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.29.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.29.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.29.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.29.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.29.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.29.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.29.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.29.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.29.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.29.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.29.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.29.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.29.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.29.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.29.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.29.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.29.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.29.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.30.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.30.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.30.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.30.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.30.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.30.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.30.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.30.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.30.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.30.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.30.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.30.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.30.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.30.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.30.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.30.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.30.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.30.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.30.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.30.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.30.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.30.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.30.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.30.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.30.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.30.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.30.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.30.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.30.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.30.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.31.self_attn.q_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.31.self_attn.q_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.31.self_attn.q_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.31.self_attn.q_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.31.self_attn.k_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.31.self_attn.k_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.31.self_attn.k_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.31.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.31.self_attn.v_proj.weight, torch.Size([2097152, 1]), torch.uint8\n",
      "model.layers.31.self_attn.v_proj.weight.absmax, torch.Size([65536]), torch.float32\n",
      "model.layers.31.self_attn.v_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.31.self_attn.v_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.31.self_attn.o_proj.weight, torch.Size([8388608, 1]), torch.uint8\n",
      "model.layers.31.self_attn.o_proj.weight.absmax, torch.Size([262144]), torch.float32\n",
      "model.layers.31.self_attn.o_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.31.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([82]), torch.uint8\n",
      "model.layers.31.mlp.gate_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.31.mlp.gate_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.31.mlp.gate_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.31.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.31.mlp.up_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.31.mlp.up_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.31.mlp.up_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.31.mlp.up_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.31.mlp.down_proj.weight, torch.Size([29360128, 1]), torch.uint8\n",
      "model.layers.31.mlp.down_proj.weight.absmax, torch.Size([917504]), torch.float32\n",
      "model.layers.31.mlp.down_proj.weight.quant_map, torch.Size([16]), torch.float32\n",
      "model.layers.31.mlp.down_proj.weight.quant_state.bitsandbytes__nf4, torch.Size([83]), torch.uint8\n",
      "model.layers.31.input_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.layers.31.post_attention_layernorm.weight, torch.Size([4096]), torch.bfloat16\n",
      "model.norm.weight, torch.Size([4096]), torch.bfloat16\n",
      "score.weight, torch.Size([3, 4096]), torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "for key in model.state_dict():\n",
    "        print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810429ba-c85b-43c7-a55a-843629551fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.embed_tokens.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.0.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.0.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.1.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.1.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.2.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.2.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.3.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.3.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.4.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.4.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.5.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.5.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.6.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.6.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.7.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.7.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.8.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.8.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.9.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.9.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.10.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.10.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.11.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.11.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.12.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.12.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.13.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.13.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.14.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.14.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.15.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.15.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.16.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.16.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.17.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.17.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.18.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.18.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.19.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.19.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.20.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.20.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.21.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.21.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.22.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.22.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.23.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.23.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.24.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.24.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.25.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.25.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.26.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.26.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.27.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.27.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.28.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.28.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.29.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.29.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.30.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.30.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.31.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.input_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.layers.31.post_attention_layernorm.weight, dtype: torch.bfloat16\n",
      "Layer: model.norm.weight, dtype: torch.bfloat16\n",
      "Layer: score.weight, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43133fe9-2ac5-430c-80ee-e4b1c06c8751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.embed_tokens.weight, dtype: torch.float16\n",
      "Layer: model.layers.0.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.0.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.0.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.1.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.1.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.1.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.2.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.2.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.2.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.3.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.3.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.3.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.4.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.4.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.4.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.5.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.5.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.5.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.6.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.6.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.6.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.7.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.7.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.7.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.8.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.8.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.8.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.9.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.9.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.9.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.10.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.10.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.10.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.11.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.11.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.11.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.12.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.12.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.12.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.13.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.13.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.13.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.14.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.14.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.14.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.15.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.15.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.15.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.16.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.16.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.16.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.17.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.17.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.17.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.18.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.18.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.18.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.19.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.19.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.19.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.20.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.20.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.20.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.21.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.21.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.21.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.22.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.22.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.22.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.23.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.23.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.23.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.24.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.24.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.24.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.25.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.25.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.25.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.26.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.26.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.26.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.27.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.27.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.27.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.28.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.28.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.28.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.29.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.29.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.29.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.30.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.30.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.30.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.31.self_attn.q_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.k_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.v_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.self_attn.o_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.gate_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.up_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.mlp.down_proj.weight, dtype: torch.uint8\n",
      "Layer: model.layers.31.input_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.layers.31.post_attention_layernorm.weight, dtype: torch.float16\n",
      "Layer: model.norm.weight, dtype: torch.float16\n",
      "Layer: score.weight, dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914da54-a43e-4e44-a575-75265d875359",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.dtype for i in model.parameters()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
