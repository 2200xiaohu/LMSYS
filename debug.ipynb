{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4301579c-9b27-4180-96c4-d7d921bdb3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from random import random, randint\n",
    "from utils import load_json, load_split_data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa143e6b-b246-4240-b2cd-a47127b66d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_data = './dataset/demo_train.csv'\n",
    "    MAX_INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8663-a48b-4484-95e6-030f2b06bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(args.train_data).reset_index(drop = True)\n",
    "#df_valid = pd.read_csv(args.valid_data).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96b93e-d2a1-4d19-b9b3-e507723d7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34566812-f99a-48b9-bcd7-051a4cff8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8dfb-4b8f-41e3-aa6a-c35ed2e20497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4245f-0814-4e75-b331-d1f1dd74acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['prompt'] ] * 2\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in ['response_a','response_b']]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='longest_first', \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f1e96-9cf9-4039-83ad-4f34bb69643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example['response_a'] + \" [SEP]\" +  \" #### \" + example['prompt'] + \" [SEP] \" + example['response_b'] + \" [SEP]\"]\n",
    "    tokenized_example = tokenizer(sentences, truncation=True, \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e1b3-d2fe-4c4d-ae98-401615cb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df_train)\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcd2e8-74f0-4918-98d5-4790cf54bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7921b57-ffd9-432d-a200-3ef4d64aa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b'])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871078b7-fc9f-4d8f-aa1a-afaefb54ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e662d-18dc-4bb6-8004-feb62a45800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cd8f4-89f1-4119-ba28-20d748dbf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb1a5-81e0-4aec-811f-4266c1091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:1000,].reset_index(drop = True).to_csv('demo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff107e9b-505b-4a35-b371-abc989431e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[1000:1200,].reset_index(drop = True).to_csv('demo_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdb18f-3bd3-4da0-9a92-dd0a6379ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice, AutoModelForSequenceClassification, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703200-17d7-4dba-b1f5-4930041f30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'meta-llama/llama-3-transformers-8b-hf-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eee09-f821-4697-bfe0-052896b9595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<pad>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e199e-c8fb-4235-a8be-b6588c43a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "128256 in tokenizer(\"<pad>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2e05f-33ec-4fe2-b480-c559c688b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c6d1-ef34-49b9-946f-1546054b097a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513d894-9d5a-456a-9156-0d80c4a33cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# config.hidden_dropout_prob = args.dropout_rate\n",
    "# config.attention_probs_dropout_prob = args.dropout_rate\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "#     inference_mode=False,\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias = 'none',\n",
    "#     target_modules=[\"q_proj\",\"k_proj\",\"v_proj\"]  # Target specific modules\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ae33e-53db-4e13-ab78-324866c4a071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.state_dict():\n",
    "        print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810429ba-c85b-43c7-a55a-843629551fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133fe9-2ac5-430c-80ee-e4b1c06c8751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914da54-a43e-4e44-a575-75265d875359",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.dtype for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d21cd-15e4-480b-b786-b8027c511b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e38681-9f85-423b-848e-b0a888249ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/1k_mt_bench_human_judgments.json', 1, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c925c-5c5e-4680-ab26-5f1bdbf90cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/lmsys-chatbot_arena_conversations-33k.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f96254-d439-4d83-9c2f-8fb7f3f67968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569eb7b-292b-4ab8-bbfb-6cc66f159a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369f833-3ecb-4ba9-80ca-9d373596e882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "prompt_response = df_train.loc[idx,'prompt_response']\n",
    "label = df_train.loc[idx,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36874c67-b6ab-4415-86d7-89a1d2b81e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_response)\n",
    "print(\"\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610e855-5fa7-4a26-85c3-11f9cc69a3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5a0df-a66b-49a9-9531-3e66aca3f001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([1,\n",
    " 32006,\n",
    " 887,\n",
    " 526])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec7fee-0823-458a-94a5-cd8fb24d734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd68316-0e01-4fc4-8f76-e5b62da4cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('<|system|>\\nYou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a28b7-ac2b-4bbc-9b48-6eeb7c7253ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('Apple\\nBa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96200af2-961a-4d23-a0f4-99d317f17889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([396,\n",
    " 18571,\n",
    " 415,\n",
    " 13,\n",
    " 4548,\n",
    " 7420,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6808dc-9877-4d5f-a3d4-798c49009e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([29933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece7e34-75cf-4d86-9e39-3a17f463b2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(templete_part1 + prompt_response + templete_part2 + templete_part3 + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f43ec6-c8e9-47c9-98d4-0c1a715a3db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templete_part1 = \"<|system|>\\nYou are a helpful assistant good at judging conversations.<|end|>\\n<|user|>\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "templete_part3 = \"<|assistant|>\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids'][1:]\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92cb47-4478-4597-a027-9662c47c7f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Apple\"\n",
    "prompt_response = templete_part1 + text + templete_part2 + templete_part3 + label + tokenizer.eos_token\n",
    "print(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff6eef-20e1-4df6-b415-7e614fa8066f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'microsoft/LLM-Research/Phi-3-mini-4k-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d64949-df75-4c8d-9b3e-41b60c220736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b820-f8d4-4eac-835f-bef80e20fd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13130933-64c5-4d13-ba8f-3ad126a0ecbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0c18-8a90-4077-8451-aee573084dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70aa3-6a54-4099-8625-1bf211e3b613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a00c5-2dc1-4942-bd80-58101d6eef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15f353-3c10-412f-9d4d-a9c6832d8f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519312-0c1c-4e21-8526-29f562ed0e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faccc94-8a02-434e-a0ca-99dbe8bf4db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('<|user|>',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9affb58-cf74-4b77-a743-00d3cb6f7a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AutoModelForCausalLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8039867-2794-42d5-9fd6-90e7073be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d33507b-c0b4-4ff2-a4bf-39dd569aef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/glm-4-9b-chat\", trust_remote_code=True)\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "    {\"role\": \"assistant\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a5b854e-9ae4-4990-84df-c2a04e7c5b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gMASK]<sop><|user|>\n",
      "Give me a short introduction to large language model.<|assistant|>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e61545e-d1c9-4eba-98f0-97a18724864f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151329"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a72c9d58-dc10-4b73-aa4c-b328253e10a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[151331, 151333, 151336]], 'attention_mask': [[1, 1, 1]], 'position_ids': [[0, 1, 2]]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(['<|user|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f564fd-8178-4706-9883-5c23a7c670ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text = 'A',add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0789eb46-4644-47bc-9f37-5c6da63e48d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('A',add_special_tokens=False, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "221791bb-f71f-4c2b-bcb1-1c5751fa4e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|user|>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([151336])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13f39e0-8d92-4fc7-bd34-1f18ed98085b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[gMASK]<sop><|user|>\\nGive me a short introduction to large language model.<|assistant|>\\nGive me a short introduction to large language model.<|assistant|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f49e-457b-4050-97fc-c0b6746b2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767040-e7e4-4fb6-a4ec-79cea4150a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete_part1 = \"<|im_start|>system\\nYou are a helpful assistant good at judging conversations.<|im_end|>\\n<|im_start|>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|im_end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids']\n",
    "#print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "templete_part3 = \"<|im_start|>assistant\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids']\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b518309-3e5d-4351-bc8e-cc28a1cebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(14374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba6b18-5775-445a-ab14-1a80cc6ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token,tokenizer.eos_token,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd0f3-6d2d-4f8a-9880-60fbc84c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1d3adf3-efa3-4add-bbfb-bd6aaf262584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9ee298bff145e9beb6cdbde53a6747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = 'THUDM/glm-4-9b-chat'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "                                             config=config,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3d80ddf-82bb-4fe5-89d7-57b68b288765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGLMForConditionalGeneration(\n",
       "  (transformer): ChatGLMModel(\n",
       "    (embedding): Embedding(\n",
       "      (word_embeddings): Embedding(151552, 4096)\n",
       "    )\n",
       "    (rotary_pos_emb): RotaryEmbedding()\n",
       "    (encoder): GLMTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-39): 40 x GLMBlock(\n",
       "          (input_layernorm): RMSNorm()\n",
       "          (self_attention): SelfAttention(\n",
       "            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
       "            (core_attention): CoreAttention(\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (post_attention_layernorm): RMSNorm()\n",
       "          (mlp): MLP(\n",
       "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
       "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): RMSNorm()\n",
       "    )\n",
       "    (output_layer): Linear(in_features=4096, out_features=151552, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6626eb-0734-4649-bed8-87e0e5f4d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d36ad-0414-420b-8b31-cada77b616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")\n",
    "#tmp2 = pd.read_json(\"dataset/lmsys-chatbot_arena_conversations-33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4ea73-9ce7-4be2-97b9-9d7b7e23319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.drop(columns = ['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac00263-f6e8-4e9f-bc76-c38ca147433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tmp,tmp2]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a47b-4730-42d0-addf-a753c40e499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87799cfd-2202-4cf7-b8f5-3440402a0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8c8a5-537c-4bbc-906d-0248a7cd8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[46969][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5501c-3b89-4305-af30-145af6105739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tmp = tmp[tmp['prompt'].apply(lambda x: is_english(x[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91e910-3568-4040-879c-7a5de5898e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812975-88eb-4906-8b49-20acf0219e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397612b-9c86-4952-9d77-827e64a83f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.read_csv(\"dataset/kaggle-ultrafeedback-drop-duplicate.csv\")\n",
    "tie = pd.read_csv(\"dataset/kaggle-ultrafeedback-ties-drop-duplicate.csv\")\n",
    "p = pd.read_csv(\"dataset/ultrafeedback_prediction.csv\")\n",
    "\n",
    "from utils import load_json\n",
    "ex = load_json(ex)\n",
    "tie = load_json(tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfe20a-8a72-4954-88f7-2965c2a47c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([tie,ex]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf4c04-5ffe-4397-9feb-926a8decdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fb5a9-0a61-4f0a-bb23-3c7a8777294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.rename(columns = {'winner_model_a':\"p_winner_model_a\", 'winner_model_b':\"p_winner_model_b\",  'winner_tie':\"p_winner_tie\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c73849-7179-4356-a75b-655e6edf1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([total, p], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdc1d3-9ef3-400f-80f6-c581a75865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9eccb-3d7a-44d6-9ecb-1367c6c0a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_label(row):\n",
    "    a = row.p_winner_model_a\n",
    "    b = row.p_winner_model_b\n",
    "    c = row.p_winner_tie\n",
    "\n",
    "    l = [a ,b, c]\n",
    "    label = l.index(max(l))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b94fa-0da9-429e-b5ea-cc3f79d919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['p_label'] = final.apply(get_p_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a4b32-8e0e-4344-99f5-64842e12798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]\n",
    "\n",
    "final['label'] = final.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b29ace-02a7-4eb9-95e1-839d8412bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = final.loc[final.p_label == final.label,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f23955-a534-4b0c-a550-e6e7ea842d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "filter_list = (filter.p_winner_model_a >= threshold) | (filter.p_winner_model_b >= threshold) | (filter.p_winner_tie >= threshold)\n",
    "filter = filter.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7f45c-eed3-4cc9-b9f8-59f236e35fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.prompt.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18a8d9-5420-420c-aa39-d0542014f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "filter_only_english = filter[filter['prompt'].apply(lambda x: is_english(x[0][:30]))].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaacf40-33eb-43ac-8b5d-a39364789553",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "filter[save_columns].to_json(f\"dataset/70k_filter_threshold{threshold}.json\", index = False)\n",
    "filter_only_english[save_columns].to_json(f\"dataset/70k_filter_only_english_threshold{threshold}.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c837a-49ed-4aa7-a593-1386f142b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter[save_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fb069-98e8-4026-9281-e8c77a6dd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fe057-4069-4291-8c21-adc21bffdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/train.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534beaf2-5d64-4675-a1c1-ff69334ed34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12e930-77fa-43c6-ab43-b0de8cadd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7b1b8-ef82-492e-b540-cc6343ab677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f42ec-4288-4707-9b8d-68d399e157ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.label.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdd206-f405-436c-b427-fd29134d55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/70k_filter_only_english_threshold0.9.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c2706-3696-4791-9148-ee20edf6135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2dbdf-6617-4efe-a881-f11e242bd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_least_similar_by_prompt_same_prediction_thr90.csv\"\n",
    "t = pd.read_csv(data_path)\n",
    "t['id'] = [randint(10000,99999) + i for i in range(len(t))]\n",
    "t.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d61e42-5510-4791-8292-3984e426b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_most_similar_by_prompt_same_prediction_thr90.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446a850-aa64-4fa1-81f8-afc92ce27a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb349e04-4248-40c4-9d75-eef94ab775d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , valid = load_split_data('dataset/train_sample10k_switch.json', 2, 2300, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4ceac-a77e-46a3-b273-a339ec57c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train.id.to_list()\n",
    "valid_id = valid.id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04567f8-98b7-447d-ac2f-67bb651eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd7bce-7769-4260-bdee-254ec7b07893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_str'] = data['prompt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc917-3fa5-4b36-aabb-1da1a98e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504410a3-6bc6-4230-bb9f-faaeec30082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb12d2-614f-4a99-b213-024431dc6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)]\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc7c15-0733-40b8-8e61-9f2119442d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data.id.isin(train_id)].reset_index(drop = True)\n",
    "valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b5924-8905-4a00-bac5-304ab7300b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in train_id if i in valid_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983324e4-e2d6-488a-9786-dca934f54122",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638216d1-f0ed-47c4-ac1b-9757b62ad911",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json('dataset/train_sample10k_switch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6110b-1ac8-47fc-9f5f-1b91141b2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd71b88-1a0c-497e-9f7c-011856dc4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = [['I read 60 pages of a book on Monday and 1/4 of the book on Tuesday. I completed the remaining 1/8 of the book on Wednesday. How many total pages are in the book?']]\n",
    "train.loc[train.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8475c-9524-440e-865c-671668b261ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.loc[valid.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb115c-369b-4d3b-a7fe-ac84c8a48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15847f0d-36c6-4a64-ae1b-813397cd2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in train.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8493bdb-b140-49f7-8494-c4b96085e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e90e88-23e3-4d49-867b-af17f6cbedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)\n",
    "valid_id = valid.id.tolist()\n",
    "train_id = train.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49777e8-68b2-4b66-a557-f95a377b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22529285-1ddf-4b23-a168-6271c96f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.loc[data.id.isin(train_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e9ca6-696c-42aa-ae26-2b76b12938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.sample(10000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42cbb8-c0f3-4001-902c-934186926d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_id = s.id.to_list()\n",
    "len([i for i in s_id if i in valid_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a8d38-9126-47d4-b39c-e2d87971b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)\n",
    "[i for i in s.prompt.values.tolist() if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f585cc1-d017-49ec-9ed8-7fbd25e4715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35115fa6-eaad-4f2a-a4b7-9ad7097460dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(tmp_valid.prompt.values.tolist()) if i in ex_33.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037325e-acb4-4e3c-ae0a-b9fdb72122a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid = tmp_valid.iloc[idx,:].reset_index(drop = True)\n",
    "not_same_prompt_in_valid = tmp_valid.iloc[~tmp_valid.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5609a2-b86f-4e6e-a83d-db86707c660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same_prompt_in_valid) + len(same_prompt_in_valid) == len(tmp_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649893d-532a-4df3-a4b5-b2e2721ee2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid.to_json(\"dataset/same_prompt_in_valid.json\", index = False)\n",
    "not_same_prompt_in_valid.to_json(\"dataset/not_same_prompt_in_valid.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee8612-2347-4d97-9486-48081621594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid.sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74c85f-e114-48a2-ab85-053bfe33c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ex = [idx for idx, i in enumerate(ex_33.prompt.values.tolist()) if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddc907-3387-4442-8ace-47f4a9e95f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33.iloc[idx_ex,:].reset_index(drop = True).sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e6673-b2d7-4e85-aa0d-9c3ebe87c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/pass/demo_A2B2C.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d0244-ab36-45e0-9e06-f1aef01623cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.sample(int(len(data) * 0.3)).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582e3d0-3077-4df1-93f3-df37d0e6f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb1a57-d15e-4597-b365-9c3af9858464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(row):\n",
    "    response_a = row.response_a\n",
    "    response_b = row.response_b\n",
    "\n",
    "    row.response_a = response_b\n",
    "    row.response_b = response_a\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4db282-2500-4d51-abd8-98925acf4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884260e-980b-4f63-be50-367369c53edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([s, data]).reset_index(drop = True)\n",
    "final['id'] = [randint(1000,999999) + i for i in range(len(final))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd823e94-95bc-47b0-9d64-2e9107b23c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "final.to_json(f\"dataset/pass/demo_A2B2C_tta.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00951469-3ca1-4a55-8f43-ba30b95ea820",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/train_sample10k_switch.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae7b3e-d15e-46ae-9f46-d6a2b851fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/pass/demo_A2B2C_tta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91f56f-a43d-4a37-a4e3-6eba8f7ee83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46094679-24f9-41ac-a917-af37289e4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check.prompt.values[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265b4e-9874-40b1-8611-80304241826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a == t.response_b, 'winner_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bd58e-be57-4494-b225-eab3b8ced348",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a=='[\"Hyderabad\"]', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573737e-3527-4eee-8435-85fa3fe5369a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == '[null]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cd37c-f776-42fb-b032-b316ece6721b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b) & (t.winner_tie != 1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de252b78-4025-4231-a709-c3e274a0f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223df7-9d38-4b76-905a-ae3e82fc9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[3844:3847,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f59df-7447-42d1-a7d7-8fd6b1d399c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d8b99-84b5-441e-81ae-cef57508556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)\n",
    "\n",
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0eea3-cd5c-4858-a913-b3d6cfc2fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、找出train里面不与33k重复部分\n",
    "2、不重复的部分再划分\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dae53d-5ce4-4e73-9d82-6c0877c50813",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in data.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "data['set_prompt_response'] = set_prompt_response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283dda44-0b15-4663-a42f-01d7122095db",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in ex_33.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "ex_33['set_prompt_response'] = set_prompt_response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36347ed-529c-4d49-8a73-1a0b412cd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(data.set_prompt_response.values) if i in ex_33.set_prompt_response.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed483b00-71b3-41fa-b106-90597b1bbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = data.loc[idx,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fee23-1f22-448a-9530-58b4756ae0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33.loc[ex_33.set_prompt_response == same.set_prompt_response.values[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad992f3d-4056-46ca-94ba-bd8a19a49030",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_same = data.loc[~data.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3841c21-c1dd-4db4-844b-8021376141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc368b-8af0-4980-8f57-2eb6ef4207bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in ex_33.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e9cde-27fe-4de4-845b-63a6ebf7ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636297d2-367c-4c15-9971-7e61b92a8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sets = not_same['set_prompt_response'].drop_duplicates().reset_index(drop=True)\n",
    "# 将唯一集合进行随机划分\n",
    "unique_sets = unique_sets.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "midpoint = len(unique_sets) // 10\n",
    "set1 = unique_sets.iloc[:midpoint]\n",
    "set2 = unique_sets.iloc[midpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f86bff-f5d2-47fc-be6a-61223fe80893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分结果从原数据集中提取对应的行\n",
    "valid = not_same[not_same['set_prompt_response'].isin(set1)].reset_index(drop=True)\n",
    "train_subset = not_same[not_same['set_prompt_response'].isin(set2)].reset_index(drop=True)\n",
    "assert len(valid) + len(train_subset) == len(not_same)\n",
    "assert len(valid) + len(train_subset) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89953790-8cbc-43de-918a-a01a93d00290",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3820ec6-5b66-4e09-8864-cee95db0d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587ad10-5f15-427b-a4dc-4062b111453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exclude_valid = pd.concat([train_subset, same]).reset_index(drop=True) #train 里面排除valid\n",
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836e690-eeab-45e0-8d53-8232e707b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(valid) + len(train_exclude_valid) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d058d-08ef-46bf-bf62-4d8a7f4b0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.concat([train_subset, ex_33]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae603b-b74f-4b7e-935b-bc695803ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train.drop(columns = ['set_prompt_response'])\n",
    "valid = valid.drop(columns = ['set_prompt_response'])\n",
    "train_exclude_valid = train_exclude_valid.drop(columns = ['set_prompt_response'])\n",
    "train_33k = train_33k.drop(columns = ['set_prompt_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45f9eb-364b-4b48-98d2-69da13e3c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_json(\"dataset/non_overlap/train_subset.json\", index = False)\n",
    "valid.to_json(\"dataset/non_overlap/valid.json\", index = False)\n",
    "train_exclude_valid.to_json(\"dataset/non_overlap/train_exclude_valid.json\", index = False)\n",
    "train_33k.to_json(\"dataset/non_overlap/train_33k.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011da0b-5683-46e8-819b-fcd2dd9d09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查\n",
    "train_subset = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "valid = pd.read_json(\"dataset/non_overlap/valid.json\")\n",
    "train_exclude_valid = pd.read_json(\"dataset/non_overlap/train_exclude_valid.json\")\n",
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec1423-87a3-4c6a-85fb-10023d83333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9c632-6445-477e-8852-dade97bcf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = get_set_prompt_response(train_subset)\n",
    "valid = get_set_prompt_response(valid)\n",
    "train_exclude_valid = get_set_prompt_response(train_exclude_valid)\n",
    "train_33k = get_set_prompt_response(train_33k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32be80f-adf4-488d-b854-9a20bc7733b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid和任何都不重合\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_33k.set_prompt_response.values]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fccd76-c374-4c6e-bc07-197e164c6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d8c0f-5898-42a9-88b6-69f43d84e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取唯一的 prompt 进行划分\n",
    "not_same['prompt_str'] = not_same['prompt'].astype(str)\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)\n",
    "\n",
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)\n",
    "\n",
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)].reset_index(drop = True)\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)].reset_index(drop = True)\n",
    "train = train.drop(columns = ['prompt_str'])\n",
    "valid = valid.drop(columns = ['prompt_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108dda8f-3443-4d3a-ae13-a4cb31e59938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc66039-5fa5-4d94-bdbf-431bd5596571",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = train_33k.sample(15000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906dd20-c569-4b93-93b5-52524dbdc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792de98-379d-4ec9-a4a2-67a6e7aa8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94fd1f-fd7c-48cc-9c01-462a96025e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/non_overlap/train_33k_switch_15k.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2b1c0-8e98-4138-98fb-1c7f86008f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19d9d3-cbf8-4d62-9568-835f19ecd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = get_set_prompt_response(valid)\n",
    "s = get_set_prompt_response(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a3beb-b4de-4b51-8fe5-ef0056ad5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k.loc[train_33k.response_b.isin([['Three times 78234 is 234,692.']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128df92c-683f-4631-ae36-2c0d822ba14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in s.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cd086-c826-4b73-ac78-1adf1d11088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(\"dataset/non_overlap/train_33k_switch_15k.json\").response_a.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e5d90-4823-4e6b-98cb-92c239172f02",
   "metadata": {},
   "source": [
    "# prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3bf91ddf-914b-435a-bb59-b97c4e63ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_2(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        id = row['id']\n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            text_length += len(text.split(\" \"))\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = prompt_response[-1] + \"\\n\\n\" + text\n",
    "                prompt_response[-1] = text\n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = len(text.split(\" \"))\n",
    "                ids.append(id)\n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels})\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response})\n",
    "    return data\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "215dbe8e-423b-4e3c-9302-fe2ab2fa78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "if_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a89a02f-2d29-480b-b197-0c247ab1e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate prompt-response\n",
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)\n",
    "\n",
    "#prepare label\n",
    "if if_train:\n",
    "    data['label'] = data.apply(lambda x: get_label(x), axis = 1)\n",
    "\n",
    "data = data.fillna('None')\n",
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c1cb0aa-f5ca-4ce0-8959-dacd23597a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "955bbbac-6da7-4832-a200-84f4783260d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>#Prompt\\nIs it morally right to try to have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>OK, does pineapple belong on a pizza? Relax an...</td>\n",
       "      <td>Ah, the age-old culinary conundrum that has di...</td>\n",
       "      <td>As an AI, I don't eat, so I don't have persona...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>#Prompt\\nOK, does pineapple belong on a pizza?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>#Prompt\\nWhat is the difference between marria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>How can I get both of them as quick as possibl...</td>\n",
       "      <td>If you want to get both a marriage license and...</td>\n",
       "      <td>In California, here are the general steps to o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>#Prompt\\nHow can I get both of them as quick a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the minimal time to get them? 1 day or...</td>\n",
       "      <td>The minimal time to get a marriage license and...</td>\n",
       "      <td>The marriage license in California is issued i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>#Prompt\\nWhat is the minimal time to get them?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55740</th>\n",
       "      <td>4294602932</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Harry Potter</td>\n",
       "      <td>*clears throat and adjusts imaginary glasses* ...</td>\n",
       "      <td>Hello! Not to be rude or anything, but who mig...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>#Prompt\\nHarry Potter\\n\\n#Response\\n##Model A\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55741</th>\n",
       "      <td>4294633312</td>\n",
       "      <td>pplx-7b-online</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>abc</td>\n",
       "      <td>It seems like you're referring to the Californ...</td>\n",
       "      <td>Hello! It seems like you've typed \"abc.\" How m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>#Prompt\\nabc\\n\\n#Response\\n##Model A\\nIt seems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55742</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>In python, implement a naive Bayes with gaussi...</td>\n",
       "      <td>Here is an implementation of a naive Bayes cla...</td>\n",
       "      <td>Sure! Here's an implementation of a naive Baye...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>#Prompt\\nIn python, implement a naive Bayes wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55743</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>If a bait contains 0,0025% bromadiolon then ho...</td>\n",
       "      <td>Bromadiolone is a rodenticide which is most of...</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>#Prompt\\nIf a bait contains 0,0025% bromadiolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55744</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>three kids eat three apples in three days, how...</td>\n",
       "      <td>27 apples</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>#Prompt\\nthree kids eat three apples in three ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55745 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a             model_b  \\\n",
       "0           30192  gpt-4-1106-preview          gpt-4-0613   \n",
       "1           30192  gpt-4-1106-preview          gpt-4-0613   \n",
       "2           53567           koala-13b          gpt-4-0613   \n",
       "3           53567           koala-13b          gpt-4-0613   \n",
       "4           53567           koala-13b          gpt-4-0613   \n",
       "...           ...                 ...                 ...   \n",
       "55740  4294602932          claude-2.1  gpt-4-1106-preview   \n",
       "55741  4294633312      pplx-7b-online          gpt-4-0613   \n",
       "55742  4294692063          claude-2.0    llama-2-13b-chat   \n",
       "55743  4294899228              palm-2      tulu-2-dpo-70b   \n",
       "55744  4294947231  gemini-pro-dev-api  gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      Is it morally right to try to have a certain p...   \n",
       "1      OK, does pineapple belong on a pizza? Relax an...   \n",
       "2      What is the difference between marriage licens...   \n",
       "3      How can I get both of them as quick as possibl...   \n",
       "4      What is the minimal time to get them? 1 day or...   \n",
       "...                                                  ...   \n",
       "55740                                       Harry Potter   \n",
       "55741                                                abc   \n",
       "55742  In python, implement a naive Bayes with gaussi...   \n",
       "55743  If a bait contains 0,0025% bromadiolon then ho...   \n",
       "55744  three kids eat three apples in three days, how...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      The question of whether it is morally right to...   \n",
       "1      Ah, the age-old culinary conundrum that has di...   \n",
       "2      A marriage license is a legal document that al...   \n",
       "3      If you want to get both a marriage license and...   \n",
       "4      The minimal time to get a marriage license and...   \n",
       "...                                                  ...   \n",
       "55740  *clears throat and adjusts imaginary glasses* ...   \n",
       "55741  It seems like you're referring to the Californ...   \n",
       "55742  Here is an implementation of a naive Bayes cla...   \n",
       "55743  Bromadiolone is a rodenticide which is most of...   \n",
       "55744                                          27 apples   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      As an AI, I don't have personal beliefs or opi...               1   \n",
       "1      As an AI, I don't eat, so I don't have persona...               1   \n",
       "2      A marriage license and a marriage certificate ...               0   \n",
       "3      In California, here are the general steps to o...               0   \n",
       "4      The marriage license in California is issued i...               0   \n",
       "...                                                  ...             ...   \n",
       "55740  Hello! Not to be rude or anything, but who mig...               0   \n",
       "55741  Hello! It seems like you've typed \"abc.\" How m...               1   \n",
       "55742  Sure! Here's an implementation of a naive Baye...               1   \n",
       "55743  As an AI language model, I do not promote or c...               0   \n",
       "55744  If three kids eat three apples in three days, ...               1   \n",
       "\n",
       "       winner_model_b  winner_tie label  \\\n",
       "0                   0           0     A   \n",
       "1                   0           0     A   \n",
       "2                   1           0     B   \n",
       "3                   1           0     B   \n",
       "4                   1           0     B   \n",
       "...               ...         ...   ...   \n",
       "55740               1           0     B   \n",
       "55741               0           0     A   \n",
       "55742               0           0     A   \n",
       "55743               1           0     B   \n",
       "55744               0           0     A   \n",
       "\n",
       "                                         prompt_response  \n",
       "0      #Prompt\\nIs it morally right to try to have a ...  \n",
       "1      #Prompt\\nOK, does pineapple belong on a pizza?...  \n",
       "2      #Prompt\\nWhat is the difference between marria...  \n",
       "3      #Prompt\\nHow can I get both of them as quick a...  \n",
       "4      #Prompt\\nWhat is the minimal time to get them?...  \n",
       "...                                                  ...  \n",
       "55740  #Prompt\\nHarry Potter\\n\\n#Response\\n##Model A\\...  \n",
       "55741  #Prompt\\nabc\\n\\n#Response\\n##Model A\\nIt seems...  \n",
       "55742  #Prompt\\nIn python, implement a naive Bayes wi...  \n",
       "55743  #Prompt\\nIf a bait contains 0,0025% bromadiolo...  \n",
       "55744  #Prompt\\nthree kids eat three apples in three ...  \n",
       "\n",
       "[55745 rows x 11 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0f9d6f7-4ee6-46cf-a40e-25ef5778f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "反转dataframe\n",
    "用栈，先进后出，超过max length就清空\n",
    "'''\n",
    "def prompt_3(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    从后往前拼接\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "    data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        id = row['id']\n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            text_length += len(text.split(\" \"))\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = text + \"\\n\\n\" + prompt_response[-1]\n",
    "                prompt_response[-1] = text\n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = len(text.split(\" \"))\n",
    "                ids.append(id)\n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46bc045e-ed87-4249-9656-3341119b9383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55745/55745 [00:14<00:00, 3827.08it/s]\n",
      "100%|██████████| 55745/55745 [00:14<00:00, 3743.99it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt3 = prompt_3(data, 1900, True)\n",
    "prompt2 = prompt_2(data, 1900, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451e865-2414-4967-bed3-6c0b02016626",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05a5aa7f-e372-4393-9d71-31f8215cf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_p3 = prompt3.loc[prompt3.id == 2846599172]\n",
    "#cehck_data = data.loc[data.id == 2846599172]\n",
    "\n",
    "check_p2 = prompt2.loc[prompt3.id == 2846599172]\n",
    "#cehck_data = data.loc[data.id == 2846599172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f4a2b-77ec-49b9-a3ea-11ac0eb01e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cehck_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79a2a4-2ef9-4716-ba63-214b5bf2877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_p3.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d7b64-b3cf-443d-9739-5f3e6322d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_p3.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb892701-03be-46ac-9361-d2bbd709e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt3.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d32670-3e6a-48df-8bf0-8d7afdc4dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt3.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54435ff-df68-405c-9c54-4769b0c0e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17463bf-671d-4e1c-b263-6ffd805226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "604688c1-8056-43ac-9ca6-5873b3c4e095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30155     555\n",
       "30156    1767\n",
       "30157    1780\n",
       "30158    1359\n",
       "30159    1312\n",
       "30160    1629\n",
       "30161    1374\n",
       "30162    1827\n",
       "Name: prompt_response, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_p3.prompt_response.apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e632247-410f-4819-b0a8-91d982e03e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30155    1703\n",
       "30156    1771\n",
       "30157    1286\n",
       "30158    1344\n",
       "30159    1734\n",
       "30160    1215\n",
       "30161    1390\n",
       "30162    1160\n",
       "Name: prompt_response, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_p2.prompt_response.apply(lambda x:len(x.split(\" \")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
