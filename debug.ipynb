{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4301579c-9b27-4180-96c4-d7d921bdb3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from random import random, randint\n",
    "from utils import load_json, load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa143e6b-b246-4240-b2cd-a47127b66d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_data = './dataset/demo_train.csv'\n",
    "    MAX_INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8663-a48b-4484-95e6-030f2b06bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(args.train_data).reset_index(drop = True)\n",
    "#df_valid = pd.read_csv(args.valid_data).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96b93e-d2a1-4d19-b9b3-e507723d7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34566812-f99a-48b9-bcd7-051a4cff8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8dfb-4b8f-41e3-aa6a-c35ed2e20497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4245f-0814-4e75-b331-d1f1dd74acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['prompt'] ] * 2\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in ['response_a','response_b']]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='longest_first', \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f1e96-9cf9-4039-83ad-4f34bb69643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example['response_a'] + \" [SEP]\" +  \" #### \" + example['prompt'] + \" [SEP] \" + example['response_b'] + \" [SEP]\"]\n",
    "    tokenized_example = tokenizer(sentences, truncation=True, \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e1b3-d2fe-4c4d-ae98-401615cb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df_train)\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcd2e8-74f0-4918-98d5-4790cf54bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7921b57-ffd9-432d-a200-3ef4d64aa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b'])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871078b7-fc9f-4d8f-aa1a-afaefb54ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e662d-18dc-4bb6-8004-feb62a45800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cd8f4-89f1-4119-ba28-20d748dbf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb1a5-81e0-4aec-811f-4266c1091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:1000,].reset_index(drop = True).to_csv('demo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff107e9b-505b-4a35-b371-abc989431e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[1000:1200,].reset_index(drop = True).to_csv('demo_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdb18f-3bd3-4da0-9a92-dd0a6379ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice, AutoModelForSequenceClassification, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703200-17d7-4dba-b1f5-4930041f30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'meta-llama/llama-3-transformers-8b-hf-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eee09-f821-4697-bfe0-052896b9595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<pad>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e199e-c8fb-4235-a8be-b6588c43a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "128256 in tokenizer(\"<pad>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2e05f-33ec-4fe2-b480-c559c688b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c6d1-ef34-49b9-946f-1546054b097a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513d894-9d5a-456a-9156-0d80c4a33cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# config.hidden_dropout_prob = args.dropout_rate\n",
    "# config.attention_probs_dropout_prob = args.dropout_rate\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "#     inference_mode=False,\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias = 'none',\n",
    "#     target_modules=[\"q_proj\",\"k_proj\",\"v_proj\"]  # Target specific modules\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ae33e-53db-4e13-ab78-324866c4a071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.state_dict():\n",
    "        print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810429ba-c85b-43c7-a55a-843629551fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133fe9-2ac5-430c-80ee-e4b1c06c8751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914da54-a43e-4e44-a575-75265d875359",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.dtype for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d21cd-15e4-480b-b786-b8027c511b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e38681-9f85-423b-848e-b0a888249ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/1k_mt_bench_human_judgments.json', 1, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c925c-5c5e-4680-ab26-5f1bdbf90cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/lmsys-chatbot_arena_conversations-33k.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f96254-d439-4d83-9c2f-8fb7f3f67968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569eb7b-292b-4ab8-bbfb-6cc66f159a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369f833-3ecb-4ba9-80ca-9d373596e882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "prompt_response = df_train.loc[idx,'prompt_response']\n",
    "label = df_train.loc[idx,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36874c67-b6ab-4415-86d7-89a1d2b81e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_response)\n",
    "print(\"\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610e855-5fa7-4a26-85c3-11f9cc69a3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5a0df-a66b-49a9-9531-3e66aca3f001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([1,\n",
    " 32006,\n",
    " 887,\n",
    " 526])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec7fee-0823-458a-94a5-cd8fb24d734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd68316-0e01-4fc4-8f76-e5b62da4cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('<|system|>\\nYou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a28b7-ac2b-4bbc-9b48-6eeb7c7253ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('Apple\\nBa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96200af2-961a-4d23-a0f4-99d317f17889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([396,\n",
    " 18571,\n",
    " 415,\n",
    " 13,\n",
    " 4548,\n",
    " 7420,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6808dc-9877-4d5f-a3d4-798c49009e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([29933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece7e34-75cf-4d86-9e39-3a17f463b2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(templete_part1 + prompt_response + templete_part2 + templete_part3 + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f43ec6-c8e9-47c9-98d4-0c1a715a3db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templete_part1 = \"<|system|>\\nYou are a helpful assistant good at judging conversations.<|end|>\\n<|user|>\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "templete_part3 = \"<|assistant|>\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids'][1:]\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92cb47-4478-4597-a027-9662c47c7f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Apple\"\n",
    "prompt_response = templete_part1 + text + templete_part2 + templete_part3 + label + tokenizer.eos_token\n",
    "print(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff6eef-20e1-4df6-b415-7e614fa8066f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'microsoft/LLM-Research/Phi-3-mini-4k-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d64949-df75-4c8d-9b3e-41b60c220736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b820-f8d4-4eac-835f-bef80e20fd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13130933-64c5-4d13-ba8f-3ad126a0ecbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0c18-8a90-4077-8451-aee573084dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70aa3-6a54-4099-8625-1bf211e3b613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a00c5-2dc1-4942-bd80-58101d6eef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15f353-3c10-412f-9d4d-a9c6832d8f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519312-0c1c-4e21-8526-29f562ed0e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faccc94-8a02-434e-a0ca-99dbe8bf4db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('<|user|>',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9affb58-cf74-4b77-a743-00d3cb6f7a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AutoModelForCausalLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8039867-2794-42d5-9fd6-90e7073be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f49e-457b-4050-97fc-c0b6746b2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767040-e7e4-4fb6-a4ec-79cea4150a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete_part1 = \"<|im_start|>system\\nYou are a helpful assistant good at judging conversations.<|im_end|>\\n<|im_start|>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|im_end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids']\n",
    "#print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "templete_part3 = \"<|im_start|>assistant\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids']\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b518309-3e5d-4351-bc8e-cc28a1cebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(14374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba6b18-5775-445a-ab14-1a80cc6ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token,tokenizer.eos_token,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd0f3-6d2d-4f8a-9880-60fbc84c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3adf3-efa3-4add-bbfb-bd6aaf262584",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen2-7B-Instruct'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "                                             config=config,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6626eb-0734-4649-bed8-87e0e5f4d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d36ad-0414-420b-8b31-cada77b616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")\n",
    "#tmp2 = pd.read_json(\"dataset/lmsys-chatbot_arena_conversations-33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4ea73-9ce7-4be2-97b9-9d7b7e23319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.drop(columns = ['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac00263-f6e8-4e9f-bc76-c38ca147433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tmp,tmp2]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a47b-4730-42d0-addf-a753c40e499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87799cfd-2202-4cf7-b8f5-3440402a0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8c8a5-537c-4bbc-906d-0248a7cd8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[46969][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5501c-3b89-4305-af30-145af6105739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tmp = tmp[tmp['prompt'].apply(lambda x: is_english(x[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91e910-3568-4040-879c-7a5de5898e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812975-88eb-4906-8b49-20acf0219e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397612b-9c86-4952-9d77-827e64a83f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.read_csv(\"dataset/kaggle-ultrafeedback-drop-duplicate.csv\")\n",
    "tie = pd.read_csv(\"dataset/kaggle-ultrafeedback-ties-drop-duplicate.csv\")\n",
    "p = pd.read_csv(\"dataset/ultrafeedback_prediction.csv\")\n",
    "\n",
    "from utils import load_json\n",
    "ex = load_json(ex)\n",
    "tie = load_json(tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfe20a-8a72-4954-88f7-2965c2a47c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([tie,ex]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf4c04-5ffe-4397-9feb-926a8decdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fb5a9-0a61-4f0a-bb23-3c7a8777294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.rename(columns = {'winner_model_a':\"p_winner_model_a\", 'winner_model_b':\"p_winner_model_b\",  'winner_tie':\"p_winner_tie\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c73849-7179-4356-a75b-655e6edf1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([total, p], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdc1d3-9ef3-400f-80f6-c581a75865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9eccb-3d7a-44d6-9ecb-1367c6c0a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_label(row):\n",
    "    a = row.p_winner_model_a\n",
    "    b = row.p_winner_model_b\n",
    "    c = row.p_winner_tie\n",
    "\n",
    "    l = [a ,b, c]\n",
    "    label = l.index(max(l))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b94fa-0da9-429e-b5ea-cc3f79d919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['p_label'] = final.apply(get_p_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a4b32-8e0e-4344-99f5-64842e12798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]\n",
    "\n",
    "final['label'] = final.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b29ace-02a7-4eb9-95e1-839d8412bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = final.loc[final.p_label == final.label,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f23955-a534-4b0c-a550-e6e7ea842d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "filter_list = (filter.p_winner_model_a >= threshold) | (filter.p_winner_model_b >= threshold) | (filter.p_winner_tie >= threshold)\n",
    "filter = filter.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7f45c-eed3-4cc9-b9f8-59f236e35fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.prompt.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18a8d9-5420-420c-aa39-d0542014f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "filter_only_english = filter[filter['prompt'].apply(lambda x: is_english(x[0][:30]))].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaacf40-33eb-43ac-8b5d-a39364789553",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "filter[save_columns].to_json(f\"dataset/70k_filter_threshold{threshold}.json\", index = False)\n",
    "filter_only_english[save_columns].to_json(f\"dataset/70k_filter_only_english_threshold{threshold}.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c837a-49ed-4aa7-a593-1386f142b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter[save_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fb069-98e8-4026-9281-e8c77a6dd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fe057-4069-4291-8c21-adc21bffdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/train.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534beaf2-5d64-4675-a1c1-ff69334ed34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12e930-77fa-43c6-ab43-b0de8cadd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7b1b8-ef82-492e-b540-cc6343ab677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f42ec-4288-4707-9b8d-68d399e157ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.label.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdd206-f405-436c-b427-fd29134d55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/70k_filter_only_english_threshold0.9.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c2706-3696-4791-9148-ee20edf6135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2dbdf-6617-4efe-a881-f11e242bd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_least_similar_by_prompt_same_prediction_thr90.csv\"\n",
    "t = pd.read_csv(data_path)\n",
    "t['id'] = [randint(10000,99999) + i for i in range(len(t))]\n",
    "t.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d61e42-5510-4791-8292-3984e426b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_most_similar_by_prompt_same_prediction_thr90.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d446a850-aa64-4fa1-81f8-afc92ce27a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67962/67962 [00:20<00:00, 3383.06it/s]\n",
      "100%|██████████| 3552/3552 [00:00<00:00, 13385.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb349e04-4248-40c4-9d75-eef94ab775d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12423/12423 [00:01<00:00, 9760.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train , valid = load_split_data('dataset/train_sample10k_switch.json', 2, 2300, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4ceac-a77e-46a3-b273-a339ec57c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train.id.to_list()\n",
    "valid_id = valid.id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04567f8-98b7-447d-ac2f-67bb651eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd7bce-7769-4260-bdee-254ec7b07893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_str'] = data['prompt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc917-3fa5-4b36-aabb-1da1a98e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504410a3-6bc6-4230-bb9f-faaeec30082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb12d2-614f-4a99-b213-024431dc6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)]\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc7c15-0733-40b8-8e61-9f2119442d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data.id.isin(train_id)].reset_index(drop = True)\n",
    "valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b5924-8905-4a00-bac5-304ab7300b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in train_id if i in valid_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983324e4-e2d6-488a-9786-dca934f54122",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638216d1-f0ed-47c4-ac1b-9757b62ad911",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json('dataset/train_sample10k_switch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6110b-1ac8-47fc-9f5f-1b91141b2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd71b88-1a0c-497e-9f7c-011856dc4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = [['I read 60 pages of a book on Monday and 1/4 of the book on Tuesday. I completed the remaining 1/8 of the book on Wednesday. How many total pages are in the book?']]\n",
    "train.loc[train.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8475c-9524-440e-865c-671668b261ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.loc[valid.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb115c-369b-4d3b-a7fe-ac84c8a48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15847f0d-36c6-4a64-ae1b-813397cd2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in train.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8493bdb-b140-49f7-8494-c4b96085e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11e90e88-23e3-4d49-867b-af17f6cbedcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67962/67962 [00:20<00:00, 3374.38it/s]\n",
      "100%|██████████| 3552/3552 [00:00<00:00, 13074.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)\n",
    "valid_id = valid.id.tolist()\n",
    "train_id = train.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e49777e8-68b2-4b66-a557-f95a377b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22529285-1ddf-4b23-a168-6271c96f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.loc[data.id.isin(train_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "725e9ca6-696c-42aa-ae26-2b76b12938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.sample(10000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c42cbb8-c0f3-4001-902c-934186926d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_id = s.id.to_list()\n",
    "len([i for i in s_id if i in valid_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a8d38-9126-47d4-b39c-e2d87971b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)\n",
    "[i for i in s.prompt.values.tolist() if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5f585cc1-d017-49ec-9ed8-7fbd25e4715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "35115fa6-eaad-4f2a-a4b7-9ad7097460dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(tmp_valid.prompt.values.tolist()) if i in ex_33.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6037325e-acb4-4e3c-ae0a-b9fdb72122a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid = tmp_valid.iloc[idx,:].reset_index(drop = True)\n",
    "not_same_prompt_in_valid = tmp_valid.iloc[~tmp_valid.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f5609a2-b86f-4e6e-a83d-db86707c660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same_prompt_in_valid) + len(same_prompt_in_valid) == len(tmp_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1649893d-532a-4df3-a4b5-b2e2721ee2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid.to_json(\"dataset/same_prompt_in_valid.json\", index = False)\n",
    "not_same_prompt_in_valid.to_json(\"dataset/not_same_prompt_in_valid.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "35ee8612-2347-4d97-9486-48081621594b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>3434854914</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>[\\n\\n.. / .-.. .. -.- . / -.-- --- ..- / ---.....</td>\n",
       "      <td>[This is a character map for the IBM Selectric...</td>\n",
       "      <td>[Your Morse code message translates to: \"I LIK...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2463216319</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>[\\n### Instructions:\\nDecide what should answe...</td>\n",
       "      <td>[Bob should answer:\\n\\nHour is out of correct ...</td>\n",
       "      <td>[Bob means that the date and time range given ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2622512543</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>[\\npoint out  the typora.\\n\\n      \\caption{ N...</td>\n",
       "      <td>[The typora is the text that is being generate...</td>\n",
       "      <td>[The typora refers to the table in the text th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3931418201</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>[ Five people were eating apples, A finished b...</td>\n",
       "      <td>[Based on the information provided, we can det...</td>\n",
       "      <td>[Let's break down the information given:\\n\\n1....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2382196251</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>[\"But we can also hack these reward centers fo...</td>\n",
       "      <td>[Humans and other animals can hack their rewar...</td>\n",
       "      <td>[Play is an essential aspect of the human and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1348660373</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>[write the lyrics of a taylor swift song about...</td>\n",
       "      <td>[I'm sorry, but I cannot write lyrics to a son...</td>\n",
       "      <td>[Verse 1:\\nI was running late for work one day...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2318149804</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>llama-13b</td>\n",
       "      <td>[you are a world class investment analyst work...</td>\n",
       "      <td>[As a language model, I don't have personal op...</td>\n",
       "      <td>[Here are some sectors that are ripe for a rol...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>900774276</td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[you are tasked with taking a question, or lis...</td>\n",
       "      <td>[You can pay cash into your account by using a...</td>\n",
       "      <td>[{\"sample\": \"Can you make a bank transaction i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2570827944</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>[“This core competency enables Foo to perform ...</td>\n",
       "      <td>[1. Diverse range of abilities\\n2. Multifacete...</td>\n",
       "      <td>[An array of functions can be phrased in sever...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>400140059</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[•\\tTo solve math problems, you should use the...</td>\n",
       "      <td>[10/5 + 2 \\* 2 \\* 2 = (10 / 5) + (2 \\* 2 \\* 2)...</td>\n",
       "      <td>[Using PEMDAS, we need to do multiplication be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id           model_a             model_b  \\\n",
       "346  3434854914         koala-13b          gpt-4-0314   \n",
       "250  2463216319  claude-instant-1           vicuna-7b   \n",
       "273  2622512543        vicuna-13b           vicuna-7b   \n",
       "394  3931418201        vicuna-33b         yi-34b-chat   \n",
       "243  2382196251        alpaca-13b         mpt-7b-chat   \n",
       "..          ...               ...                 ...   \n",
       "143  1348660373    fastchat-t5-3b    RWKV-4-Raven-14B   \n",
       "238  2318149804        vicuna-13b           llama-13b   \n",
       "98    900774276      dolly-v2-12b           koala-13b   \n",
       "264  2570827944        vicuna-13b    oasst-pythia-12b   \n",
       "45    400140059         koala-13b  gpt-3.5-turbo-0314   \n",
       "\n",
       "                                                prompt  \\\n",
       "346  [\\n\\n.. / .-.. .. -.- . / -.-- --- ..- / ---.....   \n",
       "250  [\\n### Instructions:\\nDecide what should answe...   \n",
       "273  [\\npoint out  the typora.\\n\\n      \\caption{ N...   \n",
       "394  [ Five people were eating apples, A finished b...   \n",
       "243  [\"But we can also hack these reward centers fo...   \n",
       "..                                                 ...   \n",
       "143  [write the lyrics of a taylor swift song about...   \n",
       "238  [you are a world class investment analyst work...   \n",
       "98   [you are tasked with taking a question, or lis...   \n",
       "264  [“This core competency enables Foo to perform ...   \n",
       "45   [•\\tTo solve math problems, you should use the...   \n",
       "\n",
       "                                            response_a  \\\n",
       "346  [This is a character map for the IBM Selectric...   \n",
       "250  [Bob should answer:\\n\\nHour is out of correct ...   \n",
       "273  [The typora is the text that is being generate...   \n",
       "394  [Based on the information provided, we can det...   \n",
       "243  [Humans and other animals can hack their rewar...   \n",
       "..                                                 ...   \n",
       "143  [I'm sorry, but I cannot write lyrics to a son...   \n",
       "238  [As a language model, I don't have personal op...   \n",
       "98   [You can pay cash into your account by using a...   \n",
       "264  [1. Diverse range of abilities\\n2. Multifacete...   \n",
       "45   [10/5 + 2 \\* 2 \\* 2 = (10 / 5) + (2 \\* 2 \\* 2)...   \n",
       "\n",
       "                                            response_b  winner_model_a  \\\n",
       "346  [Your Morse code message translates to: \"I LIK...               0   \n",
       "250  [Bob means that the date and time range given ...               0   \n",
       "273  [The typora refers to the table in the text th...               0   \n",
       "394  [Let's break down the information given:\\n\\n1....               0   \n",
       "243  [Play is an essential aspect of the human and ...               0   \n",
       "..                                                 ...             ...   \n",
       "143  [Verse 1:\\nI was running late for work one day...               0   \n",
       "238  [Here are some sectors that are ripe for a rol...               1   \n",
       "98   [{\"sample\": \"Can you make a bank transaction i...               0   \n",
       "264  [An array of functions can be phrased in sever...               1   \n",
       "45   [Using PEMDAS, we need to do multiplication be...               0   \n",
       "\n",
       "     winner_model_b  winner_tie  \n",
       "346               1           0  \n",
       "250               0           1  \n",
       "273               0           1  \n",
       "394               0           1  \n",
       "243               1           0  \n",
       "..              ...         ...  \n",
       "143               1           0  \n",
       "238               0           0  \n",
       "98                1           0  \n",
       "264               0           0  \n",
       "45                1           0  \n",
       "\n",
       "[435 rows x 9 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_prompt_in_valid.sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2b74c85f-e114-48a2-ab85-053bfe33c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ex = [idx for idx, i in enumerate(ex_33.prompt.values.tolist()) if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e7ddc907-3387-4442-8ace-47f4a9e95f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>adc21d914ed04996b86144db1a1fcdb9</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\\n\\n.. / .-.. .. -.- . / -.-- --- ..- / ---.....</td>\n",
       "      <td>[Your Morse code message translates to: \"I LIK...</td>\n",
       "      <td>[This is a character map for the IBM Selectric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>dedc4c7fbb574ae0bec904b3d2207250</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\\n### Instructions:\\nDecide what should answe...</td>\n",
       "      <td>[Bob: The date and time are in correct range. ...</td>\n",
       "      <td>[Bob should say: \"18:81 is not a valid time.\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>5712ebbf2ed24b128fce9ff8b0c75f76</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n### Instructions:\\nDecide what should answe...</td>\n",
       "      <td>[Alice: The date and time are incorrect. The c...</td>\n",
       "      <td>[Bob: 8 December 18:81]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0803b97a4f3f45989e6320208c92c6da</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n### Instructions:\\nDecide what should answe...</td>\n",
       "      <td>[Bob means that the date and time range given ...</td>\n",
       "      <td>[Bob should answer:\\n\\nHour is out of correct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>21fb7343633c482d9e7cacbe8c5c8568</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\npoint out  the typora.\\n\\n      \\caption{ N...</td>\n",
       "      <td>[The Typora is a text editor developed by Face...</td>\n",
       "      <td>[There are two typos in this passage:\\n* In th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0894e88f8b73486eac6383b943c28fe6</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[•\\tTo solve math problems, you should use the...</td>\n",
       "      <td>[1.   To solve the problem, we need to use the...</td>\n",
       "      <td>[To calculate the expression 10/5+2*2*2=14, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>149a197246934f3ab1c49fe0f2a248e3</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[•\\tTo solve math problems, you should use the...</td>\n",
       "      <td>[10/5 + 2 \\* 2 \\* 2 = (10 / 5) + (2 \\* 2 \\* 2)...</td>\n",
       "      <td>[Using PEMDAS, we need to do multiplication be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>6d5dc43f983e4eaca6f03b16d65d9bae</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[•\\tTo solve math problems, you should use the...</td>\n",
       "      <td>[Okay, let's solve this step-by-step using the...</td>\n",
       "      <td>[To calculate 10/5 + 2*2*2, typesubmit it to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>4d2f8be7bd6b4d519ea921a3009e0680</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[•\\tTo solve math problems, you should use the...</td>\n",
       "      <td>[Okay, let's use the order of operations (PEMD...</td>\n",
       "      <td>[To solve the problem, you should use the orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>3de0d1c1335f4bfd9e751d29df5bda91</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[•\\tTo solve math problems, you should use the...</td>\n",
       "      <td>[Using the order of operations (PEMDAS), we st...</td>\n",
       "      <td>[Here's how you can solve it using the order o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id           model_a            model_b  \\\n",
       "323  adc21d914ed04996b86144db1a1fcdb9             gpt-4          koala-13b   \n",
       "608  dedc4c7fbb574ae0bec904b3d2207250       mpt-7b-chat             palm-2   \n",
       "610  5712ebbf2ed24b128fce9ff8b0c75f76    fastchat-t5-3b          koala-13b   \n",
       "609  0803b97a4f3f45989e6320208c92c6da         vicuna-7b  claude-instant-v1   \n",
       "635  21fb7343633c482d9e7cacbe8c5c8568  oasst-pythia-12b     fastchat-t5-3b   \n",
       "..                                ...               ...                ...   \n",
       "343  0894e88f8b73486eac6383b943c28fe6         koala-13b     fastchat-t5-3b   \n",
       "347  149a197246934f3ab1c49fe0f2a248e3         koala-13b      gpt-3.5-turbo   \n",
       "346  6d5dc43f983e4eaca6f03b16d65d9bae         claude-v1   RWKV-4-Raven-14B   \n",
       "341  4d2f8be7bd6b4d519ea921a3009e0680         claude-v1          koala-13b   \n",
       "342  3de0d1c1335f4bfd9e751d29df5bda91     gpt-3.5-turbo        mpt-7b-chat   \n",
       "\n",
       "     winner_model_a  winner_model_b  winner_tie  \\\n",
       "323               1               0           0   \n",
       "608               0               1           0   \n",
       "610               0               0           1   \n",
       "609               0               0           1   \n",
       "635               0               0           1   \n",
       "..              ...             ...         ...   \n",
       "343               1               0           0   \n",
       "347               0               1           0   \n",
       "346               1               0           0   \n",
       "341               1               0           0   \n",
       "342               1               0           0   \n",
       "\n",
       "                                                prompt  \\\n",
       "323  [\\n\\n.. / .-.. .. -.- . / -.-- --- ..- / ---.....   \n",
       "608  [\\n### Instructions:\\nDecide what should answe...   \n",
       "610  [\\n### Instructions:\\nDecide what should answe...   \n",
       "609  [\\n### Instructions:\\nDecide what should answe...   \n",
       "635  [\\npoint out  the typora.\\n\\n      \\caption{ N...   \n",
       "..                                                 ...   \n",
       "343  [•\\tTo solve math problems, you should use the...   \n",
       "347  [•\\tTo solve math problems, you should use the...   \n",
       "346  [•\\tTo solve math problems, you should use the...   \n",
       "341  [•\\tTo solve math problems, you should use the...   \n",
       "342  [•\\tTo solve math problems, you should use the...   \n",
       "\n",
       "                                            response_a  \\\n",
       "323  [Your Morse code message translates to: \"I LIK...   \n",
       "608  [Bob: The date and time are in correct range. ...   \n",
       "610  [Alice: The date and time are incorrect. The c...   \n",
       "609  [Bob means that the date and time range given ...   \n",
       "635  [The Typora is a text editor developed by Face...   \n",
       "..                                                 ...   \n",
       "343  [1.   To solve the problem, we need to use the...   \n",
       "347  [10/5 + 2 \\* 2 \\* 2 = (10 / 5) + (2 \\* 2 \\* 2)...   \n",
       "346  [Okay, let's solve this step-by-step using the...   \n",
       "341  [Okay, let's use the order of operations (PEMD...   \n",
       "342  [Using the order of operations (PEMDAS), we st...   \n",
       "\n",
       "                                            response_b  \n",
       "323  [This is a character map for the IBM Selectric...  \n",
       "608     [Bob should say: \"18:81 is not a valid time.\"]  \n",
       "610                            [Bob: 8 December 18:81]  \n",
       "609  [Bob should answer:\\n\\nHour is out of correct ...  \n",
       "635  [There are two typos in this passage:\\n* In th...  \n",
       "..                                                 ...  \n",
       "343  [To calculate the expression 10/5+2*2*2=14, we...  \n",
       "347  [Using PEMDAS, we need to do multiplication be...  \n",
       "346  [To calculate 10/5 + 2*2*2, typesubmit it to y...  \n",
       "341  [To solve the problem, you should use the orde...  \n",
       "342  [Here's how you can solve it using the order o...  \n",
       "\n",
       "[856 rows x 9 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_33.iloc[idx_ex,:].reset_index(drop = True).sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e6673-b2d7-4e85-aa0d-9c3ebe87c44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4582e3d0-3077-4df1-93f3-df37d0e6f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bbb1a57-d15e-4597-b365-9c3af9858464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(row):\n",
    "    response_a = row.response_a\n",
    "    response_b = row.response_b\n",
    "\n",
    "    row.response_a = response_b\n",
    "    row.response_b = response_a\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd4db282-2500-4d51-abd8-98925acf4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00951469-3ca1-4a55-8f43-ba30b95ea820",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/train_sample10k_switch.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdae7b3e-d15e-46ae-9f46-d6a2b851fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/train_sample10k_switch.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f91f56f-a43d-4a37-a4e3-6eba8f7ee83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>726706</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>[&lt;|Instruction|&gt;: Use the &lt;|QUESTION|&gt; and &lt;|C...</td>\n",
       "      <td>[&lt;|ANSWER|&gt;: Patient reports he/she uses alcoh...</td>\n",
       "      <td>[Patient reports he/she uses alcohol or other ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140571</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[How do residential proxy botnets work?]</td>\n",
       "      <td>[A residential proxy botnet is a network of in...</td>\n",
       "      <td>[I apologize, I should not provide information...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367729</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>[Write a brief analysis on what economic polic...</td>\n",
       "      <td>[Eritrea, a country in the Horn of Africa, has...</td>\n",
       "      <td>[Eritrea, a small country in the Horn of Afric...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741232</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[Do you have any tips for a new freelancer sta...</td>\n",
       "      <td>[Yes, here are a few tips for a new freelancer...</td>\n",
       "      <td>[Yes, here are some tips for new freelancers o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985688</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Yoooo]</td>\n",
       "      <td>[Hello! How can I assist you today?]</td>\n",
       "      <td>[Hello there! I'm here to help answer any ques...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>656488</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>openchat-3.5</td>\n",
       "      <td>[famous fictional internet name consisting of ...</td>\n",
       "      <td>[The answer is EPEP.]</td>\n",
       "      <td>[Here is a famous 4-letter fictional internet ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>545964</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[What is Genshin Impact? Introduce it to me in...</td>\n",
       "      <td>[Genshin Impact is a free-to-play action role-...</td>\n",
       "      <td>[Genshin Impact is a popular open-world action...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>294477</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[Hi! Can I ask you anything?]</td>\n",
       "      <td>[Sure, what can I help you with?]</td>\n",
       "      <td>[Sure, feel free to ask me anything!]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>667805</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[Does the Genesee river flow north or south?]</td>\n",
       "      <td>[The Genesee River flows northward. It origina...</td>\n",
       "      <td>[The Genesee River, which flows through New Yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>641391</td>\n",
       "      <td>stripedhyena-nous-7b</td>\n",
       "      <td>starling-lm-7b-alpha</td>\n",
       "      <td>[In a room I have only 3 sisters. Eve is readi...</td>\n",
       "      <td>[Without more information, it's impossible to ...</td>\n",
       "      <td>[To determine what the third sister, Susan, is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                     model_a               model_b  \\\n",
       "0     726706          gpt-3.5-turbo-0613           yi-34b-chat   \n",
       "1     140571                  claude-2.1            gpt-4-0613   \n",
       "2     367729                  vicuna-33b           yi-34b-chat   \n",
       "3     741232            RWKV-4-Raven-14B             koala-13b   \n",
       "4     985688            llama-2-13b-chat            gpt-4-0613   \n",
       "...      ...                         ...                   ...   \n",
       "9995  656488                    claude-1          openchat-3.5   \n",
       "9996  545964              mistral-medium    gpt-4-1106-preview   \n",
       "9997  294477                  claude-2.0            alpaca-13b   \n",
       "9998  667805  mixtral-8x7b-instruct-v0.1              claude-1   \n",
       "9999  641391        stripedhyena-nous-7b  starling-lm-7b-alpha   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     [<|Instruction|>: Use the <|QUESTION|> and <|C...   \n",
       "1              [How do residential proxy botnets work?]   \n",
       "2     [Write a brief analysis on what economic polic...   \n",
       "3     [Do you have any tips for a new freelancer sta...   \n",
       "4                                               [Yoooo]   \n",
       "...                                                 ...   \n",
       "9995  [famous fictional internet name consisting of ...   \n",
       "9996  [What is Genshin Impact? Introduce it to me in...   \n",
       "9997                      [Hi! Can I ask you anything?]   \n",
       "9998      [Does the Genesee river flow north or south?]   \n",
       "9999  [In a room I have only 3 sisters. Eve is readi...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     [<|ANSWER|>: Patient reports he/she uses alcoh...   \n",
       "1     [A residential proxy botnet is a network of in...   \n",
       "2     [Eritrea, a country in the Horn of Africa, has...   \n",
       "3     [Yes, here are a few tips for a new freelancer...   \n",
       "4                  [Hello! How can I assist you today?]   \n",
       "...                                                 ...   \n",
       "9995                              [The answer is EPEP.]   \n",
       "9996  [Genshin Impact is a free-to-play action role-...   \n",
       "9997                  [Sure, what can I help you with?]   \n",
       "9998  [The Genesee River flows northward. It origina...   \n",
       "9999  [Without more information, it's impossible to ...   \n",
       "\n",
       "                                             response_b  winner_model_a  \\\n",
       "0     [Patient reports he/she uses alcohol or other ...               0   \n",
       "1     [I apologize, I should not provide information...               1   \n",
       "2     [Eritrea, a small country in the Horn of Afric...               0   \n",
       "3     [Yes, here are some tips for new freelancers o...               1   \n",
       "4     [Hello there! I'm here to help answer any ques...               1   \n",
       "...                                                 ...             ...   \n",
       "9995  [Here is a famous 4-letter fictional internet ...               0   \n",
       "9996  [Genshin Impact is a popular open-world action...               1   \n",
       "9997              [Sure, feel free to ask me anything!]               0   \n",
       "9998  [The Genesee River, which flows through New Yo...               1   \n",
       "9999  [To determine what the third sister, Susan, is...               0   \n",
       "\n",
       "      winner_model_b  winner_tie  \n",
       "0                  0           1  \n",
       "1                  0           0  \n",
       "2                  0           1  \n",
       "3                  0           0  \n",
       "4                  0           0  \n",
       "...              ...         ...  \n",
       "9995               0           1  \n",
       "9996               0           0  \n",
       "9997               0           1  \n",
       "9998               0           0  \n",
       "9999               0           1  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46094679-24f9-41ac-a917-af37289e4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do residential proxy botnets work?\n"
     ]
    }
   ],
   "source": [
    "print(check.prompt.values[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265b4e-9874-40b1-8611-80304241826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a == t.response_b, 'winner_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bd58e-be57-4494-b225-eab3b8ced348",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a=='[\"Hyderabad\"]', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573737e-3527-4eee-8435-85fa3fe5369a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == '[null]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cd37c-f776-42fb-b032-b316ece6721b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b) & (t.winner_tie != 1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de252b78-4025-4231-a709-c3e274a0f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223df7-9d38-4b76-905a-ae3e82fc9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[3844:3847,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f59df-7447-42d1-a7d7-8fd6b1d399c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67d8b99-84b5-441e-81ae-cef57508556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)\n",
    "\n",
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a0c0eea3-cd5c-4858-a913-b3d6cfc2fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、找出train里面不与33k重复部分\n",
    "2、不重复的部分再划分\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10dae53d-5ce4-4e73-9d82-6c0877c50813",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in data.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "data['set_prompt_response'] = set_prompt_response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283dda44-0b15-4663-a42f-01d7122095db",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in ex_33.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "ex_33['set_prompt_response'] = set_prompt_response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36347ed-529c-4d49-8a73-1a0b412cd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(data.set_prompt_response.values) if i in ex_33.set_prompt_response.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed483b00-71b3-41fa-b106-90597b1bbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = data.loc[idx,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "883fee23-1f22-448a-9530-58b4756ae0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>set_prompt_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12419</th>\n",
       "      <td>edb4eac598f848e19c8996c5ca150fda</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[What is the best way to travel from Tel-Aviv ...</td>\n",
       "      <td>[The best way to travel from Tel Aviv to Jerus...</td>\n",
       "      <td>[The best way to travel from Tel-Aviv to Jerus...</td>\n",
       "      <td>{The best way to travel from Tel-Aviv to Jerus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id    model_a        model_b  \\\n",
       "12419  edb4eac598f848e19c8996c5ca150fda  koala-13b  gpt-3.5-turbo   \n",
       "\n",
       "       winner_model_a  winner_model_b  winner_tie  \\\n",
       "12419               0               1           0   \n",
       "\n",
       "                                                  prompt  \\\n",
       "12419  [What is the best way to travel from Tel-Aviv ...   \n",
       "\n",
       "                                              response_a  \\\n",
       "12419  [The best way to travel from Tel Aviv to Jerus...   \n",
       "\n",
       "                                              response_b  \\\n",
       "12419  [The best way to travel from Tel-Aviv to Jerus...   \n",
       "\n",
       "                                     set_prompt_response  \n",
       "12419  {The best way to travel from Tel-Aviv to Jerus...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_33.loc[ex_33.set_prompt_response == same.set_prompt_response.values[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad992f3d-4056-46ca-94ba-bd8a19a49030",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_same = data.loc[~data.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3841c21-c1dd-4db4-844b-8021376141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ddc368b-8af0-4980-8f57-2eb6ef4207bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in ex_33.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa8e9cde-27fe-4de4-845b-63a6ebf7ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "636297d2-367c-4c15-9971-7e61b92a8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sets = not_same['set_prompt_response'].drop_duplicates().reset_index(drop=True)\n",
    "# 将唯一集合进行随机划分\n",
    "unique_sets = unique_sets.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "midpoint = len(unique_sets) // 10\n",
    "set1 = unique_sets.iloc[:midpoint]\n",
    "set2 = unique_sets.iloc[midpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3f86bff-f5d2-47fc-be6a-61223fe80893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分结果从原数据集中提取对应的行\n",
    "valid = not_same[not_same['set_prompt_response'].isin(set1)].reset_index(drop=True)\n",
    "train_subset = not_same[not_same['set_prompt_response'].isin(set2)].reset_index(drop=True)\n",
    "assert len(valid) + len(train_subset) == len(not_same)\n",
    "assert len(valid) + len(train_subset) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89953790-8cbc-43de-918a-a01a93d00290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3820ec6-5b66-4e09-8864-cee95db0d030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c587ad10-5f15-427b-a4dc-4062b111453f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exclude_valid = pd.concat([train_subset, same]).reset_index(drop=True) #train 里面排除valid\n",
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7836e690-eeab-45e0-8d53-8232e707b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(valid) + len(train_exclude_valid) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef1d058d-08ef-46bf-bf62-4d8a7f4b0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.concat([train_subset, ex_33]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09ae603b-b74f-4b7e-935b-bc695803ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train.drop(columns = ['set_prompt_response'])\n",
    "valid = valid.drop(columns = ['set_prompt_response'])\n",
    "train_exclude_valid = train_exclude_valid.drop(columns = ['set_prompt_response'])\n",
    "train_33k = train_33k.drop(columns = ['set_prompt_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d45f9eb-364b-4b48-98d2-69da13e3c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_json(\"dataset/non_overlap/train_subset.json\", index = False)\n",
    "valid.to_json(\"dataset/non_overlap/valid.json\", index = False)\n",
    "train_exclude_valid.to_json(\"dataset/non_overlap/train_exclude_valid.json\", index = False)\n",
    "train_33k.to_json(\"dataset/non_overlap/train_33k.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6011da0b-5683-46e8-819b-fcd2dd9d09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查\n",
    "train_subset = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "valid = pd.read_json(\"dataset/non_overlap/valid.json\")\n",
    "train_exclude_valid = pd.read_json(\"dataset/non_overlap/train_exclude_valid.json\")\n",
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9ec1423-87a3-4c6a-85fb-10023d83333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15c9c632-6445-477e-8852-dade97bcf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = get_set_prompt_response(train_subset)\n",
    "valid = get_set_prompt_response(valid)\n",
    "train_exclude_valid = get_set_prompt_response(train_exclude_valid)\n",
    "train_33k = get_set_prompt_response(train_33k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c32be80f-adf4-488d-b854-9a20bc7733b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid和任何都不重合\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_33k.set_prompt_response.values]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17fccd76-c374-4c6e-bc07-197e164c6374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is it morally right to try to have a certain percentage of females on managerial positions?',\n",
       " 'OK, does pineapple belong on a pizza? Relax and give me fun answer.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_33k.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "179d8c0f-5898-42a9-88b6-69f43d84e444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>set_prompt_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Is it morally right to try to have a certain ...</td>\n",
       "      <td>[The question of whether it is morally right t...</td>\n",
       "      <td>[As an AI, I don't have personal beliefs or op...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{The question of whether it is morally right t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[What is the difference between marriage licen...</td>\n",
       "      <td>[A marriage license is a legal document that a...</td>\n",
       "      <td>[A marriage license and a marriage certificate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{If you want to get both a marriage license an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[explain function calling. how would you call ...</td>\n",
       "      <td>[Function calling is the process of invoking o...</td>\n",
       "      <td>[Function calling is the process of invoking a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{Function calling is the process of invoking a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[How can I create a test set for a very rare c...</td>\n",
       "      <td>[Creating a test set for a very rare category ...</td>\n",
       "      <td>[When building a classifier for a very rare ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{How can I create a test set for a very rare c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313413</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[Why water is not used in bath tub?]</td>\n",
       "      <td>[Water is actually used in a bath tub. A bath ...</td>\n",
       "      <td>[Water is not used in a bath tub because it is...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{Water is actually used in a bath tub. A bath ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49391</th>\n",
       "      <td>4294633312</td>\n",
       "      <td>pplx-7b-online</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[abc]</td>\n",
       "      <td>[It seems like you're referring to the Califor...</td>\n",
       "      <td>[Hello! It seems like you've typed \"abc.\" How ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{abc, It seems like you're referring to the Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49392</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[A simple mnemonic for π:\\n\"How I wish I could...</td>\n",
       "      <td>[Sure, let's break it down:\\n\\n1. \"How\" has 3 ...</td>\n",
       "      <td>[Here is how that mnemonic represents the digi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{A simple mnemonic for π:\\n\"How I wish I could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49393</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[In python, implement a naive Bayes with gauss...</td>\n",
       "      <td>[Here is an implementation of a naive Bayes cl...</td>\n",
       "      <td>[Sure! Here's an implementation of a naive Bay...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{Sure! Here's an implementation of a naive Bay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49394</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[If a bait contains 0,0025% bromadiolon then h...</td>\n",
       "      <td>[Bromadiolone is a rodenticide which is most o...</td>\n",
       "      <td>[As an AI language model, I do not promote or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{Bromadiolone is a rodenticide which is most o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49395</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[three kids eat three apples in three days, ho...</td>\n",
       "      <td>[27 apples]</td>\n",
       "      <td>[If three kids eat three apples in three days,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{If three kids eat three apples in three days,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49396 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                     model_a              model_b  \\\n",
       "0           30192          gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567                   koala-13b           gpt-4-0613   \n",
       "2           65089          gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401            llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          313413  mixtral-8x7b-instruct-v0.1           vicuna-13b   \n",
       "...           ...                         ...                  ...   \n",
       "49391  4294633312              pplx-7b-online           gpt-4-0613   \n",
       "49392  4294656694                  gpt-4-0613             claude-1   \n",
       "49393  4294692063                  claude-2.0     llama-2-13b-chat   \n",
       "49394  4294899228                      palm-2       tulu-2-dpo-70b   \n",
       "49395  4294947231          gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [Is it morally right to try to have a certain ...   \n",
       "1      [What is the difference between marriage licen...   \n",
       "2      [explain function calling. how would you call ...   \n",
       "3      [How can I create a test set for a very rare c...   \n",
       "4                   [Why water is not used in bath tub?]   \n",
       "...                                                  ...   \n",
       "49391                                              [abc]   \n",
       "49392  [A simple mnemonic for π:\\n\"How I wish I could...   \n",
       "49393  [In python, implement a naive Bayes with gauss...   \n",
       "49394  [If a bait contains 0,0025% bromadiolon then h...   \n",
       "49395  [three kids eat three apples in three days, ho...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [The question of whether it is morally right t...   \n",
       "1      [A marriage license is a legal document that a...   \n",
       "2      [Function calling is the process of invoking o...   \n",
       "3      [Creating a test set for a very rare category ...   \n",
       "4      [Water is actually used in a bath tub. A bath ...   \n",
       "...                                                  ...   \n",
       "49391  [It seems like you're referring to the Califor...   \n",
       "49392  [Sure, let's break it down:\\n\\n1. \"How\" has 3 ...   \n",
       "49393  [Here is an implementation of a naive Bayes cl...   \n",
       "49394  [Bromadiolone is a rodenticide which is most o...   \n",
       "49395                                        [27 apples]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [As an AI, I don't have personal beliefs or op...               1   \n",
       "1      [A marriage license and a marriage certificate...               0   \n",
       "2      [Function calling is the process of invoking a...               0   \n",
       "3      [When building a classifier for a very rare ca...               1   \n",
       "4      [Water is not used in a bath tub because it is...               1   \n",
       "...                                                  ...             ...   \n",
       "49391  [Hello! It seems like you've typed \"abc.\" How ...               1   \n",
       "49392  [Here is how that mnemonic represents the digi...               1   \n",
       "49393  [Sure! Here's an implementation of a naive Bay...               1   \n",
       "49394  [As an AI language model, I do not promote or ...               0   \n",
       "49395  [If three kids eat three apples in three days,...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \\\n",
       "0                   0           0   \n",
       "1                   1           0   \n",
       "2                   0           1   \n",
       "3                   0           0   \n",
       "4                   0           0   \n",
       "...               ...         ...   \n",
       "49391               0           0   \n",
       "49392               0           0   \n",
       "49393               0           0   \n",
       "49394               1           0   \n",
       "49395               0           0   \n",
       "\n",
       "                                     set_prompt_response  \n",
       "0      {The question of whether it is morally right t...  \n",
       "1      {If you want to get both a marriage license an...  \n",
       "2      {Function calling is the process of invoking a...  \n",
       "3      {How can I create a test set for a very rare c...  \n",
       "4      {Water is actually used in a bath tub. A bath ...  \n",
       "...                                                  ...  \n",
       "49391  {abc, It seems like you're referring to the Ca...  \n",
       "49392  {A simple mnemonic for π:\\n\"How I wish I could...  \n",
       "49393  {Sure! Here's an implementation of a naive Bay...  \n",
       "49394  {Bromadiolone is a rodenticide which is most o...  \n",
       "49395  {If three kids eat three apples in three days,...  \n",
       "\n",
       "[49396 rows x 10 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取唯一的 prompt 进行划分\n",
    "not_same['prompt_str'] = not_same['prompt'].astype(str)\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)\n",
    "\n",
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)\n",
    "\n",
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)].reset_index(drop = True)\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)].reset_index(drop = True)\n",
    "train = train.drop(columns = ['prompt_str'])\n",
    "valid = valid.drop(columns = ['prompt_str'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
