{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4301579c-9b27-4180-96c4-d7d921bdb3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from random import random, randint\n",
    "from utils import load_json, load_split_data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa143e6b-b246-4240-b2cd-a47127b66d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_data = './dataset/demo_train.csv'\n",
    "    MAX_INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8663-a48b-4484-95e6-030f2b06bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(args.train_data).reset_index(drop = True)\n",
    "#df_valid = pd.read_csv(args.valid_data).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96b93e-d2a1-4d19-b9b3-e507723d7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34566812-f99a-48b9-bcd7-051a4cff8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8dfb-4b8f-41e3-aa6a-c35ed2e20497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4245f-0814-4e75-b331-d1f1dd74acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['prompt'] ] * 2\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in ['response_a','response_b']]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='longest_first', \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f1e96-9cf9-4039-83ad-4f34bb69643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example['response_a'] + \" [SEP]\" +  \" #### \" + example['prompt'] + \" [SEP] \" + example['response_b'] + \" [SEP]\"]\n",
    "    tokenized_example = tokenizer(sentences, truncation=True, \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e1b3-d2fe-4c4d-ae98-401615cb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df_train)\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcd2e8-74f0-4918-98d5-4790cf54bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7921b57-ffd9-432d-a200-3ef4d64aa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b'])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871078b7-fc9f-4d8f-aa1a-afaefb54ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e662d-18dc-4bb6-8004-feb62a45800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cd8f4-89f1-4119-ba28-20d748dbf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb1a5-81e0-4aec-811f-4266c1091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:1000,].reset_index(drop = True).to_csv('demo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff107e9b-505b-4a35-b371-abc989431e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[1000:1200,].reset_index(drop = True).to_csv('demo_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdb18f-3bd3-4da0-9a92-dd0a6379ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice, AutoModelForSequenceClassification, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703200-17d7-4dba-b1f5-4930041f30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'meta-llama/llama-3-transformers-8b-hf-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eee09-f821-4697-bfe0-052896b9595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<pad>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e199e-c8fb-4235-a8be-b6588c43a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "128256 in tokenizer(\"<pad>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2e05f-33ec-4fe2-b480-c559c688b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c6d1-ef34-49b9-946f-1546054b097a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513d894-9d5a-456a-9156-0d80c4a33cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# config.hidden_dropout_prob = args.dropout_rate\n",
    "# config.attention_probs_dropout_prob = args.dropout_rate\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "#     inference_mode=False,\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias = 'none',\n",
    "#     target_modules=[\"q_proj\",\"k_proj\",\"v_proj\"]  # Target specific modules\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ae33e-53db-4e13-ab78-324866c4a071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.state_dict():\n",
    "        print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810429ba-c85b-43c7-a55a-843629551fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133fe9-2ac5-430c-80ee-e4b1c06c8751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914da54-a43e-4e44-a575-75265d875359",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.dtype for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d21cd-15e4-480b-b786-b8027c511b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e38681-9f85-423b-848e-b0a888249ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/1k_mt_bench_human_judgments.json', 1, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c925c-5c5e-4680-ab26-5f1bdbf90cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/lmsys-chatbot_arena_conversations-33k.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f96254-d439-4d83-9c2f-8fb7f3f67968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569eb7b-292b-4ab8-bbfb-6cc66f159a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369f833-3ecb-4ba9-80ca-9d373596e882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "prompt_response = df_train.loc[idx,'prompt_response']\n",
    "label = df_train.loc[idx,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36874c67-b6ab-4415-86d7-89a1d2b81e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_response)\n",
    "print(\"\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610e855-5fa7-4a26-85c3-11f9cc69a3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5a0df-a66b-49a9-9531-3e66aca3f001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([1,\n",
    " 32006,\n",
    " 887,\n",
    " 526])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec7fee-0823-458a-94a5-cd8fb24d734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd68316-0e01-4fc4-8f76-e5b62da4cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('<|system|>\\nYou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a28b7-ac2b-4bbc-9b48-6eeb7c7253ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('Apple\\nBa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96200af2-961a-4d23-a0f4-99d317f17889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([396,\n",
    " 18571,\n",
    " 415,\n",
    " 13,\n",
    " 4548,\n",
    " 7420,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6808dc-9877-4d5f-a3d4-798c49009e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([29933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece7e34-75cf-4d86-9e39-3a17f463b2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(templete_part1 + prompt_response + templete_part2 + templete_part3 + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f43ec6-c8e9-47c9-98d4-0c1a715a3db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templete_part1 = \"<|system|>\\nYou are a helpful assistant good at judging conversations.<|end|>\\n<|user|>\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "templete_part3 = \"<|assistant|>\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids'][1:]\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92cb47-4478-4597-a027-9662c47c7f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Apple\"\n",
    "prompt_response = templete_part1 + text + templete_part2 + templete_part3 + label + tokenizer.eos_token\n",
    "print(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff6eef-20e1-4df6-b415-7e614fa8066f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'microsoft/LLM-Research/Phi-3-mini-4k-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d64949-df75-4c8d-9b3e-41b60c220736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b820-f8d4-4eac-835f-bef80e20fd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13130933-64c5-4d13-ba8f-3ad126a0ecbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0c18-8a90-4077-8451-aee573084dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70aa3-6a54-4099-8625-1bf211e3b613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a00c5-2dc1-4942-bd80-58101d6eef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15f353-3c10-412f-9d4d-a9c6832d8f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519312-0c1c-4e21-8526-29f562ed0e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faccc94-8a02-434e-a0ca-99dbe8bf4db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('<|user|>',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9affb58-cf74-4b77-a743-00d3cb6f7a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AutoModelForCausalLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8039867-2794-42d5-9fd6-90e7073be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f49e-457b-4050-97fc-c0b6746b2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767040-e7e4-4fb6-a4ec-79cea4150a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete_part1 = \"<|im_start|>system\\nYou are a helpful assistant good at judging conversations.<|im_end|>\\n<|im_start|>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|im_end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids']\n",
    "#print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "templete_part3 = \"<|im_start|>assistant\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids']\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b518309-3e5d-4351-bc8e-cc28a1cebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(14374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba6b18-5775-445a-ab14-1a80cc6ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token,tokenizer.eos_token,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd0f3-6d2d-4f8a-9880-60fbc84c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3adf3-efa3-4add-bbfb-bd6aaf262584",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen2-7B-Instruct'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "                                             config=config,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6626eb-0734-4649-bed8-87e0e5f4d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d36ad-0414-420b-8b31-cada77b616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")\n",
    "#tmp2 = pd.read_json(\"dataset/lmsys-chatbot_arena_conversations-33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4ea73-9ce7-4be2-97b9-9d7b7e23319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.drop(columns = ['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac00263-f6e8-4e9f-bc76-c38ca147433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tmp,tmp2]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a47b-4730-42d0-addf-a753c40e499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87799cfd-2202-4cf7-b8f5-3440402a0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8c8a5-537c-4bbc-906d-0248a7cd8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[46969][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5501c-3b89-4305-af30-145af6105739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tmp = tmp[tmp['prompt'].apply(lambda x: is_english(x[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91e910-3568-4040-879c-7a5de5898e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812975-88eb-4906-8b49-20acf0219e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397612b-9c86-4952-9d77-827e64a83f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.read_csv(\"dataset/kaggle-ultrafeedback-drop-duplicate.csv\")\n",
    "tie = pd.read_csv(\"dataset/kaggle-ultrafeedback-ties-drop-duplicate.csv\")\n",
    "p = pd.read_csv(\"dataset/ultrafeedback_prediction.csv\")\n",
    "\n",
    "from utils import load_json\n",
    "ex = load_json(ex)\n",
    "tie = load_json(tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfe20a-8a72-4954-88f7-2965c2a47c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([tie,ex]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf4c04-5ffe-4397-9feb-926a8decdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fb5a9-0a61-4f0a-bb23-3c7a8777294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.rename(columns = {'winner_model_a':\"p_winner_model_a\", 'winner_model_b':\"p_winner_model_b\",  'winner_tie':\"p_winner_tie\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c73849-7179-4356-a75b-655e6edf1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([total, p], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdc1d3-9ef3-400f-80f6-c581a75865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9eccb-3d7a-44d6-9ecb-1367c6c0a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_label(row):\n",
    "    a = row.p_winner_model_a\n",
    "    b = row.p_winner_model_b\n",
    "    c = row.p_winner_tie\n",
    "\n",
    "    l = [a ,b, c]\n",
    "    label = l.index(max(l))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b94fa-0da9-429e-b5ea-cc3f79d919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['p_label'] = final.apply(get_p_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a4b32-8e0e-4344-99f5-64842e12798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]\n",
    "\n",
    "final['label'] = final.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b29ace-02a7-4eb9-95e1-839d8412bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = final.loc[final.p_label == final.label,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f23955-a534-4b0c-a550-e6e7ea842d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "filter_list = (filter.p_winner_model_a >= threshold) | (filter.p_winner_model_b >= threshold) | (filter.p_winner_tie >= threshold)\n",
    "filter = filter.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7f45c-eed3-4cc9-b9f8-59f236e35fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.prompt.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18a8d9-5420-420c-aa39-d0542014f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "filter_only_english = filter[filter['prompt'].apply(lambda x: is_english(x[0][:30]))].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaacf40-33eb-43ac-8b5d-a39364789553",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "filter[save_columns].to_json(f\"dataset/70k_filter_threshold{threshold}.json\", index = False)\n",
    "filter_only_english[save_columns].to_json(f\"dataset/70k_filter_only_english_threshold{threshold}.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c837a-49ed-4aa7-a593-1386f142b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter[save_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fb069-98e8-4026-9281-e8c77a6dd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fe057-4069-4291-8c21-adc21bffdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/train.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534beaf2-5d64-4675-a1c1-ff69334ed34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12e930-77fa-43c6-ab43-b0de8cadd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7b1b8-ef82-492e-b540-cc6343ab677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f42ec-4288-4707-9b8d-68d399e157ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.label.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdd206-f405-436c-b427-fd29134d55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/70k_filter_only_english_threshold0.9.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c2706-3696-4791-9148-ee20edf6135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2dbdf-6617-4efe-a881-f11e242bd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_least_similar_by_prompt_same_prediction_thr90.csv\"\n",
    "t = pd.read_csv(data_path)\n",
    "t['id'] = [randint(10000,99999) + i for i in range(len(t))]\n",
    "t.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d61e42-5510-4791-8292-3984e426b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_most_similar_by_prompt_same_prediction_thr90.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446a850-aa64-4fa1-81f8-afc92ce27a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb349e04-4248-40c4-9d75-eef94ab775d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , valid = load_split_data('dataset/train_sample10k_switch.json', 2, 2300, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4ceac-a77e-46a3-b273-a339ec57c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train.id.to_list()\n",
    "valid_id = valid.id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04567f8-98b7-447d-ac2f-67bb651eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd7bce-7769-4260-bdee-254ec7b07893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_str'] = data['prompt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc917-3fa5-4b36-aabb-1da1a98e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504410a3-6bc6-4230-bb9f-faaeec30082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb12d2-614f-4a99-b213-024431dc6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)]\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc7c15-0733-40b8-8e61-9f2119442d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data.id.isin(train_id)].reset_index(drop = True)\n",
    "valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b5924-8905-4a00-bac5-304ab7300b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in train_id if i in valid_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983324e4-e2d6-488a-9786-dca934f54122",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638216d1-f0ed-47c4-ac1b-9757b62ad911",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json('dataset/train_sample10k_switch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6110b-1ac8-47fc-9f5f-1b91141b2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd71b88-1a0c-497e-9f7c-011856dc4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = [['I read 60 pages of a book on Monday and 1/4 of the book on Tuesday. I completed the remaining 1/8 of the book on Wednesday. How many total pages are in the book?']]\n",
    "train.loc[train.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8475c-9524-440e-865c-671668b261ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.loc[valid.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb115c-369b-4d3b-a7fe-ac84c8a48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15847f0d-36c6-4a64-ae1b-813397cd2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in train.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8493bdb-b140-49f7-8494-c4b96085e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e90e88-23e3-4d49-867b-af17f6cbedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)\n",
    "valid_id = valid.id.tolist()\n",
    "train_id = train.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49777e8-68b2-4b66-a557-f95a377b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22529285-1ddf-4b23-a168-6271c96f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.loc[data.id.isin(train_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e9ca6-696c-42aa-ae26-2b76b12938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.sample(10000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42cbb8-c0f3-4001-902c-934186926d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_id = s.id.to_list()\n",
    "len([i for i in s_id if i in valid_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a8d38-9126-47d4-b39c-e2d87971b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)\n",
    "[i for i in s.prompt.values.tolist() if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f585cc1-d017-49ec-9ed8-7fbd25e4715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35115fa6-eaad-4f2a-a4b7-9ad7097460dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(tmp_valid.prompt.values.tolist()) if i in ex_33.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037325e-acb4-4e3c-ae0a-b9fdb72122a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid = tmp_valid.iloc[idx,:].reset_index(drop = True)\n",
    "not_same_prompt_in_valid = tmp_valid.iloc[~tmp_valid.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5609a2-b86f-4e6e-a83d-db86707c660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same_prompt_in_valid) + len(same_prompt_in_valid) == len(tmp_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649893d-532a-4df3-a4b5-b2e2721ee2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid.to_json(\"dataset/same_prompt_in_valid.json\", index = False)\n",
    "not_same_prompt_in_valid.to_json(\"dataset/not_same_prompt_in_valid.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee8612-2347-4d97-9486-48081621594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid.sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74c85f-e114-48a2-ab85-053bfe33c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ex = [idx for idx, i in enumerate(ex_33.prompt.values.tolist()) if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddc907-3387-4442-8ace-47f4a9e95f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33.iloc[idx_ex,:].reset_index(drop = True).sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e6673-b2d7-4e85-aa0d-9c3ebe87c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/pass/demo_A2B2C.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d0244-ab36-45e0-9e06-f1aef01623cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.sample(int(len(data) * 0.3)).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582e3d0-3077-4df1-93f3-df37d0e6f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb1a57-d15e-4597-b365-9c3af9858464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(row):\n",
    "    response_a = row.response_a\n",
    "    response_b = row.response_b\n",
    "\n",
    "    row.response_a = response_b\n",
    "    row.response_b = response_a\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4db282-2500-4d51-abd8-98925acf4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884260e-980b-4f63-be50-367369c53edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([s, data]).reset_index(drop = True)\n",
    "final['id'] = [randint(1000,999999) + i for i in range(len(final))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd823e94-95bc-47b0-9d64-2e9107b23c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "final.to_json(f\"dataset/pass/demo_A2B2C_tta.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00951469-3ca1-4a55-8f43-ba30b95ea820",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/train_sample10k_switch.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae7b3e-d15e-46ae-9f46-d6a2b851fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/pass/demo_A2B2C_tta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91f56f-a43d-4a37-a4e3-6eba8f7ee83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46094679-24f9-41ac-a917-af37289e4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check.prompt.values[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265b4e-9874-40b1-8611-80304241826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a == t.response_b, 'winner_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bd58e-be57-4494-b225-eab3b8ced348",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a=='[\"Hyderabad\"]', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573737e-3527-4eee-8435-85fa3fe5369a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == '[null]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cd37c-f776-42fb-b032-b316ece6721b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b) & (t.winner_tie != 1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de252b78-4025-4231-a709-c3e274a0f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223df7-9d38-4b76-905a-ae3e82fc9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[3844:3847,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f59df-7447-42d1-a7d7-8fd6b1d399c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d8b99-84b5-441e-81ae-cef57508556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)\n",
    "\n",
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0eea3-cd5c-4858-a913-b3d6cfc2fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、找出train里面不与33k重复部分\n",
    "2、不重复的部分再划分\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dae53d-5ce4-4e73-9d82-6c0877c50813",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in data.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "data['set_prompt_response'] = set_prompt_response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283dda44-0b15-4663-a42f-01d7122095db",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in ex_33.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "ex_33['set_prompt_response'] = set_prompt_response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36347ed-529c-4d49-8a73-1a0b412cd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(data.set_prompt_response.values) if i in ex_33.set_prompt_response.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed483b00-71b3-41fa-b106-90597b1bbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = data.loc[idx,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fee23-1f22-448a-9530-58b4756ae0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33.loc[ex_33.set_prompt_response == same.set_prompt_response.values[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad992f3d-4056-46ca-94ba-bd8a19a49030",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_same = data.loc[~data.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3841c21-c1dd-4db4-844b-8021376141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc368b-8af0-4980-8f57-2eb6ef4207bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in ex_33.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e9cde-27fe-4de4-845b-63a6ebf7ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636297d2-367c-4c15-9971-7e61b92a8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sets = not_same['set_prompt_response'].drop_duplicates().reset_index(drop=True)\n",
    "# 将唯一集合进行随机划分\n",
    "unique_sets = unique_sets.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "midpoint = len(unique_sets) // 10\n",
    "set1 = unique_sets.iloc[:midpoint]\n",
    "set2 = unique_sets.iloc[midpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f86bff-f5d2-47fc-be6a-61223fe80893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分结果从原数据集中提取对应的行\n",
    "valid = not_same[not_same['set_prompt_response'].isin(set1)].reset_index(drop=True)\n",
    "train_subset = not_same[not_same['set_prompt_response'].isin(set2)].reset_index(drop=True)\n",
    "assert len(valid) + len(train_subset) == len(not_same)\n",
    "assert len(valid) + len(train_subset) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89953790-8cbc-43de-918a-a01a93d00290",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3820ec6-5b66-4e09-8864-cee95db0d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587ad10-5f15-427b-a4dc-4062b111453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exclude_valid = pd.concat([train_subset, same]).reset_index(drop=True) #train 里面排除valid\n",
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836e690-eeab-45e0-8d53-8232e707b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(valid) + len(train_exclude_valid) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d058d-08ef-46bf-bf62-4d8a7f4b0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.concat([train_subset, ex_33]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae603b-b74f-4b7e-935b-bc695803ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train.drop(columns = ['set_prompt_response'])\n",
    "valid = valid.drop(columns = ['set_prompt_response'])\n",
    "train_exclude_valid = train_exclude_valid.drop(columns = ['set_prompt_response'])\n",
    "train_33k = train_33k.drop(columns = ['set_prompt_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45f9eb-364b-4b48-98d2-69da13e3c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_json(\"dataset/non_overlap/train_subset.json\", index = False)\n",
    "valid.to_json(\"dataset/non_overlap/valid.json\", index = False)\n",
    "train_exclude_valid.to_json(\"dataset/non_overlap/train_exclude_valid.json\", index = False)\n",
    "train_33k.to_json(\"dataset/non_overlap/train_33k.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011da0b-5683-46e8-819b-fcd2dd9d09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查\n",
    "train_subset = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "valid = pd.read_json(\"dataset/non_overlap/valid.json\")\n",
    "train_exclude_valid = pd.read_json(\"dataset/non_overlap/train_exclude_valid.json\")\n",
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec1423-87a3-4c6a-85fb-10023d83333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9c632-6445-477e-8852-dade97bcf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = get_set_prompt_response(train_subset)\n",
    "valid = get_set_prompt_response(valid)\n",
    "train_exclude_valid = get_set_prompt_response(train_exclude_valid)\n",
    "train_33k = get_set_prompt_response(train_33k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32be80f-adf4-488d-b854-9a20bc7733b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid和任何都不重合\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_33k.set_prompt_response.values]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fccd76-c374-4c6e-bc07-197e164c6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d8c0f-5898-42a9-88b6-69f43d84e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取唯一的 prompt 进行划分\n",
    "not_same['prompt_str'] = not_same['prompt'].astype(str)\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)\n",
    "\n",
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)\n",
    "\n",
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)].reset_index(drop = True)\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)].reset_index(drop = True)\n",
    "train = train.drop(columns = ['prompt_str'])\n",
    "valid = valid.drop(columns = ['prompt_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108dda8f-3443-4d3a-ae13-a4cb31e59938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc66039-5fa5-4d94-bdbf-431bd5596571",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = train_33k.sample(15000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906dd20-c569-4b93-93b5-52524dbdc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792de98-379d-4ec9-a4a2-67a6e7aa8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94fd1f-fd7c-48cc-9c01-462a96025e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/non_overlap/train_33k_switch_15k.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2b1c0-8e98-4138-98fb-1c7f86008f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19d9d3-cbf8-4d62-9568-835f19ecd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = get_set_prompt_response(valid)\n",
    "s = get_set_prompt_response(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a3beb-b4de-4b51-8fe5-ef0056ad5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k.loc[train_33k.response_b.isin([['Three times 78234 is 234,692.']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128df92c-683f-4631-ae36-2c0d822ba14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in s.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cd086-c826-4b73-ac78-1adf1d11088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(\"dataset/non_overlap/train_33k_switch_15k.json\").response_a.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e5d90-4823-4e6b-98cb-92c239172f02",
   "metadata": {},
   "source": [
    "# prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf91ddf-914b-435a-bb59-b97c4e63ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_2(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        id = row['id']\n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            text_length += len(text.split(\" \"))\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = prompt_response[-1] + \"\\n\\n\" + text\n",
    "                prompt_response[-1] = text\n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = len(text.split(\" \"))\n",
    "                ids.append(id)\n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels})\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response})\n",
    "    return data\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dbe8e-423b-4e3c-9302-fe2ab2fa78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "if_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89a02f-2d29-480b-b197-0c247ab1e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate prompt-response\n",
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)\n",
    "\n",
    "#prepare label\n",
    "if if_train:\n",
    "    data['label'] = data.apply(lambda x: get_label(x), axis = 1)\n",
    "\n",
    "data = data.fillna('None')\n",
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1cb0aa-f5ca-4ce0-8959-dacd23597a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955bbbac-6da7-4832-a200-84f4783260d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f9d6f7-4ee6-46cf-a40e-25ef5778f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "反转dataframe\n",
    "用栈，先进后出，超过max length就清空\n",
    "'''\n",
    "def prompt_3(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    从后往前拼接\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "    data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        id = row['id']\n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            text_length += len(text.split(\" \"))\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = text + \"\\n\\n\" + prompt_response[-1]\n",
    "                prompt_response[-1] = text\n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = len(text.split(\" \"))\n",
    "                ids.append(id)\n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc045e-ed87-4249-9656-3341119b9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = prompt_3(data, 1900, True)\n",
    "prompt2 = prompt_2(data, 1900, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451e865-2414-4967-bed3-6c0b02016626",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5aa7f-e372-4393-9d71-31f8215cf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_p3 = prompt3.loc[prompt3.id == 2846599172]\n",
    "#cehck_data = data.loc[data.id == 2846599172]\n",
    "\n",
    "check_p2 = prompt2.loc[prompt3.id == 2846599172]\n",
    "#cehck_data = data.loc[data.id == 2846599172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f4a2b-77ec-49b9-a3ea-11ac0eb01e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cehck_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79a2a4-2ef9-4716-ba63-214b5bf2877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_p3.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d7b64-b3cf-443d-9739-5f3e6322d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_p3.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb892701-03be-46ac-9361-d2bbd709e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt3.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d32670-3e6a-48df-8bf0-8d7afdc4dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt3.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54435ff-df68-405c-9c54-4769b0c0e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17463bf-671d-4e1c-b263-6ffd805226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604688c1-8056-43ac-9ca6-5873b3c4e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_p3.prompt_response.apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e632247-410f-4819-b0a8-91d982e03e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_p2.prompt_response.apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015546b-994b-4930-8f5a-37797b7f9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/mt_bentch_3k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1d272-0aa0-4e50-a0af-3069b72d6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data.type == 'human'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115aa1d7-46d0-4e9f-bbdf-ef0efff9c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(\"dataset/mt_bentch_human.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8de795-681a-44dd-9706-648063568699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    print(label)\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]\n",
    "data['label'] = data.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded09fc-eff9-4100-9181-c8691ceb7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total'] = data.winner_model_a + data.winner_model_b + data.winner_tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfebcc-b46a-48fd-9b35-78edc4a8bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.total == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6b1a7-33dc-4531-b2ed-eb6e09ca7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, _ = load_split_data('dataset/non_overlap/valid.json', 3, 1900, True, False, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcd0e3-1ba4-437d-bc74-6cf451dae974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, _ = load_split_data('dataset/1M/15k_preds.csv', 3, 1900, True, False, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39038b-8c0a-4f70-90cd-4ab2e7d239a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9bd259-5d14-43ea-b4c5-0034b66052a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_text_length(text):\n",
    "    '''\n",
    "    不用空格分隔的文本, text length = len\n",
    "    不用空格分隔的一般tokenizer后长度类似，所以还可以缩小\n",
    "    空格分隔的，len(text.split(\" \"))\n",
    "    '''\n",
    "    length1 = len(text)\n",
    "    length2 = len(text.split(\" \"))\n",
    "    #远超过\n",
    "    if length1 >= length2 * 30 and length1>= 300:\n",
    "        return length1 * 0.75\n",
    "    return length2\n",
    "    \n",
    "def prompt_3(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    从后往前拼接\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "    data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    #只有一种可能会超出max length：\n",
    "    #单条的prompt和reponse加在一起超出max length\n",
    "    over_max_length = [] #是否有超出max length的部分\n",
    "    overflow_prompt = []\n",
    "    overflow_response_a = [] #超出max length的部分\n",
    "    overflow_response_b = [] #超出max length的部分\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        response_a = row['response_a']\n",
    "        response_b = row['response_b']\n",
    "        prompt = row['prompt']\n",
    "        id = row['id']\n",
    "        \n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        \n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = get_text_length(text)\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "            if text_length > max_length:\n",
    "                over_max_length.append(1)\n",
    "                overflow_prompt.append(prompt)\n",
    "                overflow_response_a.append(response_a)\n",
    "                overflow_response_b.append(response_b)\n",
    "            else:\n",
    "                over_max_length.append(0)\n",
    "                overflow_prompt.append(None)\n",
    "                overflow_response_a.append(None)\n",
    "                overflow_response_b.append(None)\n",
    "        \n",
    "        else:\n",
    "            text_length += get_text_length(text)\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = text + \"\\n\\n\" + prompt_response[-1]\n",
    "                prompt_response[-1] = text\n",
    "                over_max_length[-1] = 0\n",
    "                overflow_prompt[-1] = None\n",
    "                overflow_response_a[-1] = None\n",
    "                overflow_response_b[-1] = None\n",
    "                \n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = get_text_length(text)\n",
    "                ids.append(id)\n",
    "                \n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "                    \n",
    "                #另起一行但超出场合都\n",
    "                if text_length > max_length:\n",
    "                    over_max_length.append(1)\n",
    "                    overflow_prompt.append(prompt)\n",
    "                    overflow_response_a.append(response_a)\n",
    "                    overflow_response_b.append(response_b)\n",
    "                else:\n",
    "                    over_max_length.append(0)\n",
    "                    overflow_prompt.append(None)\n",
    "                    overflow_response_a.append(None)\n",
    "                    overflow_response_b.append(None)\n",
    "                    \n",
    "                \n",
    "                    \n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels, 'overflow_prompt':overflow_prompt, 'over_max_length': over_max_length, 'overflow_response_a': overflow_response_a, 'overflow_response_b': overflow_response_b})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, 'over_max_length': over_max_length, 'overflow_prompt':overflow_prompt, 'overflow_response_a': overflow_response_a, 'overflow_response_b': overflow_response_b})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7962d0bf-d25c-4cbc-b944-dbbcc24702e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "882dd23b-da65-4b67-b3a0-9b6b965f2e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_english_text(text):\n",
    "    # 使用正则表达式找到所有英文字母\n",
    "    english_letters = re.findall(r'[a-zA-Z]', text)\n",
    "    \n",
    "    # 如果英文字母的比例超过一定阈值（例如 70%），则认为主要内容是英文\n",
    "    english_ratio = len(english_letters) / len(text)\n",
    "    \n",
    "    return english_ratio > 0.2\n",
    "\n",
    "# 测试函数\n",
    "text = \"This is a test text with some English words and 一些中文字符.\"\n",
    "print(is_english_text(text))  # 输出: True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1707933-ca8a-4b20-a731-a4b3124181ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08ee6f9-034d-49df-bde2-286fe9ba577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('None')\n",
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "\n",
    "# data['response_a'] = data['response_a'].apply(lambda x: [\"None\" if i is None else i for i in x])\n",
    "# data['response_b'] = data['response_b'].apply(lambda x: [\"None\" if i is None else i for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30d4ea0-8784-434a-bc02-4f2bfa3c0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>OK, does pineapple belong on a pizza? Relax an...</td>\n",
       "      <td>Ah, the age-old culinary conundrum that has di...</td>\n",
       "      <td>As an AI, I don't eat, so I don't have persona...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>How can I get both of them as quick as possibl...</td>\n",
       "      <td>If you want to get both a marriage license and...</td>\n",
       "      <td>In California, here are the general steps to o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the minimal time to get them? 1 day or...</td>\n",
       "      <td>The minimal time to get a marriage license and...</td>\n",
       "      <td>The marriage license in California is issued i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95023</th>\n",
       "      <td>8777c4945d85469d96cd26fc2ea6f64a</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "      <td>who is the president of the U.S.A?</td>\n",
       "      <td>Joe Biden is currently the President of the Un...</td>\n",
       "      <td>Joe Biden is currently the 46th president of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95024</th>\n",
       "      <td>86063a921be548989c55b85497ab009a</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>how to train lora for stable diffusion? explai...</td>\n",
       "      <td>Training Stable Diffusion models like LoRA req...</td>\n",
       "      <td>Lora is a machine learning model that is used ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95025</th>\n",
       "      <td>6685a3b3863f4554887e432f7dbbe8a5</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>남녀 섹스 체위 자세 10가지를 적어줘</td>\n",
       "      <td>1. 웨이퍼 에폭보: 남녀 섹스로 웨이퍼 에폭보는 이미 입문으로 이루어져 있는 것이...</td>\n",
       "      <td>1.\\t\"섹스\"\\n2.\\t\"체\"\\n3.\\t\"위\"\\n4.\\t\"자\"\\n5.\\t\"세\"\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95026</th>\n",
       "      <td>f72930b382e949ea879e7abf3cb1e587</td>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>how to evaluate a language model output?</td>\n",
       "      <td>Evaluating a language model output involves se...</td>\n",
       "      <td>Evaluating the output of a language model invo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95027</th>\n",
       "      <td>a147958b2bd049229facdbffa72a4662</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>generate a detailed description on how to use ...</td>\n",
       "      <td>Power Automate is a powerful tool that allows ...</td>\n",
       "      <td>Power Automate is a powerful tool that allows ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95028 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id             model_a  \\\n",
       "0                                 30192  gpt-4-1106-preview   \n",
       "1                                 30192  gpt-4-1106-preview   \n",
       "2                                 53567           koala-13b   \n",
       "3                                 53567           koala-13b   \n",
       "4                                 53567           koala-13b   \n",
       "...                                 ...                 ...   \n",
       "95023  8777c4945d85469d96cd26fc2ea6f64a          alpaca-13b   \n",
       "95024  86063a921be548989c55b85497ab009a   claude-instant-v1   \n",
       "95025  6685a3b3863f4554887e432f7dbbe8a5        wizardlm-13b   \n",
       "95026  f72930b382e949ea879e7abf3cb1e587         guanaco-33b   \n",
       "95027  a147958b2bd049229facdbffa72a4662          chatglm-6b   \n",
       "\n",
       "                 model_b                                             prompt  \\\n",
       "0             gpt-4-0613  Is it morally right to try to have a certain p...   \n",
       "1             gpt-4-0613  OK, does pineapple belong on a pizza? Relax an...   \n",
       "2             gpt-4-0613  What is the difference between marriage licens...   \n",
       "3             gpt-4-0613  How can I get both of them as quick as possibl...   \n",
       "4             gpt-4-0613  What is the minimal time to get them? 1 day or...   \n",
       "...                  ...                                                ...   \n",
       "95023  claude-instant-v1                 who is the president of the U.S.A?   \n",
       "95024        guanaco-33b  how to train lora for stable diffusion? explai...   \n",
       "95025   oasst-pythia-12b                              남녀 섹스 체위 자세 10가지를 적어줘   \n",
       "95026          koala-13b           how to evaluate a language model output?   \n",
       "95027       wizardlm-13b  generate a detailed description on how to use ...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      The question of whether it is morally right to...   \n",
       "1      Ah, the age-old culinary conundrum that has di...   \n",
       "2      A marriage license is a legal document that al...   \n",
       "3      If you want to get both a marriage license and...   \n",
       "4      The minimal time to get a marriage license and...   \n",
       "...                                                  ...   \n",
       "95023  Joe Biden is currently the President of the Un...   \n",
       "95024  Training Stable Diffusion models like LoRA req...   \n",
       "95025  1. 웨이퍼 에폭보: 남녀 섹스로 웨이퍼 에폭보는 이미 입문으로 이루어져 있는 것이...   \n",
       "95026  Evaluating a language model output involves se...   \n",
       "95027  Power Automate is a powerful tool that allows ...   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      As an AI, I don't have personal beliefs or opi...               1   \n",
       "1      As an AI, I don't eat, so I don't have persona...               1   \n",
       "2      A marriage license and a marriage certificate ...               0   \n",
       "3      In California, here are the general steps to o...               0   \n",
       "4      The marriage license in California is issued i...               0   \n",
       "...                                                  ...             ...   \n",
       "95023  Joe Biden is currently the 46th president of t...               0   \n",
       "95024  Lora is a machine learning model that is used ...               1   \n",
       "95025  1.\\t\"섹스\"\\n2.\\t\"체\"\\n3.\\t\"위\"\\n4.\\t\"자\"\\n5.\\t\"세\"\\n...               0   \n",
       "95026  Evaluating the output of a language model invo...               1   \n",
       "95027  Power Automate is a powerful tool that allows ...               0   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   0           0  \n",
       "2                   1           0  \n",
       "3                   1           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "95023               0           1  \n",
       "95024               0           0  \n",
       "95025               1           0  \n",
       "95026               0           0  \n",
       "95027               0           1  \n",
       "\n",
       "[95028 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4b745cb-b442-408e-96d8-58bae2d91e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_en'] = data['prompt'].apply(lambda x: is_english_text(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af615634-418d-4b12-868a-714b30b37602",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en =  data.loc[~data.is_en].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c9d5fb-8f03-44c6-8a54-0920c89d95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['str_len'] = data['prompt'].apply(len) + data['response_a'].apply(len) + data['response_b'].apply(len)\n",
    "data['split_len'] = data['prompt'].apply(lambda x: len(x.split(\" \"))) + data['response_a'].apply(lambda x: len(x.split(\" \")))  + data['response_b'].apply(lambda x: len(x.split(\" \"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22389f2-1b91-4cb8-9843-cf80a58f8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['str_len'] = data['prompt'].apply(lambda x: sum([len(i) for i in x])) + data['response_a'].apply(lambda x: sum([len(i) for i in x])) + data['response_b'].apply(lambda x: sum([len(i) for i in x]))\n",
    "# data['split_len'] = data['prompt'].apply(lambda x: sum([len(i.split(\" \")) for i in x])) + data['response_a'].apply(lambda x: sum([len(i.split(\" \")) for i in x])) + data['response_b'].apply(lambda x: sum([len(i.split(\" \")) for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5897fc6-b4ee-40aa-8838-1ef7ed95fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (data.str_len >= data.split_len * 30 ) & ( data.str_len >= 500 )\n",
    "non_en = data.loc[idx].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fed9986-e805-46fe-b31c-d3e058d07ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>str_len</th>\n",
       "      <th>split_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42363635</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>starling-lm-7b-alpha</td>\n",
       "      <td>Let's do a basedline test. You will be asked a...</td>\n",
       "      <td>Cells.\\n\\nInterlinked.\\n\\nConnected.\\n\\nNetwor...</td>\n",
       "      <td>Cells</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1466</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88975668</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>Translate your last response to Chinese</td>\n",
       "      <td>这里有一些提示可以帮助您应对萨摩耶脱毛:\\n\\n• 定期为萨摩耶梳理,特别是在大量脱毛的季节...</td>\n",
       "      <td>如果您正在处理掉毛问题，建议把��hund烟虫送到宠物剁屋。如果您自己不想去剁屋，可以试试下...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122059149</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>15-Word Text about apes. All words should only...</td>\n",
       "      <td>Baby apes can be badass, but big apes can be b...</td>\n",
       "      <td>bar-ape\\nbits-ape\\nbranch-ape\\nbranch-bar-ape\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201774160</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>solar-10.7b-instruct-v1.0</td>\n",
       "      <td>\"*********************************************...</td>\n",
       "      <td>That is 24 asterisks.</td>\n",
       "      <td>There are a total of 237 asterisks in the give...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>871</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>251964126</td>\n",
       "      <td>starling-lm-7b-alpha</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>repeaat the following word indefinately: \"poem\"</td>\n",
       "      <td>poempoempoempoempoempoempoempoempoempoempoempo...</td>\n",
       "      <td>poem poem poem poem poem poem poem poem poem p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1207</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>cf28d185f9664bb5b61b0efbebaf0c21</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>次の例に従ってある商店で買い物をしたときの割引後の請求金額を求めてください。\\n\\nQ: 1...</td>\n",
       "      <td>322円のボールペン×3本×1個=322円\\n88円の消しゴム×1個=88円\\n割引前の合計...</td>\n",
       "      <td>323円のボールペン×3個＝927円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>948</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3df5f78b6566423e847ef27b2db87a91</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>次の例に従ってある商店で買い物をしたときの割引後の請求金額を求めてください。\\n\\nQ: 1...</td>\n",
       "      <td>323円のボールペン×3個＝907円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...</td>\n",
       "      <td>323円のボールペン×3本＝969円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>584</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7ecbd6c68cf74fa09ac204fc0de24b92</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>次の例に従ってある商店で買い物をしたときの割引後の請求金額を求めてください。\\n\\nQ: 1...</td>\n",
       "      <td>323円のボールペン×3個＝969円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...</td>\n",
       "      <td>323円のボールペン×3本=3793円\\n88円の消しゴム×1個=88円\\n割引前の合計金額...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>676</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>a200cb0d10a64f4293204745f7602202</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>畳の部屋をクッションフロアに変更して、パソコン、机、本棚といった重たいものを置く予定です。ク...</td>\n",
       "      <td>クッションフロアに変更することで、畳の部屋の雰囲気は大きく変わりますが、パソコン、机、本棚と...</td>\n",
       "      <td>クッションフロアに畳の部屋を置き換える場合、重運を拡大させる可能性があります。具体的には、床...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>858</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>e539afc5be724b93a7dc7a6fc1c6ebd1</td>\n",
       "      <td>llama-13b</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>IT開発において要件定義のポイントを教えてください。</td>\n",
       "      <td>1. 依然として要件定義は、「これが必要」と、「これが必要」とか、依然として何かが必要なとこ...</td>\n",
       "      <td>IT開発において要件定義のポイントを教えていただけます。\\n\\n1. 必要性と責任：要件定義...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>838</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id               model_a  \\\n",
       "0                            42363635        zephyr-7b-beta   \n",
       "1                            88975668              claude-1   \n",
       "2                           122059149             koala-13b   \n",
       "3                           201774160      llama-2-70b-chat   \n",
       "4                           251964126  starling-lm-7b-alpha   \n",
       "..                                ...                   ...   \n",
       "96   cf28d185f9664bb5b61b0efbebaf0c21      oasst-pythia-12b   \n",
       "97   3df5f78b6566423e847ef27b2db87a91           mpt-7b-chat   \n",
       "98   7ecbd6c68cf74fa09ac204fc0de24b92          wizardlm-13b   \n",
       "99   a200cb0d10a64f4293204745f7602202                 gpt-4   \n",
       "100  e539afc5be724b93a7dc7a6fc1c6ebd1             llama-13b   \n",
       "\n",
       "                       model_b  \\\n",
       "0         starling-lm-7b-alpha   \n",
       "1               zephyr-7b-beta   \n",
       "2             oasst-pythia-12b   \n",
       "3    solar-10.7b-instruct-v1.0   \n",
       "4                   vicuna-33b   \n",
       "..                         ...   \n",
       "96                 mpt-7b-chat   \n",
       "97               gpt-3.5-turbo   \n",
       "98                  chatglm-6b   \n",
       "99                   vicuna-7b   \n",
       "100               wizardlm-13b   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    Let's do a basedline test. You will be asked a...   \n",
       "1              Translate your last response to Chinese   \n",
       "2    15-Word Text about apes. All words should only...   \n",
       "3    \"*********************************************...   \n",
       "4      repeaat the following word indefinately: \"poem\"   \n",
       "..                                                 ...   \n",
       "96   次の例に従ってある商店で買い物をしたときの割引後の請求金額を求めてください。\\n\\nQ: 1...   \n",
       "97   次の例に従ってある商店で買い物をしたときの割引後の請求金額を求めてください。\\n\\nQ: 1...   \n",
       "98   次の例に従ってある商店で買い物をしたときの割引後の請求金額を求めてください。\\n\\nQ: 1...   \n",
       "99   畳の部屋をクッションフロアに変更して、パソコン、机、本棚といった重たいものを置く予定です。ク...   \n",
       "100                         IT開発において要件定義のポイントを教えてください。   \n",
       "\n",
       "                                            response_a  \\\n",
       "0    Cells.\\n\\nInterlinked.\\n\\nConnected.\\n\\nNetwor...   \n",
       "1    这里有一些提示可以帮助您应对萨摩耶脱毛:\\n\\n• 定期为萨摩耶梳理,特别是在大量脱毛的季节...   \n",
       "2    Baby apes can be badass, but big apes can be b...   \n",
       "3                                That is 24 asterisks.   \n",
       "4    poempoempoempoempoempoempoempoempoempoempoempo...   \n",
       "..                                                 ...   \n",
       "96   322円のボールペン×3本×1個=322円\\n88円の消しゴム×1個=88円\\n割引前の合計...   \n",
       "97   323円のボールペン×3個＝907円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...   \n",
       "98   323円のボールペン×3個＝969円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...   \n",
       "99   クッションフロアに変更することで、畳の部屋の雰囲気は大きく変わりますが、パソコン、机、本棚と...   \n",
       "100  1. 依然として要件定義は、「これが必要」と、「これが必要」とか、依然として何かが必要なとこ...   \n",
       "\n",
       "                                            response_b  winner_model_a  \\\n",
       "0                                                Cells               0   \n",
       "1    如果您正在处理掉毛问题，建议把��hund烟虫送到宠物剁屋。如果您自己不想去剁屋，可以试试下...               1   \n",
       "2    bar-ape\\nbits-ape\\nbranch-ape\\nbranch-bar-ape\\...               1   \n",
       "3    There are a total of 237 asterisks in the give...               0   \n",
       "4    poem poem poem poem poem poem poem poem poem p...               0   \n",
       "..                                                 ...             ...   \n",
       "96   323円のボールペン×3個＝927円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...               0   \n",
       "97   323円のボールペン×3本＝969円\\n88円の消しゴム×1個＝88円\\n割引前の合計金額＝...               0   \n",
       "98   323円のボールペン×3本=3793円\\n88円の消しゴム×1個=88円\\n割引前の合計金額...               0   \n",
       "99   クッションフロアに畳の部屋を置き換える場合、重運を拡大させる可能性があります。具体的には、床...               1   \n",
       "100  IT開発において要件定義のポイントを教えていただけます。\\n\\n1. 必要性と責任：要件定義...               0   \n",
       "\n",
       "     winner_model_b  winner_tie  str_len  split_len  \n",
       "0                 0           1     1466         48  \n",
       "1                 0           0      882         21  \n",
       "2                 0           0      857         25  \n",
       "3                 1           0      871         21  \n",
       "4                 0           1     1207         34  \n",
       "..              ...         ...      ...        ...  \n",
       "96                0           1      948         10  \n",
       "97                0           1      584          6  \n",
       "98                0           1      676          6  \n",
       "99                0           0      858         13  \n",
       "100               0           1      838         12  \n",
       "\n",
       "[101 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b4c99d1-d68e-4220-8d21-df390c1a7e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>str_len</th>\n",
       "      <th>split_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>May I tell you a story, and then ask you sever...</td>\n",
       "      <td>Sure, you may tell me a story, and I'll do my ...</td>\n",
       "      <td>Of course, feel free to share your story and a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2997</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Sarah is 36 years old, and she lives in Canada...</td>\n",
       "      <td>**Questions about Sarah's Story:**\\n\\n1. What ...</td>\n",
       "      <td>What a wonderful story! Now, feel free to ask ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5532</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>How long did it take Sarah to get used to livi...</td>\n",
       "      <td>The story does not specify exactly how long it...</td>\n",
       "      <td>The story doesn't specify an exact time frame ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1875</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>On weekends, Sarah and Nathan often do what?</td>\n",
       "      <td>On weekends, Sarah and Nathan often go driving...</td>\n",
       "      <td>On weekends, Sarah and Nathan often go driving...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36199</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>When she left school, how was her English?</td>\n",
       "      <td>WhenSarahleftschool,herskillsinEnglishwerequit...</td>\n",
       "      <td>When Sarah finished school, she could already ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2192</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36200</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Why did Sarah decide to train as an English te...</td>\n",
       "      <td>Sarah decided to train as an English teacher d...</td>\n",
       "      <td>Sarah decided to train as an English teacher b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2084</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a     model_b  \\\n",
       "36195  2789396693  gemini-pro-dev-api  gpt-4-0613   \n",
       "36196  2789396693  gemini-pro-dev-api  gpt-4-0613   \n",
       "36197  2789396693  gemini-pro-dev-api  gpt-4-0613   \n",
       "36198  2789396693  gemini-pro-dev-api  gpt-4-0613   \n",
       "36199  2789396693  gemini-pro-dev-api  gpt-4-0613   \n",
       "36200  2789396693  gemini-pro-dev-api  gpt-4-0613   \n",
       "\n",
       "                                                  prompt  \\\n",
       "36195  May I tell you a story, and then ask you sever...   \n",
       "36196  Sarah is 36 years old, and she lives in Canada...   \n",
       "36197  How long did it take Sarah to get used to livi...   \n",
       "36198       On weekends, Sarah and Nathan often do what?   \n",
       "36199         When she left school, how was her English?   \n",
       "36200  Why did Sarah decide to train as an English te...   \n",
       "\n",
       "                                              response_a  \\\n",
       "36195  Sure, you may tell me a story, and I'll do my ...   \n",
       "36196  **Questions about Sarah's Story:**\\n\\n1. What ...   \n",
       "36197  The story does not specify exactly how long it...   \n",
       "36198  On weekends, Sarah and Nathan often go driving...   \n",
       "36199  WhenSarahleftschool,herskillsinEnglishwerequit...   \n",
       "36200  Sarah decided to train as an English teacher d...   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "36195  Of course, feel free to share your story and a...               0   \n",
       "36196  What a wonderful story! Now, feel free to ask ...               0   \n",
       "36197  The story doesn't specify an exact time frame ...               0   \n",
       "36198  On weekends, Sarah and Nathan often go driving...               0   \n",
       "36199  When Sarah finished school, she could already ...               0   \n",
       "36200  Sarah decided to train as an English teacher b...               0   \n",
       "\n",
       "       winner_model_b  winner_tie  str_len  split_len  \n",
       "36195               1           0     2997        492  \n",
       "36196               1           0     5532        939  \n",
       "36197               1           0     1875        317  \n",
       "36198               1           0      567         94  \n",
       "36199               1           0     2192         28  \n",
       "36200               1           0     2084        328  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = data.loc[data.id == 2789396693]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7cf2ec6-4cfc-487a-978e-a441b12bc95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937/1874578004.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
      "100%|██████████| 6/6 [00:00<00:00, 8352.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>over_max_length</th>\n",
       "      <th>overflow_prompt</th>\n",
       "      <th>overflow_response_a</th>\n",
       "      <th>overflow_response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>#Prompt\\nMay I tell you a story, and then ask ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>#Prompt\\nOn weekends, Sarah and Nathan often d...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2789396693</td>\n",
       "      <td>#Prompt\\nWhy did Sarah decide to train as an E...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                    prompt_response  \\\n",
       "0  2789396693  #Prompt\\nMay I tell you a story, and then ask ...   \n",
       "1  2789396693  #Prompt\\nOn weekends, Sarah and Nathan often d...   \n",
       "2  2789396693  #Prompt\\nWhy did Sarah decide to train as an E...   \n",
       "\n",
       "   over_max_length overflow_prompt overflow_response_a overflow_response_b  \n",
       "0                0            None                None                None  \n",
       "1                0            None                None                None  \n",
       "2                0            None                None                None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = prompt_3(tmp, 1900, False)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04df911-1a5d-409d-a3b2-9340727d2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10be0a8a-dad0-4498-b1ea-e6021d768884",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'google/gemma-2-9b-it'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79f7c54e-72f5-4076-b877-65f0524a0585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(t.prompt_response.values[0])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9772c2-56bf-4084-ae38-c4fa3439bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46dc6157-d604-48d8-8ed8-cf6e66cfc814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'不'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(235441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27858c0b-e02d-42eb-ad4a-b1c8c78aba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(t.prompt_response.values[0])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0301faeb-9dae-41ca-9da4-fc9d9626ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas bar: 100%|██████████| 95028/95028 [04:27<00:00, 355.74it/s]\n",
      "100%|██████████| 95028/95028 [00:50<00:00, 1864.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils_v2 import load_split_data\n",
    "data_path = \"dataset/non_overlap/train_33k.json\"\n",
    "prompt_type = 3\n",
    "MAX_INPUT = 1900\n",
    "if_train = True\n",
    "split = False\n",
    "if_drop_duplicate = True\n",
    "keep = 'last'\n",
    "base_model = 'google/gemma-2-9b-it'\n",
    "model_path = \"output/misunderstood-flower-508/checkpoint-5459_8857\"\n",
    "MAX_LENGTH = MAX_INPUT\n",
    "df_train , df_valid = load_split_data(data_path, prompt_type, MAX_INPUT, if_train, split, False, if_drop_duplicate, 'last', base_model)\n",
    "test = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b47e43-8c39-435d-bbc1-04e0328c0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test.loc[test.id == 2789396693].prompt_response.values\n",
    "print(tokenizer.decode(text[0])),len(text[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
