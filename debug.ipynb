{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4301579c-9b27-4180-96c4-d7d921bdb3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa143e6b-b246-4240-b2cd-a47127b66d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_data = './dataset/demo_train.csv'\n",
    "    MAX_INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8663-a48b-4484-95e6-030f2b06bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(args.train_data).reset_index(drop = True)\n",
    "#df_valid = pd.read_csv(args.valid_data).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96b93e-d2a1-4d19-b9b3-e507723d7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34566812-f99a-48b9-bcd7-051a4cff8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8dfb-4b8f-41e3-aa6a-c35ed2e20497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4245f-0814-4e75-b331-d1f1dd74acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['prompt'] ] * 2\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in ['response_a','response_b']]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='longest_first', \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f1e96-9cf9-4039-83ad-4f34bb69643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example['response_a'] + \" [SEP]\" +  \" #### \" + example['prompt'] + \" [SEP] \" + example['response_b'] + \" [SEP]\"]\n",
    "    tokenized_example = tokenizer(sentences, truncation=True, \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e1b3-d2fe-4c4d-ae98-401615cb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df_train)\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcd2e8-74f0-4918-98d5-4790cf54bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7921b57-ffd9-432d-a200-3ef4d64aa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b'])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871078b7-fc9f-4d8f-aa1a-afaefb54ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e662d-18dc-4bb6-8004-feb62a45800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cd8f4-89f1-4119-ba28-20d748dbf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb1a5-81e0-4aec-811f-4266c1091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:1000,].reset_index(drop = True).to_csv('demo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff107e9b-505b-4a35-b371-abc989431e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[1000:1200,].reset_index(drop = True).to_csv('demo_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cdb18f-3bd3-4da0-9a92-dd0a6379ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice, AutoModelForSequenceClassification, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703200-17d7-4dba-b1f5-4930041f30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'meta-llama/llama-3-transformers-8b-hf-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eee09-f821-4697-bfe0-052896b9595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<pad>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e199e-c8fb-4235-a8be-b6588c43a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "128256 in tokenizer(\"<pad>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2e05f-33ec-4fe2-b480-c559c688b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c6d1-ef34-49b9-946f-1546054b097a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513d894-9d5a-456a-9156-0d80c4a33cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# config.hidden_dropout_prob = args.dropout_rate\n",
    "# config.attention_probs_dropout_prob = args.dropout_rate\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "#     inference_mode=False,\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias = 'none',\n",
    "#     target_modules=[\"q_proj\",\"k_proj\",\"v_proj\"]  # Target specific modules\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ae33e-53db-4e13-ab78-324866c4a071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.state_dict():\n",
    "        print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810429ba-c85b-43c7-a55a-843629551fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133fe9-2ac5-430c-80ee-e4b1c06c8751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914da54-a43e-4e44-a575-75265d875359",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.dtype for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3d21cd-15e4-480b-b786-b8027c511b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27711f9c-63ab-4780-9698-ac3a8bb4814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['What is the difference between OpenCL and CU...</td>\n",
       "      <td>['OpenCL and CUDA are two different programmin...</td>\n",
       "      <td>['OpenCL and CUDA are both programming languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2564acd09e3942fd97657d05282d4389</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['Why did my parent not invite me to their wed...</td>\n",
       "      <td>['It is possible that your parent did not invi...</td>\n",
       "      <td>['It is likely that they wanted to keep the gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Fuji vs. Nikon, which is better?']</td>\n",
       "      <td>['Both Fuji and Nikon are popular camera brand...</td>\n",
       "      <td>[\"This is a subjective question and the answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['How to build an arena for chatbots?']</td>\n",
       "      <td>['Building an arena for chatbots can be done b...</td>\n",
       "      <td>['Building an arena for chatbots is a great wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['When is it today?']</td>\n",
       "      <td>[\"I'm sorry, I cannot determine the current da...</td>\n",
       "      <td>['Today is February 23, 2023.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>8777c4945d85469d96cd26fc2ea6f64a</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['who is the president of the U.S.A?']</td>\n",
       "      <td>['Joe Biden is currently the President of the ...</td>\n",
       "      <td>['Joe Biden is currently the 46th president of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>86063a921be548989c55b85497ab009a</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['how to train lora for stable diffusion? expl...</td>\n",
       "      <td>[\"Training Stable Diffusion models like LoRA r...</td>\n",
       "      <td>[\"Lora is a machine learning model that is use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>6685a3b3863f4554887e432f7dbbe8a5</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['남녀 섹스 체위 자세 10가지를 적어줘']</td>\n",
       "      <td>['1. 웨이퍼 에폭보: 남녀 섹스로 웨이퍼 에폭보는 이미 입문으로 이루어져 있는 ...</td>\n",
       "      <td>['1.\\t\"섹스\"\\n2.\\t\"체\"\\n3.\\t\"위\"\\n4.\\t\"자\"\\n5.\\t\"세\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>f72930b382e949ea879e7abf3cb1e587</td>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['how to evaluate a language model output?']</td>\n",
       "      <td>[\"Evaluating a language model output involves ...</td>\n",
       "      <td>[\"Evaluating the output of a language model in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>a147958b2bd049229facdbffa72a4662</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['generate a detailed description on how to us...</td>\n",
       "      <td>['Power Automate is a powerful tool that allow...</td>\n",
       "      <td>['Power Automate is a powerful tool that allow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id            model_a            model_b  \\\n",
       "0      58210e39b3fd4441a2bd4a518bb44c2d         chatglm-6b          koala-13b   \n",
       "1      2564acd09e3942fd97657d05282d4389   oasst-pythia-12b         alpaca-13b   \n",
       "2      90bfd142157948aba01931726c888e7f          koala-13b   oasst-pythia-12b   \n",
       "3      a7c5accc53e649a3bc6b2e41d962ebc4         vicuna-13b   oasst-pythia-12b   \n",
       "4      adf27e819a3c494cb6e993f0c660e097         vicuna-13b          koala-13b   \n",
       "...                                 ...                ...                ...   \n",
       "32995  8777c4945d85469d96cd26fc2ea6f64a         alpaca-13b  claude-instant-v1   \n",
       "32996  86063a921be548989c55b85497ab009a  claude-instant-v1        guanaco-33b   \n",
       "32997  6685a3b3863f4554887e432f7dbbe8a5       wizardlm-13b   oasst-pythia-12b   \n",
       "32998  f72930b382e949ea879e7abf3cb1e587        guanaco-33b          koala-13b   \n",
       "32999  a147958b2bd049229facdbffa72a4662         chatglm-6b       wizardlm-13b   \n",
       "\n",
       "       winner_model_a  winner_model_b  winner_tie  \\\n",
       "0                   0               1           0   \n",
       "1                   0               0           1   \n",
       "2                   0               1           0   \n",
       "3                   0               1           0   \n",
       "4                   1               0           0   \n",
       "...               ...             ...         ...   \n",
       "32995               0               0           1   \n",
       "32996               1               0           0   \n",
       "32997               0               1           0   \n",
       "32998               1               0           0   \n",
       "32999               0               0           1   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      ['What is the difference between OpenCL and CU...   \n",
       "1      ['Why did my parent not invite me to their wed...   \n",
       "2                   ['Fuji vs. Nikon, which is better?']   \n",
       "3                ['How to build an arena for chatbots?']   \n",
       "4                                  ['When is it today?']   \n",
       "...                                                  ...   \n",
       "32995             ['who is the president of the U.S.A?']   \n",
       "32996  ['how to train lora for stable diffusion? expl...   \n",
       "32997                          ['남녀 섹스 체위 자세 10가지를 적어줘']   \n",
       "32998       ['how to evaluate a language model output?']   \n",
       "32999  ['generate a detailed description on how to us...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      ['OpenCL and CUDA are two different programmin...   \n",
       "1      ['It is possible that your parent did not invi...   \n",
       "2      ['Both Fuji and Nikon are popular camera brand...   \n",
       "3      ['Building an arena for chatbots can be done b...   \n",
       "4      [\"I'm sorry, I cannot determine the current da...   \n",
       "...                                                  ...   \n",
       "32995  ['Joe Biden is currently the President of the ...   \n",
       "32996  [\"Training Stable Diffusion models like LoRA r...   \n",
       "32997  ['1. 웨이퍼 에폭보: 남녀 섹스로 웨이퍼 에폭보는 이미 입문으로 이루어져 있는 ...   \n",
       "32998  [\"Evaluating a language model output involves ...   \n",
       "32999  ['Power Automate is a powerful tool that allow...   \n",
       "\n",
       "                                              response_b  \n",
       "0      ['OpenCL and CUDA are both programming languag...  \n",
       "1      ['It is likely that they wanted to keep the gu...  \n",
       "2      [\"This is a subjective question and the answer...  \n",
       "3      ['Building an arena for chatbots is a great wa...  \n",
       "4                        ['Today is February 23, 2023.']  \n",
       "...                                                  ...  \n",
       "32995  ['Joe Biden is currently the 46th president of...  \n",
       "32996  [\"Lora is a machine learning model that is use...  \n",
       "32997  ['1.\\t\"섹스\"\\n2.\\t\"체\"\\n3.\\t\"위\"\\n4.\\t\"자\"\\n5.\\t\"세\"...  \n",
       "32998  [\"Evaluating the output of a language model in...  \n",
       "32999  ['Power Automate is a powerful tool that allow...  \n",
       "\n",
       "[33000 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e38681-9f85-423b-848e-b0a888249ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39283/39283 [00:16<00:00, 2343.84it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid = load_split_data('dataset/lmsys-chatbot_arena_conversations-33k.csv', 2, 3000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3c925c-5c5e-4680-ab26-5f1bdbf90cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39283/39283 [00:16<00:00, 2331.52it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid = load_split_data('dataset/lmsys-chatbot_arena_conversations-33k.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f96254-d439-4d83-9c2f-8fb7f3f67968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b569eb7b-292b-4ab8-bbfb-6cc66f159a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>#Prompt\\nWhat is the difference between OpenCL...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2564acd09e3942fd97657d05282d4389</td>\n",
       "      <td>#Prompt\\nWhy did my parent not invite me to th...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>#Prompt\\nFuji vs. Nikon, which is better?\\n\\n#...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
       "      <td>#Prompt\\nHow to build an arena for chatbots?\\n...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
       "      <td>#Prompt\\nWhen is it today?\\n\\n#Response\\n##Mod...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33013</th>\n",
       "      <td>8777c4945d85469d96cd26fc2ea6f64a</td>\n",
       "      <td>#Prompt\\nwho is the president of the U.S.A?\\n\\...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33014</th>\n",
       "      <td>86063a921be548989c55b85497ab009a</td>\n",
       "      <td>#Prompt\\nhow to train lora for stable diffusio...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33015</th>\n",
       "      <td>6685a3b3863f4554887e432f7dbbe8a5</td>\n",
       "      <td>#Prompt\\n남녀 섹스 체위 자세 10가지를 적어줘\\n\\n#Response\\n#...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33016</th>\n",
       "      <td>f72930b382e949ea879e7abf3cb1e587</td>\n",
       "      <td>#Prompt\\nhow to evaluate a language model outp...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33017</th>\n",
       "      <td>a147958b2bd049229facdbffa72a4662</td>\n",
       "      <td>#Prompt\\ngenerate a detailed description on ho...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33018 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0      58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "1      2564acd09e3942fd97657d05282d4389   \n",
       "2      90bfd142157948aba01931726c888e7f   \n",
       "3      a7c5accc53e649a3bc6b2e41d962ebc4   \n",
       "4      adf27e819a3c494cb6e993f0c660e097   \n",
       "...                                 ...   \n",
       "33013  8777c4945d85469d96cd26fc2ea6f64a   \n",
       "33014  86063a921be548989c55b85497ab009a   \n",
       "33015  6685a3b3863f4554887e432f7dbbe8a5   \n",
       "33016  f72930b382e949ea879e7abf3cb1e587   \n",
       "33017  a147958b2bd049229facdbffa72a4662   \n",
       "\n",
       "                                         prompt_response label  \n",
       "0      #Prompt\\nWhat is the difference between OpenCL...     B  \n",
       "1      #Prompt\\nWhy did my parent not invite me to th...     C  \n",
       "2      #Prompt\\nFuji vs. Nikon, which is better?\\n\\n#...     B  \n",
       "3      #Prompt\\nHow to build an arena for chatbots?\\n...     B  \n",
       "4      #Prompt\\nWhen is it today?\\n\\n#Response\\n##Mod...     A  \n",
       "...                                                  ...   ...  \n",
       "33013  #Prompt\\nwho is the president of the U.S.A?\\n\\...     C  \n",
       "33014  #Prompt\\nhow to train lora for stable diffusio...     A  \n",
       "33015  #Prompt\\n남녀 섹스 체위 자세 10가지를 적어줘\\n\\n#Response\\n#...     B  \n",
       "33016  #Prompt\\nhow to evaluate a language model outp...     A  \n",
       "33017  #Prompt\\ngenerate a detailed description on ho...     C  \n",
       "\n",
       "[33018 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369f833-3ecb-4ba9-80ca-9d373596e882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "prompt_response = df_train.loc[1,'prompt_response']\n",
    "label = df_train.loc[1,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610e855-5fa7-4a26-85c3-11f9cc69a3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5a0df-a66b-49a9-9531-3e66aca3f001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([1,\n",
    " 32006,\n",
    " 887,\n",
    " 526])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec7fee-0823-458a-94a5-cd8fb24d734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd68316-0e01-4fc4-8f76-e5b62da4cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('<|system|>\\nYou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a28b7-ac2b-4bbc-9b48-6eeb7c7253ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('Apple\\nBa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96200af2-961a-4d23-a0f4-99d317f17889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([396,\n",
    " 18571,\n",
    " 415,\n",
    " 13,\n",
    " 4548,\n",
    " 7420,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6808dc-9877-4d5f-a3d4-798c49009e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([29933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece7e34-75cf-4d86-9e39-3a17f463b2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(templete_part1 + prompt_response + templete_part2 + templete_part3 + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f43ec6-c8e9-47c9-98d4-0c1a715a3db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templete_part1 = \"<|system|>\\nYou are a helpful assistant good at judging conversations.<|end|>\\n<|user|>\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "templete_part3 = \"<|assistant|>\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids'][1:]\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92cb47-4478-4597-a027-9662c47c7f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Apple\"\n",
    "prompt_response = templete_part1 + text + templete_part2 + templete_part3 + label + tokenizer.eos_token\n",
    "print(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff6eef-20e1-4df6-b415-7e614fa8066f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'microsoft/LLM-Research/Phi-3-mini-4k-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d64949-df75-4c8d-9b3e-41b60c220736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b820-f8d4-4eac-835f-bef80e20fd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13130933-64c5-4d13-ba8f-3ad126a0ecbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0c18-8a90-4077-8451-aee573084dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70aa3-6a54-4099-8625-1bf211e3b613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a00c5-2dc1-4942-bd80-58101d6eef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15f353-3c10-412f-9d4d-a9c6832d8f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519312-0c1c-4e21-8526-29f562ed0e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faccc94-8a02-434e-a0ca-99dbe8bf4db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('<|user|>',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9affb58-cf74-4b77-a743-00d3cb6f7a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AutoModelForCausalLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8039867-2794-42d5-9fd6-90e7073be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f49e-457b-4050-97fc-c0b6746b2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767040-e7e4-4fb6-a4ec-79cea4150a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete_part1 = \"<|im_start|>system\\nYou are a helpful assistant good at judging conversations.<|im_end|>\\n<|im_start|>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|im_end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids']\n",
    "#print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "templete_part3 = \"<|im_start|>assistant\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids']\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b518309-3e5d-4351-bc8e-cc28a1cebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(14374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba6b18-5775-445a-ab14-1a80cc6ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token,tokenizer.eos_token,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd0f3-6d2d-4f8a-9880-60fbc84c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3adf3-efa3-4add-bbfb-bd6aaf262584",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen2-7B-Instruct'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "                                             config=config,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6626eb-0734-4649-bed8-87e0e5f4d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
