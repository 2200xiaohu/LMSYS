{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301579c-9b27-4180-96c4-d7d921bdb3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    PeftModel,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import os\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa143e6b-b246-4240-b2cd-a47127b66d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_data = './dataset/demo_train.csv'\n",
    "    MAX_INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be13dab-030b-4818-9224-1bc00703f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'google/gemma-2-9b-it'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "                                             config=config,\n",
    "                                             #quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8522a0-7cfa-43ad-a402-55ed6477e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "            task_type=TaskType.CAUSAL_LM,  # For sequence classification\n",
    "            inference_mode=False,\n",
    "            r=32,\n",
    "            lora_alpha=64,\n",
    "            lora_dropout=0.5,\n",
    "            #bias = 'none',\n",
    "            target_modules=['q_proj','k_proj','v_proj','o_proj'] #,\n",
    "        )\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8932a3a-ab7e-49f1-b0d8-1d3a8af4a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "    param.data = param.data.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3bd5c-df22-4d8d-a974-d81341d6e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "?LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e95d2-e9ea-4fb8-98c6-e635f588a4c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.state_dict():\n",
    "    print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc37429-09bc-44c7-b77d-946bb7f45267",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8663-a48b-4484-95e6-030f2b06bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(args.train_data).reset_index(drop = True)\n",
    "#df_valid = pd.read_csv(args.valid_data).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96b93e-d2a1-4d19-b9b3-e507723d7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34566812-f99a-48b9-bcd7-051a4cff8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8dfb-4b8f-41e3-aa6a-c35ed2e20497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4245f-0814-4e75-b331-d1f1dd74acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['prompt'] ] * 2\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in ['response_a','response_b']]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='longest_first', \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f1e96-9cf9-4039-83ad-4f34bb69643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example['response_a'] + \" [SEP]\" +  \" #### \" + example['prompt'] + \" [SEP] \" + example['response_b'] + \" [SEP]\"]\n",
    "    tokenized_example = tokenizer(sentences, truncation=True, \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbfaa0a-1d8b-43c4-8516-5d00a9bf209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Review the user’s question and the corresponding response, along with two judgments. Determine which judgment is more accurate according to the rubric provided below. The rubric used for the initial judgments is as follows:\n",
    "- Add 1 point if the response is relevant and provides some information related to\n",
    "the user’s inquiry, even if it is incomplete or contains some irrelevant content.\n",
    "- Add another point if the response addresses a substantial portion of the user’s question,\n",
    "but does not completely resolve the query or provide a direct answer.\n",
    "- Award a third point if the response answers the basic elements of the user’s question in a\n",
    "useful way, regardless of whether it seems to have been written by an AI Assistant or if it\n",
    "has elements typically found in blogs or search results.\n",
    "- Grant a fourth point if the response is clearly written from an AI Assistant’s perspective,\n",
    "addressing the user’s question directly and comprehensively, and is well-organized and helpful,\n",
    "even if there is slight room for improvement in clarity, conciseness or focus.\n",
    "- Bestow a fifth point for a response that is impeccably tailored to the user’s question\n",
    "by an AI Assistant, without extraneous information, reflecting expert knowledge, and\n",
    "demonstrating a high-quality, engaging, and insightful answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e1b3-d2fe-4c4d-ae98-401615cb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df_train)\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcd2e8-74f0-4918-98d5-4790cf54bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7921b57-ffd9-432d-a200-3ef4d64aa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b'])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871078b7-fc9f-4d8f-aa1a-afaefb54ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e662d-18dc-4bb6-8004-feb62a45800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cd8f4-89f1-4119-ba28-20d748dbf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb1a5-81e0-4aec-811f-4266c1091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:1000,].reset_index(drop = True).to_csv('demo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff107e9b-505b-4a35-b371-abc989431e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[1000:1200,].reset_index(drop = True).to_csv('demo_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdb18f-3bd3-4da0-9a92-dd0a6379ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice, AutoModelForSequenceClassification, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703200-17d7-4dba-b1f5-4930041f30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'meta-llama/llama-3-transformers-8b-hf-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eee09-f821-4697-bfe0-052896b9595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<pad>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e199e-c8fb-4235-a8be-b6588c43a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "128256 in tokenizer(\"<pad>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2e05f-33ec-4fe2-b480-c559c688b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c6d1-ef34-49b9-946f-1546054b097a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513d894-9d5a-456a-9156-0d80c4a33cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# config.hidden_dropout_prob = args.dropout_rate\n",
    "# config.attention_probs_dropout_prob = args.dropout_rate\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "#     inference_mode=False,\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias = 'none',\n",
    "#     target_modules=[\"q_proj\",\"k_proj\",\"v_proj\"]  # Target specific modules\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ae33e-53db-4e13-ab78-324866c4a071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.state_dict():\n",
    "        print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810429ba-c85b-43c7-a55a-843629551fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133fe9-2ac5-430c-80ee-e4b1c06c8751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914da54-a43e-4e44-a575-75265d875359",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.dtype for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d21cd-15e4-480b-b786-b8027c511b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e38681-9f85-423b-848e-b0a888249ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/1k_mt_bench_human_judgments.json', 1, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c925c-5c5e-4680-ab26-5f1bdbf90cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/lmsys-chatbot_arena_conversations-33k.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f96254-d439-4d83-9c2f-8fb7f3f67968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569eb7b-292b-4ab8-bbfb-6cc66f159a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369f833-3ecb-4ba9-80ca-9d373596e882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "prompt_response = df_train.loc[idx,'prompt_response']\n",
    "label = df_train.loc[idx,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36874c67-b6ab-4415-86d7-89a1d2b81e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_response)\n",
    "print(\"\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610e855-5fa7-4a26-85c3-11f9cc69a3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5a0df-a66b-49a9-9531-3e66aca3f001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([1,\n",
    " 32006,\n",
    " 887,\n",
    " 526])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec7fee-0823-458a-94a5-cd8fb24d734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd68316-0e01-4fc4-8f76-e5b62da4cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('<|system|>\\nYou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a28b7-ac2b-4bbc-9b48-6eeb7c7253ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('Apple\\nBa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96200af2-961a-4d23-a0f4-99d317f17889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([396,\n",
    " 18571,\n",
    " 415,\n",
    " 13,\n",
    " 4548,\n",
    " 7420,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6808dc-9877-4d5f-a3d4-798c49009e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([29933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece7e34-75cf-4d86-9e39-3a17f463b2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(templete_part1 + prompt_response + templete_part2 + templete_part3 + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f43ec6-c8e9-47c9-98d4-0c1a715a3db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templete_part1 = \"<|system|>\\nYou are a helpful assistant good at judging conversations.<|end|>\\n<|user|>\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "templete_part3 = \"<|assistant|>\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids'][1:]\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92cb47-4478-4597-a027-9662c47c7f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Apple\"\n",
    "prompt_response = templete_part1 + text + templete_part2 + templete_part3 + label + tokenizer.eos_token\n",
    "print(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff6eef-20e1-4df6-b415-7e614fa8066f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'microsoft/LLM-Research/Phi-3-mini-4k-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d64949-df75-4c8d-9b3e-41b60c220736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b820-f8d4-4eac-835f-bef80e20fd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13130933-64c5-4d13-ba8f-3ad126a0ecbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0c18-8a90-4077-8451-aee573084dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70aa3-6a54-4099-8625-1bf211e3b613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a00c5-2dc1-4942-bd80-58101d6eef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15f353-3c10-412f-9d4d-a9c6832d8f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519312-0c1c-4e21-8526-29f562ed0e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faccc94-8a02-434e-a0ca-99dbe8bf4db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('<|user|>',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9affb58-cf74-4b77-a743-00d3cb6f7a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AutoModelForCausalLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8039867-2794-42d5-9fd6-90e7073be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f49e-457b-4050-97fc-c0b6746b2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767040-e7e4-4fb6-a4ec-79cea4150a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete_part1 = \"<|im_start|>system\\nYou are a helpful assistant good at judging conversations.<|im_end|>\\n<|im_start|>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|im_end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids']\n",
    "#print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "templete_part3 = \"<|im_start|>assistant\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids']\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b518309-3e5d-4351-bc8e-cc28a1cebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(14374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba6b18-5775-445a-ab14-1a80cc6ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token,tokenizer.eos_token,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd0f3-6d2d-4f8a-9880-60fbc84c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3adf3-efa3-4add-bbfb-bd6aaf262584",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen2-7B-Instruct'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "                                             config=config,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6626eb-0734-4649-bed8-87e0e5f4d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d36ad-0414-420b-8b31-cada77b616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")\n",
    "#tmp2 = pd.read_json(\"dataset/lmsys-chatbot_arena_conversations-33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4ea73-9ce7-4be2-97b9-9d7b7e23319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.drop(columns = ['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac00263-f6e8-4e9f-bc76-c38ca147433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tmp,tmp2]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a47b-4730-42d0-addf-a753c40e499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87799cfd-2202-4cf7-b8f5-3440402a0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8c8a5-537c-4bbc-906d-0248a7cd8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[46969][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5501c-3b89-4305-af30-145af6105739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tmp = tmp[tmp['prompt'].apply(lambda x: is_english(x[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91e910-3568-4040-879c-7a5de5898e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812975-88eb-4906-8b49-20acf0219e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397612b-9c86-4952-9d77-827e64a83f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.read_csv(\"dataset/kaggle-ultrafeedback-drop-duplicate.csv\")\n",
    "tie = pd.read_csv(\"dataset/kaggle-ultrafeedback-ties-drop-duplicate.csv\")\n",
    "p = pd.read_csv(\"dataset/ultrafeedback_prediction.csv\")\n",
    "\n",
    "from utils import load_json\n",
    "ex = load_json(ex)\n",
    "tie = load_json(tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfe20a-8a72-4954-88f7-2965c2a47c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([tie,ex]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf4c04-5ffe-4397-9feb-926a8decdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fb5a9-0a61-4f0a-bb23-3c7a8777294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.rename(columns = {'winner_model_a':\"p_winner_model_a\", 'winner_model_b':\"p_winner_model_b\",  'winner_tie':\"p_winner_tie\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c73849-7179-4356-a75b-655e6edf1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([total, p], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdc1d3-9ef3-400f-80f6-c581a75865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9eccb-3d7a-44d6-9ecb-1367c6c0a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_label(row):\n",
    "    a = row.p_winner_model_a\n",
    "    b = row.p_winner_model_b\n",
    "    c = row.p_winner_tie\n",
    "\n",
    "    l = [a ,b, c]\n",
    "    label = l.index(max(l))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b94fa-0da9-429e-b5ea-cc3f79d919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['p_label'] = final.apply(get_p_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a4b32-8e0e-4344-99f5-64842e12798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]\n",
    "\n",
    "final['label'] = final.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b29ace-02a7-4eb9-95e1-839d8412bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = final.loc[final.p_label == final.label,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f23955-a534-4b0c-a550-e6e7ea842d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "filter_list = (filter.p_winner_model_a >= threshold) | (filter.p_winner_model_b >= threshold) | (filter.p_winner_tie >= threshold)\n",
    "filter = filter.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7f45c-eed3-4cc9-b9f8-59f236e35fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.prompt.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18a8d9-5420-420c-aa39-d0542014f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "filter_only_english = filter[filter['prompt'].apply(lambda x: is_english(x[0][:30]))].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaacf40-33eb-43ac-8b5d-a39364789553",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "filter[save_columns].to_json(f\"dataset/70k_filter_threshold{threshold}.json\", index = False)\n",
    "filter_only_english[save_columns].to_json(f\"dataset/70k_filter_only_english_threshold{threshold}.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c837a-49ed-4aa7-a593-1386f142b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter[save_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fb069-98e8-4026-9281-e8c77a6dd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fe057-4069-4291-8c21-adc21bffdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/train.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534beaf2-5d64-4675-a1c1-ff69334ed34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12e930-77fa-43c6-ab43-b0de8cadd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7b1b8-ef82-492e-b540-cc6343ab677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f42ec-4288-4707-9b8d-68d399e157ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.label.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdd206-f405-436c-b427-fd29134d55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/70k_filter_only_english_threshold0.9.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c2706-3696-4791-9148-ee20edf6135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2dbdf-6617-4efe-a881-f11e242bd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_least_similar_by_prompt_same_prediction_thr90.csv\"\n",
    "t = pd.read_csv(data_path)\n",
    "t['id'] = [randint(10000,99999) + i for i in range(len(t))]\n",
    "t.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d61e42-5510-4791-8292-3984e426b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_most_similar_by_prompt_same_prediction_thr90.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446a850-aa64-4fa1-81f8-afc92ce27a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb349e04-4248-40c4-9d75-eef94ab775d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , valid = load_split_data('dataset/train_sample10k_switch.json', 2, 2300, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4ceac-a77e-46a3-b273-a339ec57c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train.id.to_list()\n",
    "valid_id = valid.id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04567f8-98b7-447d-ac2f-67bb651eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd7bce-7769-4260-bdee-254ec7b07893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_str'] = data['prompt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc917-3fa5-4b36-aabb-1da1a98e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504410a3-6bc6-4230-bb9f-faaeec30082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb12d2-614f-4a99-b213-024431dc6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)]\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc7c15-0733-40b8-8e61-9f2119442d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data.id.isin(train_id)].reset_index(drop = True)\n",
    "valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b5924-8905-4a00-bac5-304ab7300b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in train_id if i in valid_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983324e4-e2d6-488a-9786-dca934f54122",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638216d1-f0ed-47c4-ac1b-9757b62ad911",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json('dataset/train_sample10k_switch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6110b-1ac8-47fc-9f5f-1b91141b2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd71b88-1a0c-497e-9f7c-011856dc4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = [['I read 60 pages of a book on Monday and 1/4 of the book on Tuesday. I completed the remaining 1/8 of the book on Wednesday. How many total pages are in the book?']]\n",
    "train.loc[train.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8475c-9524-440e-865c-671668b261ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.loc[valid.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb115c-369b-4d3b-a7fe-ac84c8a48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15847f0d-36c6-4a64-ae1b-813397cd2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in train.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8493bdb-b140-49f7-8494-c4b96085e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e90e88-23e3-4d49-867b-af17f6cbedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, False)\n",
    "valid_id = valid.id.tolist()\n",
    "train_id = train.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49777e8-68b2-4b66-a557-f95a377b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22529285-1ddf-4b23-a168-6271c96f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.loc[data.id.isin(train_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e9ca6-696c-42aa-ae26-2b76b12938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.sample(10000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42cbb8-c0f3-4001-902c-934186926d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_id = s.id.to_list()\n",
    "len([i for i in s_id if i in valid_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a8d38-9126-47d4-b39c-e2d87971b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)\n",
    "[i for i in s.prompt.values.tolist() if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f585cc1-d017-49ec-9ed8-7fbd25e4715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35115fa6-eaad-4f2a-a4b7-9ad7097460dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(tmp_valid.prompt.values.tolist()) if i in ex_33.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037325e-acb4-4e3c-ae0a-b9fdb72122a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid = tmp_valid.iloc[idx,:].reset_index(drop = True)\n",
    "not_same_prompt_in_valid = tmp_valid.iloc[~tmp_valid.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5609a2-b86f-4e6e-a83d-db86707c660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same_prompt_in_valid) + len(same_prompt_in_valid) == len(tmp_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649893d-532a-4df3-a4b5-b2e2721ee2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid.to_json(\"dataset/same_prompt_in_valid.json\", index = False)\n",
    "not_same_prompt_in_valid.to_json(\"dataset/not_same_prompt_in_valid.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee8612-2347-4d97-9486-48081621594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_prompt_in_valid.sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74c85f-e114-48a2-ab85-053bfe33c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ex = [idx for idx, i in enumerate(ex_33.prompt.values.tolist()) if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddc907-3387-4442-8ace-47f4a9e95f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33.iloc[idx_ex,:].reset_index(drop = True).sort_values(by = ['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e6673-b2d7-4e85-aa0d-9c3ebe87c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/pass/demo_A2B2C.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d0244-ab36-45e0-9e06-f1aef01623cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.sample(int(len(data) * 0.3)).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582e3d0-3077-4df1-93f3-df37d0e6f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb1a57-d15e-4597-b365-9c3af9858464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(row):\n",
    "    response_a = row.response_a\n",
    "    response_b = row.response_b\n",
    "\n",
    "    row.response_a = response_b\n",
    "    row.response_b = response_a\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4db282-2500-4d51-abd8-98925acf4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884260e-980b-4f63-be50-367369c53edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([s, data]).reset_index(drop = True)\n",
    "final['id'] = [randint(1000,999999) + i for i in range(len(final))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd823e94-95bc-47b0-9d64-2e9107b23c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "final.to_json(f\"dataset/pass/demo_A2B2C_tta.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00951469-3ca1-4a55-8f43-ba30b95ea820",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/train_sample10k_switch.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae7b3e-d15e-46ae-9f46-d6a2b851fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/pass/demo_A2B2C_tta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91f56f-a43d-4a37-a4e3-6eba8f7ee83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46094679-24f9-41ac-a917-af37289e4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check.prompt.values[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265b4e-9874-40b1-8611-80304241826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a == t.response_b, 'winner_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bd58e-be57-4494-b225-eab3b8ced348",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a=='[\"Hyderabad\"]', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573737e-3527-4eee-8435-85fa3fe5369a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == '[null]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cd37c-f776-42fb-b032-b316ece6721b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b) & (t.winner_tie != 1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de252b78-4025-4231-a709-c3e274a0f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223df7-9d38-4b76-905a-ae3e82fc9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[3844:3847,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f59df-7447-42d1-a7d7-8fd6b1d399c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d8b99-84b5-441e-81ae-cef57508556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)\n",
    "\n",
    "ex_33 = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')\n",
    "ex_33 = load_json(ex_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0eea3-cd5c-4858-a913-b3d6cfc2fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、找出train里面不与33k重复部分\n",
    "2、不重复的部分再划分\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dae53d-5ce4-4e73-9d82-6c0877c50813",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in data.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "data['set_prompt_response'] = set_prompt_response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283dda44-0b15-4663-a42f-01d7122095db",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt_response = []\n",
    "for i in ex_33.itertuples():\n",
    "    prompt_response = i.prompt + i.response_a + i.response_b\n",
    "    set_prompt_response.append(set(prompt_response))\n",
    "ex_33['set_prompt_response'] = set_prompt_response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36347ed-529c-4d49-8a73-1a0b412cd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, i in enumerate(data.set_prompt_response.values) if i in ex_33.set_prompt_response.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed483b00-71b3-41fa-b106-90597b1bbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = data.loc[idx,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fee23-1f22-448a-9530-58b4756ae0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_33.loc[ex_33.set_prompt_response == same.set_prompt_response.values[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad992f3d-4056-46ca-94ba-bd8a19a49030",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_same = data.loc[~data.index.isin(idx),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3841c21-c1dd-4db4-844b-8021376141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(not_same) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc368b-8af0-4980-8f57-2eb6ef4207bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in ex_33.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e9cde-27fe-4de4-845b-63a6ebf7ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(not_same.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636297d2-367c-4c15-9971-7e61b92a8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sets = not_same['set_prompt_response'].drop_duplicates().reset_index(drop=True)\n",
    "# 将唯一集合进行随机划分\n",
    "unique_sets = unique_sets.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "midpoint = len(unique_sets) // 10\n",
    "set1 = unique_sets.iloc[:midpoint]\n",
    "set2 = unique_sets.iloc[midpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f86bff-f5d2-47fc-be6a-61223fe80893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分结果从原数据集中提取对应的行\n",
    "valid = not_same[not_same['set_prompt_response'].isin(set1)].reset_index(drop=True)\n",
    "train_subset = not_same[not_same['set_prompt_response'].isin(set2)].reset_index(drop=True)\n",
    "assert len(valid) + len(train_subset) == len(not_same)\n",
    "assert len(valid) + len(train_subset) + len(same) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89953790-8cbc-43de-918a-a01a93d00290",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3820ec6-5b66-4e09-8864-cee95db0d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in same.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587ad10-5f15-427b-a4dc-4062b111453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exclude_valid = pd.concat([train_subset, same]).reset_index(drop=True) #train 里面排除valid\n",
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836e690-eeab-45e0-8d53-8232e707b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(valid) + len(train_exclude_valid) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d058d-08ef-46bf-bf62-4d8a7f4b0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.concat([train_subset, ex_33]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae603b-b74f-4b7e-935b-bc695803ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train.drop(columns = ['set_prompt_response'])\n",
    "valid = valid.drop(columns = ['set_prompt_response'])\n",
    "train_exclude_valid = train_exclude_valid.drop(columns = ['set_prompt_response'])\n",
    "train_33k = train_33k.drop(columns = ['set_prompt_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45f9eb-364b-4b48-98d2-69da13e3c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_json(\"dataset/non_overlap/train_subset.json\", index = False)\n",
    "valid.to_json(\"dataset/non_overlap/valid.json\", index = False)\n",
    "train_exclude_valid.to_json(\"dataset/non_overlap/train_exclude_valid.json\", index = False)\n",
    "train_33k.to_json(\"dataset/non_overlap/train_33k.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011da0b-5683-46e8-819b-fcd2dd9d09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查\n",
    "train_subset = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "valid = pd.read_json(\"dataset/non_overlap/valid.json\")\n",
    "train_exclude_valid = pd.read_json(\"dataset/non_overlap/train_exclude_valid.json\")\n",
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec1423-87a3-4c6a-85fb-10023d83333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9c632-6445-477e-8852-dade97bcf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = get_set_prompt_response(train_subset)\n",
    "valid = get_set_prompt_response(valid)\n",
    "train_exclude_valid = get_set_prompt_response(train_exclude_valid)\n",
    "train_33k = get_set_prompt_response(train_33k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32be80f-adf4-488d-b854-9a20bc7733b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid和任何都不重合\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_subset.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_exclude_valid.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in train_33k.set_prompt_response.values]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fccd76-c374-4c6e-bc07-197e164c6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d8c0f-5898-42a9-88b6-69f43d84e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取唯一的 prompt 进行划分\n",
    "not_same['prompt_str'] = not_same['prompt'].astype(str)\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)\n",
    "\n",
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)\n",
    "\n",
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)].reset_index(drop = True)\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)].reset_index(drop = True)\n",
    "train = train.drop(columns = ['prompt_str'])\n",
    "valid = valid.drop(columns = ['prompt_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108dda8f-3443-4d3a-ae13-a4cb31e59938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc66039-5fa5-4d94-bdbf-431bd5596571",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = train_33k.sample(15000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906dd20-c569-4b93-93b5-52524dbdc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792de98-379d-4ec9-a4a2-67a6e7aa8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94fd1f-fd7c-48cc-9c01-462a96025e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/non_overlap/train_33k_switch_15k.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2b1c0-8e98-4138-98fb-1c7f86008f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19d9d3-cbf8-4d62-9568-835f19ecd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = get_set_prompt_response(valid)\n",
    "s = get_set_prompt_response(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a3beb-b4de-4b51-8fe5-ef0056ad5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_33k.loc[train_33k.response_b.isin([['Three times 78234 is 234,692.']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128df92c-683f-4631-ae36-2c0d822ba14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in s.set_prompt_response.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cd086-c826-4b73-ac78-1adf1d11088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(\"dataset/non_overlap/train_33k_switch_15k.json\").response_a.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e5d90-4823-4e6b-98cb-92c239172f02",
   "metadata": {},
   "source": [
    "# prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf91ddf-914b-435a-bb59-b97c4e63ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_2(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        id = row['id']\n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            text_length += len(text.split(\" \"))\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = prompt_response[-1] + \"\\n\\n\" + text\n",
    "                prompt_response[-1] = text\n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = len(text.split(\" \"))\n",
    "                ids.append(id)\n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels})\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response})\n",
    "    return data\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dbe8e-423b-4e3c-9302-fe2ab2fa78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_subset.json\")\n",
    "if_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89a02f-2d29-480b-b197-0c247ab1e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate prompt-response\n",
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)\n",
    "\n",
    "#prepare label\n",
    "if if_train:\n",
    "    data['label'] = data.apply(lambda x: get_label(x), axis = 1)\n",
    "\n",
    "data = data.fillna('None')\n",
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1cb0aa-f5ca-4ce0-8959-dacd23597a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955bbbac-6da7-4832-a200-84f4783260d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f9d6f7-4ee6-46cf-a40e-25ef5778f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "反转dataframe\n",
    "用栈，先进后出，超过max length就清空\n",
    "'''\n",
    "def prompt_3(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    从后往前拼接\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "    data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        id = row['id']\n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            text_length += len(text.split(\" \"))\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = text + \"\\n\\n\" + prompt_response[-1]\n",
    "                prompt_response[-1] = text\n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = len(text.split(\" \"))\n",
    "                ids.append(id)\n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc045e-ed87-4249-9656-3341119b9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = prompt_3(data, 1900, True)\n",
    "prompt2 = prompt_2(data, 1900, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451e865-2414-4967-bed3-6c0b02016626",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5aa7f-e372-4393-9d71-31f8215cf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_p3 = prompt3.loc[prompt3.id == 2846599172]\n",
    "#cehck_data = data.loc[data.id == 2846599172]\n",
    "\n",
    "check_p2 = prompt2.loc[prompt3.id == 2846599172]\n",
    "#cehck_data = data.loc[data.id == 2846599172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f4a2b-77ec-49b9-a3ea-11ac0eb01e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cehck_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79a2a4-2ef9-4716-ba63-214b5bf2877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_p3.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d7b64-b3cf-443d-9739-5f3e6322d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_p3.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb892701-03be-46ac-9361-d2bbd709e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt3.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d32670-3e6a-48df-8bf0-8d7afdc4dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt3.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54435ff-df68-405c-9c54-4769b0c0e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17463bf-671d-4e1c-b263-6ffd805226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604688c1-8056-43ac-9ca6-5873b3c4e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_p3.prompt_response.apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e632247-410f-4819-b0a8-91d982e03e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_p2.prompt_response.apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015546b-994b-4930-8f5a-37797b7f9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/mt_bentch_3k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1d272-0aa0-4e50-a0af-3069b72d6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data.type == 'human'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115aa1d7-46d0-4e9f-bbdf-ef0efff9c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(\"dataset/mt_bentch_human.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8de795-681a-44dd-9706-648063568699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    print(label)\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]\n",
    "data['label'] = data.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded09fc-eff9-4100-9181-c8691ceb7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total'] = data.winner_model_a + data.winner_model_b + data.winner_tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfebcc-b46a-48fd-9b35-78edc4a8bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.total == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6b1a7-33dc-4531-b2ed-eb6e09ca7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, _ = load_split_data('dataset/non_overlap/valid.json', 3, 1900, True, False, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcd0e3-1ba4-437d-bc74-6cf451dae974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, _ = load_split_data('dataset/1M/15k_preds.csv', 3, 1900, True, False, False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39038b-8c0a-4f70-90cd-4ab2e7d239a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9bd259-5d14-43ea-b4c5-0034b66052a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_text_length(text):\n",
    "    '''\n",
    "    不用空格分隔的文本, text length = len\n",
    "    不用空格分隔的一般tokenizer后长度类似，所以还可以缩小\n",
    "    空格分隔的，len(text.split(\" \"))\n",
    "    '''\n",
    "    length1 = len(text)\n",
    "    length2 = len(text.split(\" \"))\n",
    "    #远超过\n",
    "    if length1 >= length2 * 30 and length1>= 300:\n",
    "        return length1 * 0.75\n",
    "    return length2\n",
    "    \n",
    "def prompt_3(data, max_length, if_train):\n",
    "    '''\n",
    "    超过max length新开一行，label不变\n",
    "    从后往前拼接\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    '''\n",
    "\n",
    "    data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']\n",
    "    data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    #只有一种可能会超出max length：\n",
    "    #单条的prompt和reponse加在一起超出max length\n",
    "    over_max_length = [] #是否有超出max length的部分\n",
    "    overflow_prompt = []\n",
    "    overflow_response_a = [] #超出max length的部分\n",
    "    overflow_response_b = [] #超出max length的部分\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['prompt_response']\n",
    "        response_a = row['response_a']\n",
    "        response_b = row['response_b']\n",
    "        prompt = row['prompt']\n",
    "        id = row['id']\n",
    "        \n",
    "        if if_train:\n",
    "            label = row['label']\n",
    "        \n",
    "        if id not in ids:\n",
    "            #第一次出现\n",
    "            prompt_response.append(text)\n",
    "            text_length = get_text_length(text)\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "            if text_length > max_length:\n",
    "                over_max_length.append(1)\n",
    "                overflow_prompt.append(prompt)\n",
    "                overflow_response_a.append(response_a)\n",
    "                overflow_response_b.append(response_b)\n",
    "            else:\n",
    "                over_max_length.append(0)\n",
    "                overflow_prompt.append(None)\n",
    "                overflow_response_a.append(None)\n",
    "                overflow_response_b.append(None)\n",
    "        \n",
    "        else:\n",
    "            text_length += get_text_length(text)\n",
    "            if text_length <= max_length:\n",
    "                #取上一个text出来，合并后替换\n",
    "                text = text + \"\\n\\n\" + prompt_response[-1]\n",
    "                prompt_response[-1] = text\n",
    "                over_max_length[-1] = 0\n",
    "                overflow_prompt[-1] = None\n",
    "                overflow_response_a[-1] = None\n",
    "                overflow_response_b[-1] = None\n",
    "                \n",
    "            else:\n",
    "                #另一起一行\n",
    "                prompt_response.append(text)\n",
    "                text_length = get_text_length(text)\n",
    "                ids.append(id)\n",
    "                \n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "                    \n",
    "                #另起一行但超出场合都\n",
    "                if text_length > max_length:\n",
    "                    over_max_length.append(1)\n",
    "                    overflow_prompt.append(prompt)\n",
    "                    overflow_response_a.append(response_a)\n",
    "                    overflow_response_b.append(response_b)\n",
    "                else:\n",
    "                    over_max_length.append(0)\n",
    "                    overflow_prompt.append(None)\n",
    "                    overflow_response_a.append(None)\n",
    "                    overflow_response_b.append(None)\n",
    "                    \n",
    "                \n",
    "                    \n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels, 'overflow_prompt':overflow_prompt, 'over_max_length': over_max_length, 'overflow_response_a': overflow_response_a, 'overflow_response_b': overflow_response_b})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, 'over_max_length': over_max_length, 'overflow_prompt':overflow_prompt, 'overflow_response_a': overflow_response_a, 'overflow_response_b': overflow_response_b})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#反转\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962d0bf-d25c-4cbc-b944-dbbcc24702e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882dd23b-da65-4b67-b3a0-9b6b965f2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_english_text(text):\n",
    "    # 使用正则表达式找到所有英文字母\n",
    "    english_letters = re.findall(r'[a-zA-Z]', text)\n",
    "    \n",
    "    # 如果英文字母的比例超过一定阈值（例如 70%），则认为主要内容是英文\n",
    "    english_ratio = len(english_letters) / len(text)\n",
    "    \n",
    "    return english_ratio > 0.2\n",
    "\n",
    "# 测试函数\n",
    "text = \"This is a test text with some English words and 一些中文字符.\"\n",
    "print(is_english_text(text))  # 输出: True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1707933-ca8a-4b20-a731-a4b3124181ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ee6f9-034d-49df-bde2-286fe9ba577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('None')\n",
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "\n",
    "# data['response_a'] = data['response_a'].apply(lambda x: [\"None\" if i is None else i for i in x])\n",
    "# data['response_b'] = data['response_b'].apply(lambda x: [\"None\" if i is None else i for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d4ea0-8784-434a-bc02-4f2bfa3c0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b745cb-b442-408e-96d8-58bae2d91e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_en'] = data['prompt'].apply(lambda x: is_english_text(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af615634-418d-4b12-868a-714b30b37602",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en =  data.loc[~data.is_en].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9d5fb-8f03-44c6-8a54-0920c89d95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['str_len'] = data['prompt'].apply(len) + data['response_a'].apply(len) + data['response_b'].apply(len)\n",
    "data['split_len'] = data['prompt'].apply(lambda x: len(x.split(\" \"))) + data['response_a'].apply(lambda x: len(x.split(\" \")))  + data['response_b'].apply(lambda x: len(x.split(\" \"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22389f2-1b91-4cb8-9843-cf80a58f8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['str_len'] = data['prompt'].apply(lambda x: sum([len(i) for i in x])) + data['response_a'].apply(lambda x: sum([len(i) for i in x])) + data['response_b'].apply(lambda x: sum([len(i) for i in x]))\n",
    "# data['split_len'] = data['prompt'].apply(lambda x: sum([len(i.split(\" \")) for i in x])) + data['response_a'].apply(lambda x: sum([len(i.split(\" \")) for i in x])) + data['response_b'].apply(lambda x: sum([len(i.split(\" \")) for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5897fc6-b4ee-40aa-8838-1ef7ed95fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (data.str_len >= data.split_len * 30 ) & ( data.str_len >= 500 )\n",
    "non_en = data.loc[idx].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed9986-e805-46fe-b31c-d3e058d07ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c99d1-d68e-4220-8d21-df390c1a7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.loc[data.id == 2789396693]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf2ec6-4cfc-487a-978e-a441b12bc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = prompt_3(tmp, 1900, False)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04df911-1a5d-409d-a3b2-9340727d2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be0a8a-dad0-4498-b1ea-e6021d768884",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'google/gemma-2-9b-it'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7c54e-72f5-4076-b877-65f0524a0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer(t.prompt_response.values[0])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9772c2-56bf-4084-ae38-c4fa3439bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc6157-d604-48d8-8ed8-cf6e66cfc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(235441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27858c0b-e02d-42eb-ad4a-b1c8c78aba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(t.prompt_response.values[0])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301faeb-9dae-41ca-9da4-fc9d9626ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_v2 import load_split_data\n",
    "data_path = \"dataset/non_overlap/train_33k.json\"\n",
    "prompt_type = 3\n",
    "MAX_INPUT = 1900\n",
    "if_train = True\n",
    "split = False\n",
    "if_drop_duplicate = True\n",
    "keep = 'last'\n",
    "base_model = 'google/gemma-2-9b-it'\n",
    "model_path = \"output/misunderstood-flower-508/checkpoint-5459_8857\"\n",
    "MAX_LENGTH = MAX_INPUT\n",
    "\n",
    "df_train , df_valid = load_split_data(data_path, prompt_type, MAX_INPUT, if_train, split, False, if_drop_duplicate, 'last', base_model)\n",
    "test = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b47e43-8c39-435d-bbc1-04e0328c0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test.loc[test.id == 2789396693].prompt_response.values\n",
    "print(tokenizer.decode(text[0])),len(text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6360f-bac1-4e5f-8ca7-7c517674a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = test['label'].apply(tokenizer.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43f1d7-ff8c-4817-ab74-6c81f50c7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.label == 'C'].length.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c07abe-b246-4505-8be9-4e5c48d500df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.label == 'A'].length.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772c73d-7759-448f-89e2-8a5e7d0611e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.label == 'B'].length.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568e721-00e3-45e2-b938-4dfa3ff13684",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = test.loc[test.label == 'C'].length.median()\n",
    "idx = ((test.label == 'C') & ((test.length > m - 100) & (test.length < m + 300))) | ((test.label == 'C') & (test.length == 1916))\n",
    "filter_tie = test.loc[idx].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803f50b-026d-4043-933c-389f8dbee7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940679b5-f2a3-4fbd-b3a6-4303219054c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.length == 1916]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d5f46-ea09-4135-b625-e42b95eb8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_33k_switch_10k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7c6a4-593e-4483-a270-88a89e466dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.id == '5cf1be2e58964aada5f803d3845da7af']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3514adfd-9fa1-4b46-b1eb-fe201bbb9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['length'] = test['prompt_response'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d87c3-99fd-46ca-8b06-ae1ecd7e326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row, tokenizer):\n",
    "\n",
    "    now_data = row\n",
    "    response_a = row['response_a']\n",
    "    response_a_input_ids = tokenizer(text=response_a, add_special_tokens=False, padding=False)['input_ids']\n",
    "    row['response_a_input_ids'] = response_a_input_ids\n",
    "    \n",
    "    response_b = row['response_b']\n",
    "    response_b_input_ids = tokenizer(text=response_b, add_special_tokens=False, padding=False)['input_ids']\n",
    "    row['response_b_input_ids'] = response_b_input_ids\n",
    "    \n",
    "    prompt = row['prompt']\n",
    "    prompt_input_ids = tokenizer(text=prompt, add_special_tokens=False, padding=False)['input_ids']\n",
    "    row['prompt_input_ids'] = prompt_input_ids\n",
    "    \n",
    "    label = now_data['label']\n",
    "    label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "    row['label_ids'] = label_ids\n",
    "\n",
    "    return row\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd314ca-a86d-49de-a570-cee431756618",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc = 'pandas bar')\n",
    "#seperate prompt-response\n",
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)\n",
    "\n",
    "#prepare label\n",
    "if if_train:\n",
    "    data['label'] = data.apply(lambda x: get_label(x), axis = 1)\n",
    "\n",
    "data = data.fillna('None')\n",
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "\n",
    "#分词\n",
    "data = data.progress_apply(lambda x: tokenize(x, tokenizer), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c7b12-9b02-469e-a989-e440d7f2c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['a_length'] = data['response_a_input_ids'].apply(len)\n",
    "data['b_length'] = data['response_b_input_ids'].apply(len)\n",
    "data['p_length'] = data['prompt_input_ids'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a2bfd-26b5-46f7-aaf5-255f2c811c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23577343-8654-4303-865d-9c60583ba093",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A赢，但A明显短于B\n",
    "B赢，但B明显短于A\n",
    "打平，但两者长度差距很大\n",
    "'''\n",
    "\n",
    "idx1 = (data.label == 'A') & (data.a_length * 2 < data.b_length) \n",
    "idx2 = (data.label == 'B') & (data.a_length > data.b_length * 2) \n",
    "idx3 = (data.label == 'C') & ((data.a_length > data.b_length * 3) | (data.a_length * 3 < data.b_length))\n",
    "idx4 = (data.a_length > 1000) | (data.b_length > 1000) | (data.p_length > 1000)\n",
    "final = data[~(idx3 | idx1 | idx2)].reset_index(drop = True)\n",
    "final\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1949fa-6d3f-4cee-a9b0-e274cd54c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = final.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84102a51-01f0-44d0-a5c2-858479c0409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0d19c-37ee-494f-8e5e-542793f57fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = pd.read_json(\"dataset/non_overlap/train_33k_switch_10k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1158b-e50c-4c87-bcab-bce8ffe86136",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = o.loc[o.id.isin(ids)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ba4dc-16f5-4c5f-ad0f-18d4ae80c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed671d8-83c7-47b6-9de0-732e19dfd57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.loc[o.id.isin(ids)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69bdfd-7413-41b9-94b9-88ae8e9892d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(row):\n",
    "    response_a = row.response_a\n",
    "    response_b = row.response_b\n",
    "\n",
    "    row.response_a = response_b\n",
    "    row.response_b = response_a\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e437110-4972-47ea-9b27-41107c145dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "final.loc[final.winner_tie !=1, 'winner_model_a'] = final.loc[final.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "final.loc[final.winner_tie !=1, 'winner_model_b'] = final.loc[final.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cb9b8-6049-46f7-a1a8-76cb1312fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_json(\"dataset/non_overlap/train_33k_switch_10k_filter_diff.json\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8b787-7d6f-4e86-b24f-64344e536957",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(\"dataset/non_overlap/train_33k_switch_10k_filter_diff.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8faf5-3d9e-4887-b220-acbc78ab8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_json(\"dataset/non_overlap/train_33k_switch_dif_length_13k.json\")\n",
    "data = pd.read_json(\"dataset/non_overlap/train_33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf55f9-7310-4f9d-ad06-0dafe583dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "单个id有超过两条以上的对话，就将都为None的丢掉\n",
    "否则保留\n",
    "'''\n",
    "idx = data.response_b.isna() & data.response_a.isna()#都为none\n",
    "t = data[idx].id.unique()\n",
    "all_none = data.loc[data.id.isin(t)].reset_index(drop = True)\n",
    "count = all_none.id.value_counts().reset_index()\n",
    "drop_id = count.loc[count['count']>1].id.unique()\n",
    "filter_idx = data.id.isin(drop_id) & idx\n",
    "data = data[~filter_idx].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f970b0-fb90-4e27-8539-0eff61d29a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3525e-efb1-4f62-993a-232e01b5ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.id == 3939156539]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0282ad-191c-4e12-95f9-acf3bd965d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/pretrain/korean_arena.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ce708-cee9-4b95-952e-2c6dab800b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (data.winner_model_a == 0) &(data.winner_model_b == 0) & (data.winner_tie == 0)\n",
    "data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e42573-39b7-4dc5-b8ff-0caf6b2862ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_v2 import load_split_data\n",
    "data_path = \"dataset/pretrain/math_2k7_arena.json\"\n",
    "prompt_type = 3\n",
    "MAX_INPUT = 1900\n",
    "if_train = True\n",
    "split = False\n",
    "if_drop_duplicate = True\n",
    "keep = 'last'\n",
    "base_model = 'google/gemma-2-9b-it'\n",
    "model_path = \"output/misunderstood-flower-508/checkpoint-5459_8857\"\n",
    "MAX_LENGTH = MAX_INPUT\n",
    "\n",
    "df_train , df_valid = load_split_data(data_path, prompt_type, MAX_INPUT, if_train, split, False, if_drop_duplicate, 'last', base_model)\n",
    "test = df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
