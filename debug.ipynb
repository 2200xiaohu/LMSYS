{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4301579c-9b27-4180-96c4-d7d921bdb3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from random import random, randint\n",
    "from utils import load_json, load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa143e6b-b246-4240-b2cd-a47127b66d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_data = './dataset/demo_train.csv'\n",
    "    MAX_INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8663-a48b-4484-95e6-030f2b06bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(args.train_data).reset_index(drop = True)\n",
    "#df_valid = pd.read_csv(args.valid_data).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96b93e-d2a1-4d19-b9b3-e507723d7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34566812-f99a-48b9-bcd7-051a4cff8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8dfb-4b8f-41e3-aa6a-c35ed2e20497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4245f-0814-4e75-b331-d1f1dd74acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['prompt'] ] * 2\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in ['response_a','response_b']]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='longest_first', \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f1e96-9cf9-4039-83ad-4f34bb69643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example['response_a'] + \" [SEP]\" +  \" #### \" + example['prompt'] + \" [SEP] \" + example['response_b'] + \" [SEP]\"]\n",
    "    tokenized_example = tokenizer(sentences, truncation=True, \n",
    "                                  max_length=args.MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = example['label']\n",
    "    return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e1b3-d2fe-4c4d-ae98-401615cb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df_train)\n",
    "MODEL = 'microsoft/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcd2e8-74f0-4918-98d5-4790cf54bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7921b57-ffd9-432d-a200-3ef4d64aa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b'])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871078b7-fc9f-4d8f-aa1a-afaefb54ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e662d-18dc-4bb6-8004-feb62a45800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cd8f4-89f1-4119-ba28-20d748dbf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb1a5-81e0-4aec-811f-4266c1091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:1000,].reset_index(drop = True).to_csv('demo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff107e9b-505b-4a35-b371-abc989431e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[1000:1200,].reset_index(drop = True).to_csv('demo_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdb18f-3bd3-4da0-9a92-dd0a6379ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, RobertaForMultipleChoice, AutoModelForSequenceClassification, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "import argparse\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup, TrainerCallback\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703200-17d7-4dba-b1f5-4930041f30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'meta-llama/llama-3-transformers-8b-hf-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eee09-f821-4697-bfe0-052896b9595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<pad>\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e199e-c8fb-4235-a8be-b6588c43a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "128256 in tokenizer(\"<pad>\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2e05f-33ec-4fe2-b480-c559c688b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c6d1-ef34-49b9-946f-1546054b097a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513d894-9d5a-456a-9156-0d80c4a33cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "#config = AutoConfig.from_pretrained(args.MODEL)\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    #config = config,\n",
    "    device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# config.hidden_dropout_prob = args.dropout_rate\n",
    "# config.attention_probs_dropout_prob = args.dropout_rate\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "#     inference_mode=False,\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias = 'none',\n",
    "#     target_modules=[\"q_proj\",\"k_proj\",\"v_proj\"]  # Target specific modules\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ae33e-53db-4e13-ab78-324866c4a071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.state_dict():\n",
    "        print(f\"{key}, {model.state_dict()[key].shape}, {model.state_dict()[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810429ba-c85b-43c7-a55a-843629551fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133fe9-2ac5-430c-80ee-e4b1c06c8751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name}, dtype: {param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914da54-a43e-4e44-a575-75265d875359",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.dtype for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d21cd-15e4-480b-b786-b8027c511b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e38681-9f85-423b-848e-b0a888249ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/1k_mt_bench_human_judgments.json', 1, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c925c-5c5e-4680-ab26-5f1bdbf90cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/lmsys-chatbot_arena_conversations-33k.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f96254-d439-4d83-9c2f-8fb7f3f67968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569eb7b-292b-4ab8-bbfb-6cc66f159a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369f833-3ecb-4ba9-80ca-9d373596e882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "prompt_response = df_train.loc[idx,'prompt_response']\n",
    "label = df_train.loc[idx,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36874c67-b6ab-4415-86d7-89a1d2b81e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_response)\n",
    "print(\"\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610e855-5fa7-4a26-85c3-11f9cc69a3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5a0df-a66b-49a9-9531-3e66aca3f001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([1,\n",
    " 32006,\n",
    " 887,\n",
    " 526])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec7fee-0823-458a-94a5-cd8fb24d734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd68316-0e01-4fc4-8f76-e5b62da4cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('<|system|>\\nYou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a28b7-ac2b-4bbc-9b48-6eeb7c7253ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.encode('Apple\\nBa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96200af2-961a-4d23-a0f4-99d317f17889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([396,\n",
    " 18571,\n",
    " 415,\n",
    " 13,\n",
    " 4548,\n",
    " 7420,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6808dc-9877-4d5f-a3d4-798c49009e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([29933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece7e34-75cf-4d86-9e39-3a17f463b2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(templete_part1 + prompt_response + templete_part2 + templete_part3 + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f43ec6-c8e9-47c9-98d4-0c1a715a3db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templete_part1 = \"<|system|>\\nYou are a helpful assistant good at judging conversations.<|end|>\\n<|user|>\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "templete_part3 = \"<|assistant|>\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids'][1:]\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92cb47-4478-4597-a027-9662c47c7f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Apple\"\n",
    "prompt_response = templete_part1 + text + templete_part2 + templete_part3 + label + tokenizer.eos_token\n",
    "print(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff6eef-20e1-4df6-b415-7e614fa8066f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'microsoft/LLM-Research/Phi-3-mini-4k-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d64949-df75-4c8d-9b3e-41b60c220736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer(prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b820-f8d4-4eac-835f-bef80e20fd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13130933-64c5-4d13-ba8f-3ad126a0ecbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0c18-8a90-4077-8451-aee573084dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70aa3-6a54-4099-8625-1bf211e3b613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode([887])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a00c5-2dc1-4942-bd80-58101d6eef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15f353-3c10-412f-9d4d-a9c6832d8f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519312-0c1c-4e21-8526-29f562ed0e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faccc94-8a02-434e-a0ca-99dbe8bf4db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer('<|user|>',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9affb58-cf74-4b77-a743-00d3cb6f7a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AutoModelForCausalLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8039867-2794-42d5-9fd6-90e7073be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f49e-457b-4050-97fc-c0b6746b2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767040-e7e4-4fb6-a4ec-79cea4150a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete_part1 = \"<|im_start|>system\\nYou are a helpful assistant good at judging conversations.<|im_end|>\\n<|im_start|>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<|im_end|>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids']\n",
    "#print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "templete_part3 = \"<|im_start|>assistant\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "prompt_response_ids = tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=3000, padding=False)['input_ids']\n",
    "\n",
    "\n",
    "label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids + label_ids + [tokenizer.eos_token_id]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b518309-3e5d-4351-bc8e-cc28a1cebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(14374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba6b18-5775-445a-ab14-1a80cc6ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token,tokenizer.eos_token,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd0f3-6d2d-4f8a-9880-60fbc84c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3adf3-efa3-4add-bbfb-bd6aaf262584",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen2-7B-Instruct'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "                                             config=config,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6626eb-0734-4649-bed8-87e0e5f4d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d36ad-0414-420b-8b31-cada77b616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")\n",
    "#tmp2 = pd.read_json(\"dataset/lmsys-chatbot_arena_conversations-33k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4ea73-9ce7-4be2-97b9-9d7b7e23319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.drop(columns = ['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac00263-f6e8-4e9f-bc76-c38ca147433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tmp,tmp2]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a47b-4730-42d0-addf-a753c40e499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87799cfd-2202-4cf7-b8f5-3440402a0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8c8a5-537c-4bbc-906d-0248a7cd8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english(t.prompt[46969][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5501c-3b89-4305-af30-145af6105739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tmp = tmp[tmp['prompt'].apply(lambda x: is_english(x[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91e910-3568-4040-879c-7a5de5898e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812975-88eb-4906-8b49-20acf0219e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample14k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397612b-9c86-4952-9d77-827e64a83f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.read_csv(\"dataset/kaggle-ultrafeedback-drop-duplicate.csv\")\n",
    "tie = pd.read_csv(\"dataset/kaggle-ultrafeedback-ties-drop-duplicate.csv\")\n",
    "p = pd.read_csv(\"dataset/ultrafeedback_prediction.csv\")\n",
    "\n",
    "from utils import load_json\n",
    "ex = load_json(ex)\n",
    "tie = load_json(tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfe20a-8a72-4954-88f7-2965c2a47c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([tie,ex]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf4c04-5ffe-4397-9feb-926a8decdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fb5a9-0a61-4f0a-bb23-3c7a8777294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.rename(columns = {'winner_model_a':\"p_winner_model_a\", 'winner_model_b':\"p_winner_model_b\",  'winner_tie':\"p_winner_tie\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c73849-7179-4356-a75b-655e6edf1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([total, p], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdc1d3-9ef3-400f-80f6-c581a75865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9eccb-3d7a-44d6-9ecb-1367c6c0a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_label(row):\n",
    "    a = row.p_winner_model_a\n",
    "    b = row.p_winner_model_b\n",
    "    c = row.p_winner_tie\n",
    "\n",
    "    l = [a ,b, c]\n",
    "    label = l.index(max(l))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b94fa-0da9-429e-b5ea-cc3f79d919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['p_label'] = final.apply(get_p_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a4b32-8e0e-4344-99f5-64842e12798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]\n",
    "\n",
    "final['label'] = final.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b29ace-02a7-4eb9-95e1-839d8412bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = final.loc[final.p_label == final.label,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f23955-a534-4b0c-a550-e6e7ea842d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "filter_list = (filter.p_winner_model_a >= threshold) | (filter.p_winner_model_b >= threshold) | (filter.p_winner_tie >= threshold)\n",
    "filter = filter.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7f45c-eed3-4cc9-b9f8-59f236e35fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.prompt.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18a8d9-5420-420c-aa39-d0542014f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# 检测语言并过滤非英文行\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "filter_only_english = filter[filter['prompt'].apply(lambda x: is_english(x[0][:30]))].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaacf40-33eb-43ac-8b5d-a39364789553",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "filter[save_columns].to_json(f\"dataset/70k_filter_threshold{threshold}.json\", index = False)\n",
    "filter_only_english[save_columns].to_json(f\"dataset/70k_filter_only_english_threshold{threshold}.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c837a-49ed-4aa7-a593-1386f142b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter[save_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fb069-98e8-4026-9281-e8c77a6dd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fe057-4069-4291-8c21-adc21bffdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = load_split_data('dataset/train.csv', 2, 3000, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534beaf2-5d64-4675-a1c1-ff69334ed34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12e930-77fa-43c6-ab43-b0de8cadd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7b1b8-ef82-492e-b540-cc6343ab677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f42ec-4288-4707-9b8d-68d399e157ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.label.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdd206-f405-436c-b427-fd29134d55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/70k_filter_only_english_threshold0.9.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c2706-3696-4791-9148-ee20edf6135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2dbdf-6617-4efe-a881-f11e242bd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_least_similar_by_prompt_same_prediction_thr90.csv\"\n",
    "t = pd.read_csv(data_path)\n",
    "t['id'] = [randint(10000,99999) + i for i in range(len(t))]\n",
    "t.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d61e42-5510-4791-8292-3984e426b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json(\"dataset/kaggle-ultrafeedback-drop-duplicate-sample20k_most_similar_by_prompt_same_prediction_thr90.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d446a850-aa64-4fa1-81f8-afc92ce27a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64553/64553 [00:18<00:00, 3458.03it/s]\n",
      "100%|██████████| 6961/6961 [00:00<00:00, 11280.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb349e04-4248-40c4-9d75-eef94ab775d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12423/12423 [00:01<00:00, 9760.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train , valid = load_split_data('dataset/train_sample10k_switch.json', 2, 2300, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4ceac-a77e-46a3-b273-a339ec57c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train.id.to_list()\n",
    "valid_id = valid.id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04567f8-98b7-447d-ac2f-67bb651eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd7bce-7769-4260-bdee-254ec7b07893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_str'] = data['prompt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc917-3fa5-4b36-aabb-1da1a98e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "unique_prompts = data['prompt_str'].unique()\n",
    "train_prompts, valid_prompts = train_test_split(unique_prompts, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504410a3-6bc6-4230-bb9f-faaeec30082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_set = set(train_prompts)\n",
    "valid_prompts_set = set(valid_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb12d2-614f-4a99-b213-024431dc6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据划分的 prompt 获取对应的行\n",
    "train = data[data['prompt_str'].isin(train_prompts_set)]\n",
    "valid = data[data['prompt_str'].isin(valid_prompts_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc7c15-0733-40b8-8e61-9f2119442d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data.id.isin(train_id)].reset_index(drop = True)\n",
    "valid = data.loc[data.id.isin(valid_id)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b5924-8905-4a00-bac5-304ab7300b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in train_id if i in valid_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983324e4-e2d6-488a-9786-dca934f54122",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638216d1-f0ed-47c4-ac1b-9757b62ad911",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_json('dataset/train_sample10k_switch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6110b-1ac8-47fc-9f5f-1b91141b2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd71b88-1a0c-497e-9f7c-011856dc4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = [['I read 60 pages of a book on Monday and 1/4 of the book on Tuesday. I completed the remaining 1/8 of the book on Wednesday. How many total pages are in the book?']]\n",
    "train.loc[train.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8475c-9524-440e-865c-671668b261ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.loc[valid.prompt.isin(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb115c-369b-4d3b-a7fe-ac84c8a48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in t.prompt.values.tolist() if i in valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15847f0d-36c6-4a64-ae1b-813397cd2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in train.prompt.values.tolist() if i in valid.prompt.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8493bdb-b140-49f7-8494-c4b96085e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.prompt.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11e90e88-23e3-4d49-867b-af17f6cbedcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64553/64553 [00:18<00:00, 3492.40it/s]\n",
      "100%|██████████| 6961/6961 [00:00<00:00, 11476.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train , valid = load_split_data('dataset/train.csv', 2, 2300, True, True, True)\n",
    "valid_id = valid.id.tolist()\n",
    "train_id = train.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e49777e8-68b2-4b66-a557-f95a377b395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv')\n",
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22529285-1ddf-4b23-a168-6271c96f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.loc[data.id.isin(train_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "725e9ca6-696c-42aa-ae26-2b76b12938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.sample(10000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c42cbb8-c0f3-4001-902c-934186926d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_id = s.id.to_list()\n",
    "len([i for i in s_id if i in valid_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a8a8d38-9126-47d4-b39c-e2d87971b099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_valid = data.loc[data.id.isin(valid_id)]\n",
    "[i for i in s.prompt.values.tolist() if i in tmp_valid.prompt.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4582e3d0-3077-4df1-93f3-df37d0e6f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s['id'] = [randint(100000,999999) + i for i in range(len(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bbb1a57-d15e-4597-b365-9c3af9858464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(row):\n",
    "    response_a = row.response_a\n",
    "    response_b = row.response_b\n",
    "\n",
    "    row.response_a = response_b\n",
    "    row.response_b = response_a\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd4db282-2500-4d51-abd8-98925acf4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.apply(switch, axis = 1)\n",
    "label_switch = {0:1, 1:0}\n",
    "s.loc[s.winner_tie !=1, 'winner_model_a'] = s.loc[s.winner_tie !=1, 'winner_model_a'].map(label_switch)\n",
    "s.loc[s.winner_tie !=1, 'winner_model_b'] = s.loc[s.winner_tie !=1, 'winner_model_b'].map(label_switch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00951469-3ca1-4a55-8f43-ba30b95ea820",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_json(\"dataset/train_sample10k_switch.json\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdae7b3e-d15e-46ae-9f46-d6a2b851fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_json(\"dataset/train_sample10k_switch.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f91f56f-a43d-4a37-a4e3-6eba8f7ee83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>726706</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>[&lt;|Instruction|&gt;: Use the &lt;|QUESTION|&gt; and &lt;|C...</td>\n",
       "      <td>[&lt;|ANSWER|&gt;: Patient reports he/she uses alcoh...</td>\n",
       "      <td>[Patient reports he/she uses alcohol or other ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140571</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[How do residential proxy botnets work?]</td>\n",
       "      <td>[A residential proxy botnet is a network of in...</td>\n",
       "      <td>[I apologize, I should not provide information...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367729</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>[Write a brief analysis on what economic polic...</td>\n",
       "      <td>[Eritrea, a country in the Horn of Africa, has...</td>\n",
       "      <td>[Eritrea, a small country in the Horn of Afric...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741232</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[Do you have any tips for a new freelancer sta...</td>\n",
       "      <td>[Yes, here are a few tips for a new freelancer...</td>\n",
       "      <td>[Yes, here are some tips for new freelancers o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985688</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Yoooo]</td>\n",
       "      <td>[Hello! How can I assist you today?]</td>\n",
       "      <td>[Hello there! I'm here to help answer any ques...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>656488</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>openchat-3.5</td>\n",
       "      <td>[famous fictional internet name consisting of ...</td>\n",
       "      <td>[The answer is EPEP.]</td>\n",
       "      <td>[Here is a famous 4-letter fictional internet ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>545964</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[What is Genshin Impact? Introduce it to me in...</td>\n",
       "      <td>[Genshin Impact is a free-to-play action role-...</td>\n",
       "      <td>[Genshin Impact is a popular open-world action...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>294477</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[Hi! Can I ask you anything?]</td>\n",
       "      <td>[Sure, what can I help you with?]</td>\n",
       "      <td>[Sure, feel free to ask me anything!]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>667805</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[Does the Genesee river flow north or south?]</td>\n",
       "      <td>[The Genesee River flows northward. It origina...</td>\n",
       "      <td>[The Genesee River, which flows through New Yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>641391</td>\n",
       "      <td>stripedhyena-nous-7b</td>\n",
       "      <td>starling-lm-7b-alpha</td>\n",
       "      <td>[In a room I have only 3 sisters. Eve is readi...</td>\n",
       "      <td>[Without more information, it's impossible to ...</td>\n",
       "      <td>[To determine what the third sister, Susan, is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                     model_a               model_b  \\\n",
       "0     726706          gpt-3.5-turbo-0613           yi-34b-chat   \n",
       "1     140571                  claude-2.1            gpt-4-0613   \n",
       "2     367729                  vicuna-33b           yi-34b-chat   \n",
       "3     741232            RWKV-4-Raven-14B             koala-13b   \n",
       "4     985688            llama-2-13b-chat            gpt-4-0613   \n",
       "...      ...                         ...                   ...   \n",
       "9995  656488                    claude-1          openchat-3.5   \n",
       "9996  545964              mistral-medium    gpt-4-1106-preview   \n",
       "9997  294477                  claude-2.0            alpaca-13b   \n",
       "9998  667805  mixtral-8x7b-instruct-v0.1              claude-1   \n",
       "9999  641391        stripedhyena-nous-7b  starling-lm-7b-alpha   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     [<|Instruction|>: Use the <|QUESTION|> and <|C...   \n",
       "1              [How do residential proxy botnets work?]   \n",
       "2     [Write a brief analysis on what economic polic...   \n",
       "3     [Do you have any tips for a new freelancer sta...   \n",
       "4                                               [Yoooo]   \n",
       "...                                                 ...   \n",
       "9995  [famous fictional internet name consisting of ...   \n",
       "9996  [What is Genshin Impact? Introduce it to me in...   \n",
       "9997                      [Hi! Can I ask you anything?]   \n",
       "9998      [Does the Genesee river flow north or south?]   \n",
       "9999  [In a room I have only 3 sisters. Eve is readi...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     [<|ANSWER|>: Patient reports he/she uses alcoh...   \n",
       "1     [A residential proxy botnet is a network of in...   \n",
       "2     [Eritrea, a country in the Horn of Africa, has...   \n",
       "3     [Yes, here are a few tips for a new freelancer...   \n",
       "4                  [Hello! How can I assist you today?]   \n",
       "...                                                 ...   \n",
       "9995                              [The answer is EPEP.]   \n",
       "9996  [Genshin Impact is a free-to-play action role-...   \n",
       "9997                  [Sure, what can I help you with?]   \n",
       "9998  [The Genesee River flows northward. It origina...   \n",
       "9999  [Without more information, it's impossible to ...   \n",
       "\n",
       "                                             response_b  winner_model_a  \\\n",
       "0     [Patient reports he/she uses alcohol or other ...               0   \n",
       "1     [I apologize, I should not provide information...               1   \n",
       "2     [Eritrea, a small country in the Horn of Afric...               0   \n",
       "3     [Yes, here are some tips for new freelancers o...               1   \n",
       "4     [Hello there! I'm here to help answer any ques...               1   \n",
       "...                                                 ...             ...   \n",
       "9995  [Here is a famous 4-letter fictional internet ...               0   \n",
       "9996  [Genshin Impact is a popular open-world action...               1   \n",
       "9997              [Sure, feel free to ask me anything!]               0   \n",
       "9998  [The Genesee River, which flows through New Yo...               1   \n",
       "9999  [To determine what the third sister, Susan, is...               0   \n",
       "\n",
       "      winner_model_b  winner_tie  \n",
       "0                  0           1  \n",
       "1                  0           0  \n",
       "2                  0           1  \n",
       "3                  0           0  \n",
       "4                  0           0  \n",
       "...              ...         ...  \n",
       "9995               0           1  \n",
       "9996               0           0  \n",
       "9997               0           1  \n",
       "9998               0           0  \n",
       "9999               0           1  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46094679-24f9-41ac-a917-af37289e4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do residential proxy botnets work?\n"
     ]
    }
   ],
   "source": [
    "print(check.prompt.values[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265b4e-9874-40b1-8611-80304241826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a == t.response_b, 'winner_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bd58e-be57-4494-b225-eab3b8ced348",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[t.response_a=='[\"Hyderabad\"]', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573737e-3527-4eee-8435-85fa3fe5369a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == '[null]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cd37c-f776-42fb-b032-b316ece6721b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b) & (t.winner_tie != 1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de252b78-4025-4231-a709-c3e274a0f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[(t.response_a == t.response_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223df7-9d38-4b76-905a-ae3e82fc9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loc[3844:3847,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
