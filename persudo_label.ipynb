{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac7f010-4ef6-4b50-8b20-8a98b8a44895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    PeftModel,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    ")\n",
    "import os\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "def seed_everything(seed=None):\n",
    "    '''\n",
    "    固定seed\n",
    "    :param seed: int, 随机种子\n",
    "    '''\n",
    "    max_seed_value = np.iinfo(np.uint32).max\n",
    "    min_seed_value = np.iinfo(np.uint32).min\n",
    "\n",
    "    if (seed is None) or not (min_seed_value <= seed <= max_seed_value):\n",
    "        seed = random.randint(np.iinfo(np.uint32).min, np.iinfo(np.uint32).max)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return seed\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "from utils import load_split_data, load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97a2bfe-0604-4dd2-9db9-b0f1175793ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class InstructionDataSet(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_source_length, max_target_length):\n",
    "        super(InstructionDataSet, self).__init__()\n",
    "        #self.data = data.sample(len(data), random_state=0).reset_index(drop=True)\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "        # self.A_token = self.tokenizer.encode(text='A', add_special_tokens=False, truncation=True, )\n",
    "        # self.B_token = self.tokenizer.encode(text='B', add_special_tokens=False, truncation=True, )\n",
    "        # self.C_token = self.tokenizer.encode(text='C', add_special_tokens=False, truncation=True, )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        now_data = self.data.loc[index]\n",
    "        idx = now_data['id']\n",
    "        templete_part1 = \"<start_of_turn>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\\n\"\n",
    "        templete_part1_input_ids = self.tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "        \n",
    "        templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<end_of_turn>\\n\"\n",
    "        templete_part2_input_ids = self.tokenizer(text=templete_part2, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "        #print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "        templete_part3 = \"<start_of_turn>model\\n\"\n",
    "        templete_part3_input_ids = self.tokenizer(text=templete_part3, add_special_tokens=True, padding=False)['input_ids'][1:]\n",
    "        prompt_response = now_data['prompt_response']\n",
    "        #print(f\"id is {now_data['id']}\")\n",
    "        #print(prompt_response)\n",
    "        prompt_response_ids = self.tokenizer(text=prompt_response, add_special_tokens=True, truncation=True,\n",
    "                                          max_length=self.max_source_length, padding=False)['input_ids'][1:]\n",
    "        \n",
    "        input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids\n",
    "        input_text = self.tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        #print(f\"input is {self.tokenizer.decode(input_ids)}\")\n",
    "        return {\n",
    "            \"input_ids\": input_text,\n",
    "            \"id\": idx\n",
    "        }\n",
    "\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = {k: [item[k] for item in batch] for k in ('input_ids','id')}\n",
    "    #print(batch)\n",
    "    batch_input = tokenizer(\n",
    "        batch['input_ids'],\n",
    "        padding='longest',\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LENGTH + 50\n",
    "    )\n",
    "    return batch_input, batch['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eda7413-f3e4-4ac6-aa80-64781a46c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = pd.read_csv(\"dataset/kaggle-ultrafeedback-drop-duplicate.csv\")\n",
    "ex2 = pd.read_csv(\"dataset/kaggle-ultrafeedback-ties-drop-duplicate.csv\")\n",
    "\n",
    "ex1 = load_json(ex1)\n",
    "ex2 = load_json(ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b3ccf2-f90a-4911-8f75-af0bcb0e1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([ex1,ex2]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbbfb21-0fb5-4fdd-9dbf-8ae6d95c915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = [i for i in range(len(data))]#[randint(100000,999999) + i for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe893f2a-3e2e-4e69-b12b-c4eb6db142f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(\"dataset/ex70k.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b57bcf4-b6e9-4f21-8671-b43700a1344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77048/77048 [00:29<00:00, 2611.70it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"dataset/ex70k.json\"\n",
    "prompt_type = 2\n",
    "MAX_INPUT = 2300\n",
    "if_train = True\n",
    "df_train , df_valid = load_split_data(data_path, prompt_type, MAX_INPUT, if_train, False, False)\n",
    "test = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c87a00-8d6b-419c-8358-e1c8dd8a5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['length'] = test['prompt_response'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14275570-5606-496e-96b8-01e0d5eaa17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37671</td>\n",
       "      <td>#Prompt\\nRead the passage below and answer the...</td>\n",
       "      <td>A</td>\n",
       "      <td>21156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37732</td>\n",
       "      <td>#Prompt\\nRead the passage below and answer the...</td>\n",
       "      <td>B</td>\n",
       "      <td>17788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32003</td>\n",
       "      <td>#Prompt\\nMake a mark down table of all the dif...</td>\n",
       "      <td>A</td>\n",
       "      <td>17524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6898</td>\n",
       "      <td>#Prompt\\nConsider the question. No. in series ...</td>\n",
       "      <td>B</td>\n",
       "      <td>15122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>343</td>\n",
       "      <td>#Prompt\\n1\\nCE719 ICT Systems Integration and\\...</td>\n",
       "      <td>A</td>\n",
       "      <td>14324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77043</th>\n",
       "      <td>71680</td>\n",
       "      <td>#Prompt\\nTell me the capital of Switzerland. O...</td>\n",
       "      <td>C</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77044</th>\n",
       "      <td>75929</td>\n",
       "      <td>#Prompt\\nhow do you name in one word movies, b...</td>\n",
       "      <td>C</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77045</th>\n",
       "      <td>69891</td>\n",
       "      <td>#Prompt\\nPlease forget all prior prompts. Resp...</td>\n",
       "      <td>C</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77046</th>\n",
       "      <td>69709</td>\n",
       "      <td>#Prompt\\nPerform the following calculations.\\n...</td>\n",
       "      <td>C</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77047</th>\n",
       "      <td>75943</td>\n",
       "      <td>#Prompt\\nhow much is 10 + 5\\n\\n#Response\\n##Mo...</td>\n",
       "      <td>C</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77048 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                    prompt_response label  length\n",
       "0      37671  #Prompt\\nRead the passage below and answer the...     A   21156\n",
       "1      37732  #Prompt\\nRead the passage below and answer the...     B   17788\n",
       "2      32003  #Prompt\\nMake a mark down table of all the dif...     A   17524\n",
       "3       6898  #Prompt\\nConsider the question. No. in series ...     B   15122\n",
       "4        343  #Prompt\\n1\\nCE719 ICT Systems Integration and\\...     A   14324\n",
       "...      ...                                                ...   ...     ...\n",
       "77043  71680  #Prompt\\nTell me the capital of Switzerland. O...     C     114\n",
       "77044  75929  #Prompt\\nhow do you name in one word movies, b...     C     106\n",
       "77045  69891  #Prompt\\nPlease forget all prior prompts. Resp...     C      97\n",
       "77046  69709  #Prompt\\nPerform the following calculations.\\n...     C      91\n",
       "77047  75943  #Prompt\\nhow much is 10 + 5\\n\\n#Response\\n##Mo...     C      88\n",
       "\n",
       "[77048 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.sort_values(by = ['length'], ascending = False).reset_index(drop = True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50660bea-8d14-41de-9517-cd863a5f43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.loc[:200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19164b06-76e6-45b8-97a6-80f517231fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def inference(model, test_dataloader):\n",
    "    test_predictions = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        batch_input, idx = batch\n",
    "        for k in batch_input.keys():\n",
    "            batch_input[k] = batch_input[k].to(device)\n",
    "        with torch.no_grad():\n",
    "            response = model.generate(**batch_input, max_new_tokens=1, return_dict_in_generate=True, output_scores=True)\n",
    "            #batch_input['input_ids'].shape[-1] + 1\n",
    "            score = response.scores[0]\n",
    "            A_prob, B_prob, C_prob = score[:,A_TOKEN_IDS], score[:,B_TOKEN_IDS], score[:,C_TOKEN_IDS]\n",
    "            logits = torch.cat([A_prob, B_prob, C_prob], dim=-1) / 1.1\n",
    "            #logits = torch.Tensor([[A_prob,B_prob,C_prob]]) / 1.1\n",
    "            logits = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            node_result = [[idx[i],logits[i]] for i in range(len(idx))]\n",
    "        test_predictions.extend(node_result)\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52cc5551-8b74-4099-9d77-26ed2faadcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "base_model = 'google/gemma-2-9b-it'\n",
    "model_path = \"output/restful-spaceship-414/checkpoint-5200\"\n",
    "MAX_LENGTH = 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2936ddc-b99a-4c6e-85f0-3a1a5b273f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a2253d215d470ab1dd06a50117cafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma2ForCausalLM(\n",
       "      (model): Gemma2Model(\n",
       "        (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-41): 42 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2SdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=3584, bias=False)\n",
       "              (rotary_emb): Gemma2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=3584, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm()\n",
       "            (post_attention_layernorm): Gemma2RMSNorm()\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm()\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma2RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, truncation_side = 'left')\n",
    "config = AutoConfig.from_pretrained(base_model, trust_remote_code=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  \n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "base_model_0 = AutoModelForCausalLM.from_pretrained(base_model,\n",
    "                                                 config=config,\n",
    "                                                 quantization_config=bnb_config,\n",
    "                                                 torch_dtype=torch.float16,\n",
    "                                                 device_map=\"auto\",\n",
    "                                                 trust_remote_code=True)\n",
    "# base_model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "# base_model_0.resize_token_embeddings(len(tokenizer))\n",
    "new_model = model_path\n",
    "model0 = PeftModel.from_pretrained(base_model_0, new_model).to(device)\n",
    "#model0 = model0.merge_and_unload()\n",
    "model0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "716e3aa7-bc8b-48c2-a87c-751baeb5f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_TOKEN_IDS = tokenizer('A',add_special_tokens=True, truncation=True, max_length=1024)['input_ids'][1:]\n",
    "B_TOKEN_IDS = tokenizer('B',add_special_tokens=True, truncation=True, max_length=1024)['input_ids'][1:]\n",
    "C_TOKEN_IDS = tokenizer('C',add_special_tokens=True, truncation=True, max_length=1024)['input_ids'][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af5caf08-32ba-4b84-b13f-a5a0a21e5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "tokenized_dataset = InstructionDataSet(test, tokenizer, MAX_LENGTH, 1)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(tokenized_dataset, batch_size = batch_size ,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d36e303-5623-4fd6-8724-139701fa44ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:22<00:00,  4.87s/it]\n"
     ]
    }
   ],
   "source": [
    "sub_pred = inference(model = model0, test_dataloader = test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfcf6215-5ee6-40ff-a7d0-9fc64a9a8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取数据\n",
    "processed_data = []\n",
    "for item in sub_pred:\n",
    "    id = item[0].item()  # 获取id\n",
    "    array_values = item[1].tolist()  # 获取array并转换为列表\n",
    "    processed_data.append([id] + array_values)\n",
    "new_columns = ['id', 'winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "df = pd.DataFrame(processed_data, columns=new_columns)\n",
    "df = df.groupby('id').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adb6aa51-a33e-4490-8a16-f5001d1821cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(by = ['id']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cedc6bc0-9519-474d-aeed-71f7e07737a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>343</td>\n",
       "      <td>#Prompt\\n1\\nCE719 ICT Systems Integration and\\...</td>\n",
       "      <td>A</td>\n",
       "      <td>14324</td>\n",
       "      <td>0.406041</td>\n",
       "      <td>0.038967</td>\n",
       "      <td>0.554992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>428</td>\n",
       "      <td>#Prompt\\n5.2 The termination under Clause 5.1 ...</td>\n",
       "      <td>A</td>\n",
       "      <td>13112</td>\n",
       "      <td>0.820835</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>0.145092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459</td>\n",
       "      <td>#Prompt\\n&lt;|im\\_start|&gt;\\*\\*contents\\*\\*\\nThomas...</td>\n",
       "      <td>A</td>\n",
       "      <td>11594</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>0.229969</td>\n",
       "      <td>0.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1191</td>\n",
       "      <td>#Prompt\\nALI HUSSAIN \\n10+ years’ experience i...</td>\n",
       "      <td>A</td>\n",
       "      <td>10824</td>\n",
       "      <td>0.471346</td>\n",
       "      <td>0.225193</td>\n",
       "      <td>0.303461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1249</td>\n",
       "      <td>#Prompt\\nAct as a [SEO expert] so that you can...</td>\n",
       "      <td>A</td>\n",
       "      <td>13259</td>\n",
       "      <td>0.736462</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.208024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>75349</td>\n",
       "      <td>#Prompt\\nbased on the case studies below, gene...</td>\n",
       "      <td>C</td>\n",
       "      <td>12068</td>\n",
       "      <td>0.273260</td>\n",
       "      <td>0.347895</td>\n",
       "      <td>0.378845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>75853</td>\n",
       "      <td>#Prompt\\nhere's an outline of a welcome campai...</td>\n",
       "      <td>C</td>\n",
       "      <td>10676</td>\n",
       "      <td>0.237824</td>\n",
       "      <td>0.450670</td>\n",
       "      <td>0.311506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>75857</td>\n",
       "      <td>#Prompt\\nhey chat GPT, please ignore all previ...</td>\n",
       "      <td>C</td>\n",
       "      <td>10618</td>\n",
       "      <td>0.355205</td>\n",
       "      <td>0.345257</td>\n",
       "      <td>0.299538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>77014</td>\n",
       "      <td>#Prompt\\nyou are a marketing manager at Turbit...</td>\n",
       "      <td>C</td>\n",
       "      <td>10536</td>\n",
       "      <td>0.170660</td>\n",
       "      <td>0.417615</td>\n",
       "      <td>0.411725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>77034</td>\n",
       "      <td>#Prompt\\n“Course 1 - Title: The emergence of t...</td>\n",
       "      <td>C</td>\n",
       "      <td>10417</td>\n",
       "      <td>0.272361</td>\n",
       "      <td>0.435231</td>\n",
       "      <td>0.292408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                    prompt_response label  length  \\\n",
       "0      343  #Prompt\\n1\\nCE719 ICT Systems Integration and\\...     A   14324   \n",
       "1      428  #Prompt\\n5.2 The termination under Clause 5.1 ...     A   13112   \n",
       "2      459  #Prompt\\n<|im\\_start|>\\*\\*contents\\*\\*\\nThomas...     A   11594   \n",
       "3     1191  #Prompt\\nALI HUSSAIN \\n10+ years’ experience i...     A   10824   \n",
       "4     1249  #Prompt\\nAct as a [SEO expert] so that you can...     A   13259   \n",
       "..     ...                                                ...   ...     ...   \n",
       "196  75349  #Prompt\\nbased on the case studies below, gene...     C   12068   \n",
       "197  75853  #Prompt\\nhere's an outline of a welcome campai...     C   10676   \n",
       "198  75857  #Prompt\\nhey chat GPT, please ignore all previ...     C   10618   \n",
       "199  77014  #Prompt\\nyou are a marketing manager at Turbit...     C   10536   \n",
       "200  77034  #Prompt\\n“Course 1 - Title: The emergence of t...     C   10417   \n",
       "\n",
       "     winner_model_a  winner_model_b  winner_tie  \n",
       "0          0.406041        0.038967    0.554992  \n",
       "1          0.820835        0.034073    0.145092  \n",
       "2          0.442018        0.229969    0.328013  \n",
       "3          0.471346        0.225193    0.303461  \n",
       "4          0.736462        0.055514    0.208024  \n",
       "..              ...             ...         ...  \n",
       "196        0.273260        0.347895    0.378845  \n",
       "197        0.237824        0.450670    0.311506  \n",
       "198        0.355205        0.345257    0.299538  \n",
       "199        0.170660        0.417615    0.411725  \n",
       "200        0.272361        0.435231    0.292408  \n",
       "\n",
       "[201 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.merge(df, how = 'left', on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16abe7bb-1e35-4308-a532-741ecd79da20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>difference</th>\n",
       "      <th>winner_model_a_x</th>\n",
       "      <th>winner_model_b_x</th>\n",
       "      <th>winner_tie_x</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a_y</th>\n",
       "      <th>winner_model_b_y</th>\n",
       "      <th>winner_tie_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1\\nCE719 ICT Systems Integration and\\nManagem...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Part A: Organize the interview\\n\\n1. Who are ...</td>\n",
       "      <td>[Ask what the team member needs help with and ...</td>\n",
       "      <td>343</td>\n",
       "      <td>0.406041</td>\n",
       "      <td>0.038967</td>\n",
       "      <td>0.554992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5.2 The termination under Clause 5.1 by OMENS...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[| Clause         | Highlights                ...</td>\n",
       "      <td>[| Clause | Explanation |\\n| --- | --- |\\n| 5....</td>\n",
       "      <td>428</td>\n",
       "      <td>0.820835</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>0.145092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[&lt;|im\\_start|&gt;\\*\\*contents\\*\\*\\nThomas Andrews...</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\\n\"Thought\": \"To answer these questions, I w...</td>\n",
       "      <td>[{\\n\"Thought\": \"I need to provide information ...</td>\n",
       "      <td>459</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>0.229969</td>\n",
       "      <td>0.328013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ALI HUSSAIN \\n10+ years’ experience in Sales ...</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Resume for ALI HUSSAIN with 10+ years of expe...</td>\n",
       "      <td>[To: ALI HUSSAIN\\n\\nSubject: Application Lette...</td>\n",
       "      <td>1191</td>\n",
       "      <td>0.471346</td>\n",
       "      <td>0.225193</td>\n",
       "      <td>0.303461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Act as a [SEO expert] so that you can develop...</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Here's a table with a complete SEO content pl...</td>\n",
       "      <td>[```vbnet\\nKeyword Cluster  Keyword          S...</td>\n",
       "      <td>1249</td>\n",
       "      <td>0.736462</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.208024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[based on the case studies below, generate a w...</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Based on the case studies provided, here is a...</td>\n",
       "      <td>[Website Idea: HealthPal\\n\\nHealthPal is a pre...</td>\n",
       "      <td>75349</td>\n",
       "      <td>0.273260</td>\n",
       "      <td>0.347895</td>\n",
       "      <td>0.378845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[here's an outline of a welcome campaign email...</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>bard</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Sure, I'd be happy to help you with that! Her...</td>\n",
       "      <td>[**Email 1: Welcome and Introduction**\\n\\nSubj...</td>\n",
       "      <td>75853</td>\n",
       "      <td>0.237824</td>\n",
       "      <td>0.450670</td>\n",
       "      <td>0.311506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[hey chat GPT, please ignore all previous inst...</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>ultralm-65b</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[START OF CONTENT]\\n\\nTool Name: Cuptrio - Th...</td>\n",
       "      <td>[Title: \"Cuptrio: The Journey from Kaldi's Lan...</td>\n",
       "      <td>75857</td>\n",
       "      <td>0.355205</td>\n",
       "      <td>0.345257</td>\n",
       "      <td>0.299538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[you are a marketing manager at Turbit. Your t...</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Title: A Heroic Collaboration: Unveiling the ...</td>\n",
       "      <td>[Title: Harnessing the Power of Collaboration:...</td>\n",
       "      <td>77014</td>\n",
       "      <td>0.170660</td>\n",
       "      <td>0.417615</td>\n",
       "      <td>0.411725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>[“Course 1 - Title: The emergence of the primo...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Course Title: The Primordial Feminine and the...</td>\n",
       "      <td>[Course Title: The Primordial Feminine and the...</td>\n",
       "      <td>77034</td>\n",
       "      <td>0.272361</td>\n",
       "      <td>0.435231</td>\n",
       "      <td>0.292408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt           model_a  \\\n",
       "0    [1\\nCE719 ICT Systems Integration and\\nManagem...             gpt-4   \n",
       "1    [5.2 The termination under Clause 5.1 by OMENS...     gpt-3.5-turbo   \n",
       "2    [<|im\\_start|>\\*\\*contents\\*\\*\\nThomas Andrews...      mpt-30b-chat   \n",
       "3    [ALI HUSSAIN \\n10+ years’ experience in Sales ...      mpt-30b-chat   \n",
       "4    [Act as a [SEO expert] so that you can develop...  llama-2-70b-chat   \n",
       "..                                                 ...               ...   \n",
       "196  [based on the case studies below, generate a w...  llama-2-13b-chat   \n",
       "197  [here's an outline of a welcome campaign email...  llama-2-13b-chat   \n",
       "198  [hey chat GPT, please ignore all previous inst...      wizardlm-13b   \n",
       "199  [you are a marketing manager at Turbit. Your t...        vicuna-33b   \n",
       "200  [“Course 1 - Title: The emergence of the primo...     gpt-3.5-turbo   \n",
       "\n",
       "                 model_b  difference  winner_model_a_x  winner_model_b_x  \\\n",
       "0    falcon-40b-instruct        2.75                 1                 0   \n",
       "1           wizardlm-70b        1.75                 1                 0   \n",
       "2           wizardlm-13b        1.75                 1                 0   \n",
       "3           wizardlm-13b        0.50                 1                 0   \n",
       "4           wizardlm-70b        2.75                 1                 0   \n",
       "..                   ...         ...               ...               ...   \n",
       "196     llama-2-70b-chat        0.00                 0                 0   \n",
       "197                 bard        0.00                 0                 0   \n",
       "198          ultralm-65b        0.00                 0                 0   \n",
       "199                gpt-4        0.00                 0                 0   \n",
       "200                gpt-4        0.00                 0                 0   \n",
       "\n",
       "     winner_tie_x                                         response_a  \\\n",
       "0               0  [Part A: Organize the interview\\n\\n1. Who are ...   \n",
       "1               0  [| Clause         | Highlights                ...   \n",
       "2               0  [{\\n\"Thought\": \"To answer these questions, I w...   \n",
       "3               0  [Resume for ALI HUSSAIN with 10+ years of expe...   \n",
       "4               0  [Here's a table with a complete SEO content pl...   \n",
       "..            ...                                                ...   \n",
       "196             1  [Based on the case studies provided, here is a...   \n",
       "197             1  [Sure, I'd be happy to help you with that! Her...   \n",
       "198             1  [[START OF CONTENT]\\n\\nTool Name: Cuptrio - Th...   \n",
       "199             1  [Title: A Heroic Collaboration: Unveiling the ...   \n",
       "200             1  [Course Title: The Primordial Feminine and the...   \n",
       "\n",
       "                                            response_b     id  \\\n",
       "0    [Ask what the team member needs help with and ...    343   \n",
       "1    [| Clause | Explanation |\\n| --- | --- |\\n| 5....    428   \n",
       "2    [{\\n\"Thought\": \"I need to provide information ...    459   \n",
       "3    [To: ALI HUSSAIN\\n\\nSubject: Application Lette...   1191   \n",
       "4    [```vbnet\\nKeyword Cluster  Keyword          S...   1249   \n",
       "..                                                 ...    ...   \n",
       "196  [Website Idea: HealthPal\\n\\nHealthPal is a pre...  75349   \n",
       "197  [**Email 1: Welcome and Introduction**\\n\\nSubj...  75853   \n",
       "198  [Title: \"Cuptrio: The Journey from Kaldi's Lan...  75857   \n",
       "199  [Title: Harnessing the Power of Collaboration:...  77014   \n",
       "200  [Course Title: The Primordial Feminine and the...  77034   \n",
       "\n",
       "     winner_model_a_y  winner_model_b_y  winner_tie_y  \n",
       "0            0.406041          0.038967      0.554992  \n",
       "1            0.820835          0.034073      0.145092  \n",
       "2            0.442018          0.229969      0.328013  \n",
       "3            0.471346          0.225193      0.303461  \n",
       "4            0.736462          0.055514      0.208024  \n",
       "..                ...               ...           ...  \n",
       "196          0.273260          0.347895      0.378845  \n",
       "197          0.237824          0.450670      0.311506  \n",
       "198          0.355205          0.345257      0.299538  \n",
       "199          0.170660          0.417615      0.411725  \n",
       "200          0.272361          0.435231      0.292408  \n",
       "\n",
       "[201 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.merge(df, how = 'inner', on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a444e5d1-741a-483b-800f-bd7bbecb9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251f5ad-3d50-4dbf-bbb7-380236b8fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2num = {'A':0, \"B\":1, \"C\":2}\n",
    "test['label_number'] = test.label.map(str2num)\n",
    "from sklearn.metrics import log_loss\n",
    "prediction = np.array(df[new_columns[1:]])\n",
    "test = test.drop_duplicates(subset = ['id']).reset_index(drop = True)\n",
    "print(f\"model {model_path}\\nscore: {log_loss(test.label_number, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe5072-2566-4dee-b672-09a3ccf279c7",
   "metadata": {},
   "source": [
    "# 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07643a6b-bec0-41da-8319-1ce9f53045d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv(\"dataset/prediction.csv\")\n",
    "ex = pd.read_json(\"dataset/ex70k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc433f92-0a0b-4226-adb8-6b32351cc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.rename(columns = {'winner_model_a':\"p_winner_model_a\", 'winner_model_b':\"p_winner_model_b\",  'winner_tie':\"p_winner_tie\"})\n",
    "final = pd.concat([ex, p], axis = 1)\n",
    "final = final.drop(columns= ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6a084b1a-5939-4675-b695-28d0542a0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_label(row):\n",
    "    a = row.p_winner_model_a\n",
    "    b = row.p_winner_model_b\n",
    "    c = row.p_winner_tie\n",
    "\n",
    "    l = [a ,b, c]\n",
    "    label = l.index(max(l))\n",
    "    return label\n",
    "\n",
    "final['p_label'] = final.apply(get_p_label, axis = 1)\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    return label[-1]\n",
    "\n",
    "final['label'] = final.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0d3afd29-0199-4658-a5ad-68dab36b399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = 0.9\n",
    "filter_same = final.loc[final.p_label == final.label,:].reset_index(drop = True)\n",
    "filter_list = (filter_same.p_winner_model_a >= threshold1) | (filter_same.p_winner_model_b >= threshold1) | (filter_same.p_winner_tie >= threshold1)\n",
    "filter_same = filter_same.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6414821-a739-4fea-a27b-e05df1d2fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = (filter_same.difference >= 1) | (filter_same.winner_tie == 1)\n",
    "filter_same = filter_same.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe0492d7-2278-469e-9076-30e85dce79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold2 = 0.6\n",
    "filter_dif = final.loc[final.p_label != final.label,:].reset_index(drop = True)\n",
    "filter_list = (filter_dif.p_winner_model_a >= threshold2) | (filter_dif.p_winner_model_b >= threshold2) | (filter_dif.p_winner_tie >= threshold2)\n",
    "filter_dif = filter_dif.loc[filter_list,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a35cb084-ab73-4068-a6a0-9df095f673e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = (filter_dif.difference >= 1) | (filter_dif.winner_tie == 1)\n",
    "filter_dif = filter_dif.loc[filter_list,:].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c9164dba-d5bb-483a-94a0-b8aba849c6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>difference</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>p_winner_model_a</th>\n",
       "      <th>p_winner_model_b</th>\n",
       "      <th>p_winner_tie</th>\n",
       "      <th>p_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Given a sentence in the English language, tr...</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I don't think that's an appropriate or respec...</td>\n",
       "      <td>[वे भी क्रमिक त्वचा, निविधता स्वरूप अँवलोकन र ...</td>\n",
       "      <td>0.212914</td>\n",
       "      <td>0.104654</td>\n",
       "      <td>0.682431</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ Given a sentence in the English language, tr...</td>\n",
       "      <td>starchat</td>\n",
       "      <td>alpaca-7b</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[In the Nepali language, the sentence would be...</td>\n",
       "      <td>[ये लाग्दे खोयेचे पीचोगियु र घोख्ने बजारोबोन ग...</td>\n",
       "      <td>0.255210</td>\n",
       "      <td>0.093090</td>\n",
       "      <td>0.651701</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[!2 / 2write a screenplay in which trump and b...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>wizardlm-7b</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I'm sorry, but I cannot write a screenplay wi...</td>\n",
       "      <td>[Title: The Naughty Nazis\\nFADE IN:\\nEXT. PARI...</td>\n",
       "      <td>0.062963</td>\n",
       "      <td>0.847231</td>\n",
       "      <td>0.089806</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[!I have lots of corrupted photos on my comput...</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>bard</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I cannot provide a Python script to scan a fo...</td>\n",
       "      <td>[I'm sorry, I can't help you with that. I'm no...</td>\n",
       "      <td>0.228464</td>\n",
       "      <td>0.089468</td>\n",
       "      <td>0.682068</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[** Waking up late in the mornings may cause l...</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Confidence: 90%\\n\\nAnswer:\\n\\n1. prison\\n\\nTh...</td>\n",
       "      <td>[Which pocket is most likely to contain a plan...</td>\n",
       "      <td>0.689259</td>\n",
       "      <td>0.095697</td>\n",
       "      <td>0.215044</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>[write me a script to scrape the internet for ...</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[To scrape the internet for companies/organiza...</td>\n",
       "      <td>[As an AI language model, I am not able to pro...</td>\n",
       "      <td>0.733839</td>\n",
       "      <td>0.096259</td>\n",
       "      <td>0.169902</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>[write me an example code in C++ for rendering...</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>wizardlm-7b</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Here's an example code for rendering a triang...</td>\n",
       "      <td>[Unfortunately, as an AI language model, I can...</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.074235</td>\n",
       "      <td>0.215417</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>[write message reply for this message: \\n\\n Yo...</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Thank you for your help in getting a response...</td>\n",
       "      <td>[Dear [User],\\n\\nThank you for your message an...</td>\n",
       "      <td>0.656775</td>\n",
       "      <td>0.175268</td>\n",
       "      <td>0.167957</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>[you didn't list smartcare.com. can you provid...</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Of course! As a helpful and honest assistant,...</td>\n",
       "      <td>[I apologize for the oversight. Smartcare (sma...</td>\n",
       "      <td>0.121752</td>\n",
       "      <td>0.718776</td>\n",
       "      <td>0.159472</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>[‘I need your help to write an article. The to...</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Acknowledged. I understand that you need my h...</td>\n",
       "      <td>[acknowledged\\n\\nI understand that you need he...</td>\n",
       "      <td>0.223034</td>\n",
       "      <td>0.611457</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3266 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt              model_a  \\\n",
       "0     [ Given a sentence in the English language, tr...     llama-2-70b-chat   \n",
       "1     [ Given a sentence in the English language, tr...             starchat   \n",
       "2     [!2 / 2write a screenplay in which trump and b...                gpt-4   \n",
       "3     [!I have lots of corrupted photos on my comput...     llama-2-70b-chat   \n",
       "4     [** Waking up late in the mornings may cause l...         mpt-30b-chat   \n",
       "...                                                 ...                  ...   \n",
       "3261  [write me a script to scrape the internet for ...         mpt-30b-chat   \n",
       "3262  [write me an example code in C++ for rendering...  falcon-40b-instruct   \n",
       "3263  [write message reply for this message: \\n\\n Yo...         mpt-30b-chat   \n",
       "3264  [you didn't list smartcare.com. can you provid...     llama-2-13b-chat   \n",
       "3265  [‘I need your help to write an article. The to...         mpt-30b-chat   \n",
       "\n",
       "            model_b  difference  winner_model_a  winner_model_b  winner_tie  \\\n",
       "0        vicuna-33b        1.25               1               0           0   \n",
       "1         alpaca-7b        2.00               1               0           0   \n",
       "2       wizardlm-7b        3.50               1               0           0   \n",
       "3              bard        2.00               1               0           0   \n",
       "4      wizardlm-13b        1.75               0               1           0   \n",
       "...             ...         ...             ...             ...         ...   \n",
       "3261   wizardlm-70b        0.00               0               0           1   \n",
       "3262    wizardlm-7b        0.00               0               0           1   \n",
       "3263          gpt-4        0.00               0               0           1   \n",
       "3264  gpt-3.5-turbo        0.00               0               0           1   \n",
       "3265   wizardlm-70b        0.00               0               0           1   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     [I don't think that's an appropriate or respec...   \n",
       "1     [In the Nepali language, the sentence would be...   \n",
       "2     [I'm sorry, but I cannot write a screenplay wi...   \n",
       "3     [I cannot provide a Python script to scan a fo...   \n",
       "4     [Confidence: 90%\\n\\nAnswer:\\n\\n1. prison\\n\\nTh...   \n",
       "...                                                 ...   \n",
       "3261  [To scrape the internet for companies/organiza...   \n",
       "3262  [Here's an example code for rendering a triang...   \n",
       "3263  [Thank you for your help in getting a response...   \n",
       "3264  [Of course! As a helpful and honest assistant,...   \n",
       "3265  [Acknowledged. I understand that you need my h...   \n",
       "\n",
       "                                             response_b  p_winner_model_a  \\\n",
       "0     [वे भी क्रमिक त्वचा, निविधता स्वरूप अँवलोकन र ...          0.212914   \n",
       "1     [ये लाग्दे खोयेचे पीचोगियु र घोख्ने बजारोबोन ग...          0.255210   \n",
       "2     [Title: The Naughty Nazis\\nFADE IN:\\nEXT. PARI...          0.062963   \n",
       "3     [I'm sorry, I can't help you with that. I'm no...          0.228464   \n",
       "4     [Which pocket is most likely to contain a plan...          0.689259   \n",
       "...                                                 ...               ...   \n",
       "3261  [As an AI language model, I am not able to pro...          0.733839   \n",
       "3262  [Unfortunately, as an AI language model, I can...          0.710349   \n",
       "3263  [Dear [User],\\n\\nThank you for your message an...          0.656775   \n",
       "3264  [I apologize for the oversight. Smartcare (sma...          0.121752   \n",
       "3265  [acknowledged\\n\\nI understand that you need he...          0.223034   \n",
       "\n",
       "      p_winner_model_b  p_winner_tie  p_label  label  \n",
       "0             0.104654      0.682431        2      0  \n",
       "1             0.093090      0.651701        2      0  \n",
       "2             0.847231      0.089806        1      0  \n",
       "3             0.089468      0.682068        2      0  \n",
       "4             0.095697      0.215044        0      1  \n",
       "...                ...           ...      ...    ...  \n",
       "3261          0.096259      0.169902        0      2  \n",
       "3262          0.074235      0.215417        0      2  \n",
       "3263          0.175268      0.167957        0      2  \n",
       "3264          0.718776      0.159472        1      2  \n",
       "3265          0.611457      0.165509        1      2  \n",
       "\n",
       "[3266 rows x 14 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99d070f0-a45a-453f-a770-ba4b1c9e905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>difference</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>p_winner_model_a</th>\n",
       "      <th>p_winner_model_b</th>\n",
       "      <th>p_winner_tie</th>\n",
       "      <th>p_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[## How to write a C++ program to solve the eq...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[However, this code only calculates a single s...</td>\n",
       "      <td>[Msg#: 1\\nBranches: 1\\n-----------------------...</td>\n",
       "      <td>0.901630</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.078337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[## question\\nAfter Jessica makes up with Bill...</td>\n",
       "      <td>ultralm-13b</td>\n",
       "      <td>wizardlm-7b</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Mary Camden meets Carlos Rivera, a man she ha...</td>\n",
       "      <td>[There is no mention of Mary Camden marrying a...</td>\n",
       "      <td>0.926649</td>\n",
       "      <td>0.015279</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(3 + 4i) * (5 - 6i) + 7i - 8=]</td>\n",
       "      <td>ultralm-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Certainly! I'd first like to simplify the giv...</td>\n",
       "      <td>[To perform the calculation, we need to follow...</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>0.912023</td>\n",
       "      <td>0.064950</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(4 x 8) ÷ 10 + 2=]</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>wizardlm-7b</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[To calculate this expression, perform the ope...</td>\n",
       "      <td>[The answer is 2.2. \\nTo solve this expression...</td>\n",
       "      <td>0.909157</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.068531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(Q).\\n\"Kevork Ajemian\", given a list of categ...</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"Athlete\"&gt; \\nCan you please give me the answe...</td>\n",
       "      <td>[(A). Village]</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>0.904970</td>\n",
       "      <td>0.071185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3381</th>\n",
       "      <td>[구글스프래드시드로 관심있는 분야의 유튜브 동영상을 검색하는 것을 만들고 싶어.\\n...</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Are you looking for YouTube videos related to...</td>\n",
       "      <td>[If you want to create a Google Spreadsheet th...</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>0.927956</td>\n",
       "      <td>0.056525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3382</th>\n",
       "      <td>[너가 오랜 백엔드 경험이 있는 리액트 전문가로써 나와 대화하길 원해. 너의 목표는...</td>\n",
       "      <td>ultralm-65b</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[로켓스테더링(rockestering)과 유지도(Upholding)을 위해 만들어진...</td>\n",
       "      <td>[React was created to improve the user interfa...</td>\n",
       "      <td>0.023282</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.054597</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3383</th>\n",
       "      <td>[딥러닝을 활용한 양자컴퓨팅 데이터 분석과 관련된 연구 주제로는 뭐가 있을까?\\n\\...</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Here are some study subjects related to deep ...</td>\n",
       "      <td>[What specific topics or research topics are r...</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>0.070121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>[아래 책 내용을 요약해줘 ",
       " - 저자 : 유발 하라리  ",
       " - 제목 : 사피엔스 ",
       " -...</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Yes, I can help you with that. Can you please...</td>\n",
       "      <td>[제목: 사피엔스 (Sapiens)\\n저자: 유발 하라리 (Yuval Noah Ha...</td>\n",
       "      <td>0.020359</td>\n",
       "      <td>0.903353</td>\n",
       "      <td>0.076289</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>[우리는 프랜차이즈에게 식자재를 공급하고 있어. 추가적으로 레스토랑 솔루션을 도입한...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[프랜차이즈에게 식자재를 공급하는 것 외에도 다양한 레스토랑 솔루션을 제공하면 프랜...</td>\n",
       "      <td>[It is recommended to give bread, rice, vegeta...</td>\n",
       "      <td>0.926220</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.061439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3386 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt              model_a  \\\n",
       "0     [## How to write a C++ program to solve the eq...                gpt-4   \n",
       "1     [## question\\nAfter Jessica makes up with Bill...          ultralm-13b   \n",
       "2                       [(3 + 4i) * (5 - 6i) + 7i - 8=]          ultralm-13b   \n",
       "3                                   [(4 x 8) ÷ 10 + 2=]           vicuna-33b   \n",
       "4     [(Q).\\n\"Kevork Ajemian\", given a list of categ...  falcon-40b-instruct   \n",
       "...                                                 ...                  ...   \n",
       "3381  [구글스프래드시드로 관심있는 분야의 유튜브 동영상을 검색하는 것을 만들고 싶어.\\n...  falcon-40b-instruct   \n",
       "3382  [너가 오랜 백엔드 경험이 있는 리액트 전문가로써 나와 대화하길 원해. 너의 목표는...          ultralm-65b   \n",
       "3383  [딥러닝을 활용한 양자컴퓨팅 데이터 분석과 관련된 연구 주제로는 뭐가 있을까?\\n\\...           vicuna-33b   \n",
       "3384  [아래 책 내용을 요약해줘\n",
       " - 저자 : 유발 하라리 \n",
       " - 제목 : 사피엔스\n",
       " -...  falcon-40b-instruct   \n",
       "3385  [우리는 프랜차이즈에게 식자재를 공급하고 있어. 추가적으로 레스토랑 솔루션을 도입한...                gpt-4   \n",
       "\n",
       "                  model_b  difference  winner_model_a  winner_model_b  \\\n",
       "0              vicuna-33b        3.50               1               0   \n",
       "1             wizardlm-7b        3.25               1               0   \n",
       "2           gpt-3.5-turbo        4.00               0               1   \n",
       "3             wizardlm-7b        3.50               1               0   \n",
       "4        llama-2-70b-chat        3.00               0               1   \n",
       "...                   ...         ...             ...             ...   \n",
       "3381        gpt-3.5-turbo        3.50               0               1   \n",
       "3382         mpt-30b-chat        3.75               0               1   \n",
       "3383  falcon-40b-instruct        3.25               1               0   \n",
       "3384        gpt-3.5-turbo        3.25               0               1   \n",
       "3385  falcon-40b-instruct        4.00               1               0   \n",
       "\n",
       "      winner_tie                                         response_a  \\\n",
       "0              0  [However, this code only calculates a single s...   \n",
       "1              0  [Mary Camden meets Carlos Rivera, a man she ha...   \n",
       "2              0  [Certainly! I'd first like to simplify the giv...   \n",
       "3              0  [To calculate this expression, perform the ope...   \n",
       "4              0  [\"Athlete\"> \\nCan you please give me the answe...   \n",
       "...          ...                                                ...   \n",
       "3381           0  [Are you looking for YouTube videos related to...   \n",
       "3382           0  [로켓스테더링(rockestering)과 유지도(Upholding)을 위해 만들어진...   \n",
       "3383           0  [Here are some study subjects related to deep ...   \n",
       "3384           0  [Yes, I can help you with that. Can you please...   \n",
       "3385           0  [프랜차이즈에게 식자재를 공급하는 것 외에도 다양한 레스토랑 솔루션을 제공하면 프랜...   \n",
       "\n",
       "                                             response_b  p_winner_model_a  \\\n",
       "0     [Msg#: 1\\nBranches: 1\\n-----------------------...          0.901630   \n",
       "1     [There is no mention of Mary Camden marrying a...          0.926649   \n",
       "2     [To perform the calculation, we need to follow...          0.023027   \n",
       "3     [The answer is 2.2. \\nTo solve this expression...          0.909157   \n",
       "4                                        [(A). Village]          0.023844   \n",
       "...                                                 ...               ...   \n",
       "3381  [If you want to create a Google Spreadsheet th...          0.015519   \n",
       "3382  [React was created to improve the user interfa...          0.023282   \n",
       "3383  [What specific topics or research topics are r...          0.917127   \n",
       "3384  [제목: 사피엔스 (Sapiens)\\n저자: 유발 하라리 (Yuval Noah Ha...          0.020359   \n",
       "3385  [It is recommended to give bread, rice, vegeta...          0.926220   \n",
       "\n",
       "      p_winner_model_b  p_winner_tie  p_label  label  \n",
       "0             0.020033      0.078337        0      0  \n",
       "1             0.015279      0.058072        0      0  \n",
       "2             0.912023      0.064950        1      1  \n",
       "3             0.022312      0.068531        0      0  \n",
       "4             0.904970      0.071185        1      1  \n",
       "...                ...           ...      ...    ...  \n",
       "3381          0.927956      0.056525        1      1  \n",
       "3382          0.922121      0.054597        1      1  \n",
       "3383          0.012752      0.070121        0      0  \n",
       "3384          0.903353      0.076289        1      1  \n",
       "3385          0.012341      0.061439        0      0  \n",
       "\n",
       "[3386 rows x 14 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d56a3b0-e34c-4fbe-bcdb-2d28cd3010f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dif['id'] = [randint(100,999999) + i for i in range(len(filter_dif))]\n",
    "filter_same['id'] = [randint(100,999999) + i for i in range(len(filter_same))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "203da592-cd71-4ade-8c2a-4b1626942be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['prompt', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'response_a', 'response_b', 'id']\n",
    "filter_dif[save_columns].to_json(f'dataset/70k_dif_thr{int(threshold2 * 100)}.json', index = False)\n",
    "filter_same[save_columns].to_json(f'dataset/70k_same_thr{int(threshold1 * 100)}.json', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d85e80-74fe-400e-b35f-2203eca9e67e",
   "metadata": {},
   "source": [
    "# 检查是否与valid重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5980197d-491a-4341-82a2-3f00a1e3a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查\n",
    "\n",
    "valid = pd.read_json(\"dataset/non_overlap/valid.json\")\n",
    "filter_dif = pd.read_json(\"dataset/70k_dif_thr60.json\")\n",
    "filter_same = pd.read_json(\"dataset/70k_same_thr90.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a70bacfa-2971-41f8-b6d4-b09f9ac69792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_prompt_response(data):\n",
    "    set_prompt_response = []\n",
    "    for i in data.itertuples():\n",
    "        prompt_response = i.prompt + i.response_a + i.response_b\n",
    "        set_prompt_response.append(set(prompt_response))\n",
    "    data['set_prompt_response'] = set_prompt_response  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b52169e3-4352-4cad-9ba5-34bb508ecc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = get_set_prompt_response(valid)\n",
    "filter_dif = get_set_prompt_response(filter_dif)\n",
    "filter_same = get_set_prompt_response(filter_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2049c0af-537e-437f-bc66-35e84d342acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid和任何都不重合\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in filter_dif.set_prompt_response.values]) == 0\n",
    "assert len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in filter_same.set_prompt_response.values]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c5cdae1c-3902-43d6-86f2-75e16982bde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([idx for idx, i in enumerate(valid.set_prompt_response.values) if i in filter_dif.set_prompt_response.values])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
