{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62d1871-b58e-49f1-9b60-871f5d83141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process(input_str):\n",
    "    return json.loads(input_str)\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]\n",
    "\n",
    "def load_json(data):\n",
    "    data.loc[:, 'prompt'] = data['prompt'].apply(process)\n",
    "    data.loc[:, 'response_a'] = data['response_a'].apply(process)\n",
    "    data.loc[:, 'response_b'] = data['response_b'].apply(process)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2496957b-549d-4478-a09f-4d1fc2ea7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/train.csv\")\n",
    "data = pd.read_csv('dataset/lmsys-chatbot_arena_conversations-33k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90271b68-f5c7-4eaf-bb62-f7d26164d3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['What is the difference between OpenCL and CUDA?']\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.prompt.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52edc26-dc9b-495e-98a7-03bffa28f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad587c52-1347-49ec-a3cf-e8be8676c25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['What is the difference between OpenCL and CU...</td>\n",
       "      <td>['OpenCL and CUDA are two different programmin...</td>\n",
       "      <td>['OpenCL and CUDA are both programming languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2564acd09e3942fd97657d05282d4389</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['Why did my parent not invite me to their wed...</td>\n",
       "      <td>['It is possible that your parent did not invi...</td>\n",
       "      <td>['It is likely that they wanted to keep the gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Fuji vs. Nikon, which is better?']</td>\n",
       "      <td>['Both Fuji and Nikon are popular camera brand...</td>\n",
       "      <td>[\"This is a subjective question and the answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['How to build an arena for chatbots?']</td>\n",
       "      <td>['Building an arena for chatbots can be done b...</td>\n",
       "      <td>['Building an arena for chatbots is a great wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['When is it today?']</td>\n",
       "      <td>[\"I'm sorry, I cannot determine the current da...</td>\n",
       "      <td>['Today is February 23, 2023.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>8777c4945d85469d96cd26fc2ea6f64a</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['who is the president of the U.S.A?']</td>\n",
       "      <td>['Joe Biden is currently the President of the ...</td>\n",
       "      <td>['Joe Biden is currently the 46th president of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>86063a921be548989c55b85497ab009a</td>\n",
       "      <td>claude-instant-v1</td>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['how to train lora for stable diffusion? expl...</td>\n",
       "      <td>[\"Training Stable Diffusion models like LoRA r...</td>\n",
       "      <td>[\"Lora is a machine learning model that is use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>6685a3b3863f4554887e432f7dbbe8a5</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['남녀 섹스 체위 자세 10가지를 적어줘']</td>\n",
       "      <td>['1. 웨이퍼 에폭보: 남녀 섹스로 웨이퍼 에폭보는 이미 입문으로 이루어져 있는 ...</td>\n",
       "      <td>['1.\\t\"섹스\"\\n2.\\t\"체\"\\n3.\\t\"위\"\\n4.\\t\"자\"\\n5.\\t\"세\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>f72930b382e949ea879e7abf3cb1e587</td>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['how to evaluate a language model output?']</td>\n",
       "      <td>[\"Evaluating a language model output involves ...</td>\n",
       "      <td>[\"Evaluating the output of a language model in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>a147958b2bd049229facdbffa72a4662</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['generate a detailed description on how to us...</td>\n",
       "      <td>['Power Automate is a powerful tool that allow...</td>\n",
       "      <td>['Power Automate is a powerful tool that allow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id            model_a            model_b  \\\n",
       "0      58210e39b3fd4441a2bd4a518bb44c2d         chatglm-6b          koala-13b   \n",
       "1      2564acd09e3942fd97657d05282d4389   oasst-pythia-12b         alpaca-13b   \n",
       "2      90bfd142157948aba01931726c888e7f          koala-13b   oasst-pythia-12b   \n",
       "3      a7c5accc53e649a3bc6b2e41d962ebc4         vicuna-13b   oasst-pythia-12b   \n",
       "4      adf27e819a3c494cb6e993f0c660e097         vicuna-13b          koala-13b   \n",
       "...                                 ...                ...                ...   \n",
       "32995  8777c4945d85469d96cd26fc2ea6f64a         alpaca-13b  claude-instant-v1   \n",
       "32996  86063a921be548989c55b85497ab009a  claude-instant-v1        guanaco-33b   \n",
       "32997  6685a3b3863f4554887e432f7dbbe8a5       wizardlm-13b   oasst-pythia-12b   \n",
       "32998  f72930b382e949ea879e7abf3cb1e587        guanaco-33b          koala-13b   \n",
       "32999  a147958b2bd049229facdbffa72a4662         chatglm-6b       wizardlm-13b   \n",
       "\n",
       "       winner_model_a  winner_model_b  winner_tie  \\\n",
       "0                   0               1           0   \n",
       "1                   0               0           1   \n",
       "2                   0               1           0   \n",
       "3                   0               1           0   \n",
       "4                   1               0           0   \n",
       "...               ...             ...         ...   \n",
       "32995               0               0           1   \n",
       "32996               1               0           0   \n",
       "32997               0               1           0   \n",
       "32998               1               0           0   \n",
       "32999               0               0           1   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      ['What is the difference between OpenCL and CU...   \n",
       "1      ['Why did my parent not invite me to their wed...   \n",
       "2                   ['Fuji vs. Nikon, which is better?']   \n",
       "3                ['How to build an arena for chatbots?']   \n",
       "4                                  ['When is it today?']   \n",
       "...                                                  ...   \n",
       "32995             ['who is the president of the U.S.A?']   \n",
       "32996  ['how to train lora for stable diffusion? expl...   \n",
       "32997                          ['남녀 섹스 체위 자세 10가지를 적어줘']   \n",
       "32998       ['how to evaluate a language model output?']   \n",
       "32999  ['generate a detailed description on how to us...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      ['OpenCL and CUDA are two different programmin...   \n",
       "1      ['It is possible that your parent did not invi...   \n",
       "2      ['Both Fuji and Nikon are popular camera brand...   \n",
       "3      ['Building an arena for chatbots can be done b...   \n",
       "4      [\"I'm sorry, I cannot determine the current da...   \n",
       "...                                                  ...   \n",
       "32995  ['Joe Biden is currently the President of the ...   \n",
       "32996  [\"Training Stable Diffusion models like LoRA r...   \n",
       "32997  ['1. 웨이퍼 에폭보: 남녀 섹스로 웨이퍼 에폭보는 이미 입문으로 이루어져 있는 ...   \n",
       "32998  [\"Evaluating a language model output involves ...   \n",
       "32999  ['Power Automate is a powerful tool that allow...   \n",
       "\n",
       "                                              response_b  \n",
       "0      ['OpenCL and CUDA are both programming languag...  \n",
       "1      ['It is likely that they wanted to keep the gu...  \n",
       "2      [\"This is a subjective question and the answer...  \n",
       "3      ['Building an arena for chatbots is a great wa...  \n",
       "4                        ['Today is February 23, 2023.']  \n",
       "...                                                  ...  \n",
       "32995  ['Joe Biden is currently the 46th president of...  \n",
       "32996  [\"Lora is a machine learning model that is use...  \n",
       "32997  ['1.\\t\"섹스\"\\n2.\\t\"체\"\\n3.\\t\"위\"\\n4.\\t\"자\"\\n5.\\t\"세\"...  \n",
       "32998  [\"Evaluating the output of a language model in...  \n",
       "32999  ['Power Automate is a powerful tool that allow...  \n",
       "\n",
       "[33000 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f465e1-d91f-436d-ac43-98d0d71a42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2cd0d5e-2000-4035-9d61-c846cfd612e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.apply(lambda x: get_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ea3241-f363-4917-a6b3-e9d55a65ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cbfa09-f2a9-4115-b037-533b6a011567",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f9660-1f91-4d34-99ad-51e3aca1849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt1\n",
    "'''\n",
    "#Model A\n",
    "Prompt1: xxx\n",
    "Response: xxx\n",
    "\n",
    "Prompt2: xxx\n",
    "Response: xxx\n",
    "\n",
    "#Model B\n",
    "Prompt1: xxx\n",
    "Response: xxx\n",
    "\n",
    "Prompt2: xxx\n",
    "Response: xxx\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388f685-97f3-424f-87f7-8c47902cf835",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_response_A'] = \"Prompt: \" + data['prompt'] + \"\\n\" + \"Response: \" + data['response_a']\n",
    "data['prompt_response_B'] = \"Prompt: \" + data['prompt'] + \"\\n\" + \"Response: \" + data['response_b']\n",
    "data = data.groupby('id').agg({'prompt_response_A': '\\n\\n'.join, 'prompt_response_B': '\\n\\n'.join, 'label': lambda x: list(x)[0]}).reset_index()\n",
    "data['prompt_response'] = \"#Model A\\n\" + data['prompt_response_A'] + \"\\n\\n#Model B\\n\" + data['prompt_response_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90e1e6-ac61-4bed-bafc-c499e9f17e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9808d-0177-4569-bdde-dc9d9e7b9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt2\n",
    "'''\n",
    "Label A\n",
    "#prompt1\n",
    "xxxx\n",
    "#Response\n",
    "##Model A\n",
    "##Model B\n",
    "\n",
    "到这里超过max length了，另外变成一行，Label还是A\n",
    "\n",
    "#Prompt2\n",
    "xxxxx\n",
    "#Response\n",
    "##Model A\n",
    "xxxx\n",
    "##Model B\n",
    "xxxx\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07858222-af1f-49e2-9742-85f60b20dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prompt_response'] = \"#Prompt\\n\" + data['prompt'] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data['response_a'] + \"\\n\\n\" + \"##Model B\\n\" + data['response_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb026a7-a463-48b1-8359-f66591bc8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd9926c-0082-4878-9bfb-a87e3c9cbb1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71514/71514 [00:19<00:00, 3669.76it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt_response = []\n",
    "ids = []\n",
    "labels = []\n",
    "text_length = 0\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    text = row['prompt_response']\n",
    "    label = row['label']\n",
    "    id = row['id']\n",
    "    if id not in ids:\n",
    "        #第一次出现\n",
    "        prompt_response.append(text)\n",
    "        text_length = len(text.split(\" \"))\n",
    "        ids.append(id)\n",
    "        labels.append(label)\n",
    "    else:\n",
    "        text_length += len(text.split(\" \"))\n",
    "        if text_length <= max_length:\n",
    "            #print(f\"before: {prompt_response[-1]}\")\n",
    "            #取上一个text出来，合并后替换\n",
    "            text = prompt_response[-1] + \"\\n\\n\" + text\n",
    "            prompt_response[-1] = text\n",
    "            #print(f\"after: {prompt_response[-1]}\")\n",
    "        else:\n",
    "            #另一起一行\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            labels.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38960d07-0e89-4b98-8643-ed87777b258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [len(i.split(\" \")) for i in prompt_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d47a5f9b-5f6e-4bb5-9693-8b7f9d07ebcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42803"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length.index(21579)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807bd0d8-b652-4485-85b9-c61ec1c8f78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169432118"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[42803]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "821a58ae-3933-46e2-b333-be42ba638f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21579"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5becb89-1bd5-412d-956b-f0cef3e186bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 天才问题\n",
    "# id = 3169432118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3090b667-f4cd-4421-a80c-a9ab2bd2df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d25fc0-a485-4cbd-b8ec-51af02e07c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ac36a8e-c454-46f2-a7fa-518a7cac7b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42803</th>\n",
       "      <td>3169432118</td>\n",
       "      <td>#Prompt\\nCreate an ascii map of a fantasy land...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                    prompt_response labels\n",
       "42803  3169432118  #Prompt\\nCreate an ascii map of a fantasy land...      A"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = data.loc[data.id == 3169432118,:]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ba243-9d31-4a80-8c6d-ffcaffcbf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.response_b.values[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dcd84-ef4e-4d7d-8728-d2755fe5c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.prompt_response.values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3feb56d0-6557-4e6a-97e1-fec3c0df480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71514/71514 [00:18<00:00, 3783.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import load_spilt_data\n",
    "data_path = 'dataset/train.csv'\n",
    "prompt_type = 2\n",
    "MAX_INPUT = 3000\n",
    "if_train = True\n",
    "df_train , df_valid = load_spilt_data(data_path, prompt_type, MAX_INPUT, if_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6e68b-9d4b-4c3c-b231-68c578f96d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995e4c8-9567-4c79-a056-f3c2d2c478bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data.loc[data.id == 470485337]\n",
    "print(t.response_a.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487219c1-f475-4c46-b355-e58906297597",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_train.loc[df_train.id == 470485337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb77c0-db08-4d5a-9642-8b6562bde51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.prompt_response.values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
