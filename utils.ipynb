{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f717bef9-e3c0-4ded-b04f-22e8479c22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    RobertaForMultipleChoice,\n",
    "    AutoModelForSequenceClassification,\n",
    "    LlamaModel,\n",
    "    LlamaForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    get_polynomial_decay_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    PeftModel,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate(['winner_model_a','winner_model_b','winner_tie']) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return 'A'\n",
    "    elif label[-1] == 1:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "    return label[-1]\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9545ccc-f70c-4f4b-96bd-de8dd97c0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_subset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccf03ef-1416-45ce-9054-b1dc4669bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate prompt-response\n",
    "data = data.explode(['prompt','response_a','response_b']).reset_index(drop = True)\n",
    "\n",
    "data['label'] = data.apply(lambda x: get_label(x), axis = 1)\n",
    "\n",
    "data = data.fillna('None')\n",
    "data['response_a'] = data['response_a'].apply(lambda x: 'None' if len(x)==0 else x)\n",
    "data['response_b'] = data['response_b'].apply(lambda x: 'None' if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703240ab-2bd9-49d6-b1ed-381ae1d8b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'google/gemma-2-9b-it'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1f3c37b-b913-4ad7-bbc5-27760f3799d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete_part1 = \"<start_of_turn>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\\n\"\n",
    "templete_part1_input_ids = tokenizer(text=templete_part1, add_special_tokens=True, padding=False)['input_ids']\n",
    "\n",
    "templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<end_of_turn>\\n\"\n",
    "templete_part2_input_ids = tokenizer(text=templete_part2, add_special_tokens=False, padding=False)['input_ids']\n",
    "#print(f\"templete_part2 is {templete_part2_input_ids}\")\n",
    "templete_part3 = \"<start_of_turn>model\\n\"\n",
    "templete_part3_input_ids = tokenizer(text=templete_part3, add_special_tokens=False, padding=False)['input_ids']\n",
    "\n",
    "use_in_prompt_1 = tokenizer(text=\"#Prompt\\n\", add_special_tokens=False, padding=False)['input_ids']\n",
    "use_in_prompt_2 = tokenizer(text=\"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\", add_special_tokens=False, padding=False)['input_ids']\n",
    "use_in_prompt_3 = tokenizer(text=\"\\n\\n\" + \"##Model B\\n\", add_special_tokens=False, padding=False)['input_ids']\n",
    "\n",
    "templete_part4_input_ids = tokenizer(text=\"\\n\\n\", add_special_tokens=False, padding=False)['input_ids']\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7ebfb7-da36-456c-95a7-21ae0f72efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(1000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae5266fc-585f-49a0-88ff-a665131216f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row, tokenizer):\n",
    "\n",
    "    now_data = row\n",
    "    response_a = row['response_a']\n",
    "    response_a_input_ids = tokenizer(text=response_a, add_special_tokens=False, padding=False)['input_ids']\n",
    "    row['response_a_input_ids'] = response_a_input_ids\n",
    "    \n",
    "    response_b = row['response_b']\n",
    "    response_b_input_ids = tokenizer(text=response_b, add_special_tokens=False, padding=False)['input_ids']\n",
    "    row['response_b_input_ids'] = response_b_input_ids\n",
    "    \n",
    "    prompt = row['prompt']\n",
    "    prompt_input_ids = tokenizer(text=prompt, add_special_tokens=False, padding=False)['input_ids']\n",
    "    row['prompt_input_ids'] = prompt_input_ids\n",
    "    \n",
    "    label = now_data['label']\n",
    "    label_ids = tokenizer.encode(text=label, add_special_tokens=False)\n",
    "    row['label_ids'] = label_ids\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e465ee-94c2-40e5-9064-75b59be4ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: tokenize(x, tokenizer), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0b0c047-62c0-4051-9e57-40edc52291cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_values(A, B, a_space, b_space, ex_space):\n",
    "    # ËÆ°ÁÆóAÂíåa_spaceÁöÑÂ∑ÆÂÄº\n",
    "    a_diff = a_space - A\n",
    "    b_diff = b_space - B\n",
    "    \n",
    "    # Á¨¨‰∏ÄÁßçÊÉÖÂÜµÔºöAÂ∞è‰∫éa_spaceÔºåBÂ∞è‰∫éb_space\n",
    "    if A < a_space and B < b_space:\n",
    "        ex_space += a_diff + b_diff\n",
    "        return A, B, ex_space\n",
    "\n",
    "    # Á¨¨‰∫åÁßçÊÉÖÂÜµÔºöÂ¶ÇÊûúAÂíåBÈÉΩÂêÑËá™Â§ß‰∫éËá™Â∑±ÁöÑspace\n",
    "    elif A > a_space and B > b_space:\n",
    "        total_extra_needed = (A - a_space) + (B - b_space)\n",
    "        if total_extra_needed > ex_space:\n",
    "            A = int(a_space + ex_space / 2)\n",
    "            B = int(b_space + ex_space / 2)\n",
    "            ex_space = 0\n",
    "        else:\n",
    "            a_space = A\n",
    "            b_space = B\n",
    "            ex_space -= total_extra_needed\n",
    "            \n",
    "        return A, B, ex_space\n",
    "        \n",
    "    # Á¨¨‰∏âÁßçÊÉÖÂÜµÔºöAÊàñËÄÖBÂÖ∂‰∏≠Êúâ‰∏Ä‰∏™Â§ß‰∫éa_space, b_space\n",
    "    elif A >= a_space or B >= b_space:\n",
    "        # Â¶ÇÊûúAÂ§ß‰∫éa_space‰ΩÜÊòØBÂ∞è‰∫éb_space\n",
    "        if A >= a_space and B <= b_space:\n",
    "            extra_needed = A - a_space\n",
    "            ex_space += b_space - B\n",
    "            #Â§üÁî®\n",
    "            if ex_space >= extra_needed:\n",
    "                ex_space -= extra_needed\n",
    "                \n",
    "            else:\n",
    "                #‰∏çÂ§üÁî®\n",
    "                #b_space = B + available_space\n",
    "                A = a_space + ex_space\n",
    "                ex_space = 0\n",
    "\n",
    "        # Â¶ÇÊûúBÂ§ß‰∫éb_space‰ΩÜÊòØAÂ∞è‰∫éa_space\n",
    "        elif B > b_space and A < a_space:\n",
    "            extra_needed = B - b_space\n",
    "            ex_space += a_space - A\n",
    "            \n",
    "            if ex_space >= extra_needed:\n",
    "                ex_space -= extra_needed\n",
    "                \n",
    "            else:\n",
    "                B = b_space + ex_space\n",
    "                ex_space = 0\n",
    "\n",
    "        return A, B, ex_space\n",
    "    \n",
    "\n",
    "def adjust(current_lengths, prompt_length_space=300, response_length_space=800):\n",
    "    prompt_length = current_lengths[0]\n",
    "    response_a_length = current_lengths[1]\n",
    "    response_b_length = current_lengths[2]\n",
    "    #ÂÖàÁúãpromptÁöÑÈ¢ùÂ∫¶\n",
    "    ex_space = max(0, prompt_length_space - prompt_length)\n",
    "    response_a_length, response_b_length, ex_space = adjust_values(response_a_length, response_b_length, response_length_space, response_length_space, ex_space)\n",
    "    prompt_length = min(prompt_length, prompt_length_space)\n",
    "    prompt_length += ex_space\n",
    "\n",
    "    return prompt_length, response_a_length, response_b_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bdca9ea-4263-42d9-b86b-486dd747d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_max_length(prompt_input_ids, model_a_input_ids, model_b_input_ids, max_length):\n",
    "    '''\n",
    "    ÂçïÊù°Ë∂ÖÂá∫max length\n",
    "    '''\n",
    "    length = [len(prompt_input_ids), len(model_a_input_ids), len(model_b_input_ids)]\n",
    "    prompt_length = int(max_length // 5)\n",
    "    response_length = int((max_length - prompt_length) // 2)\n",
    "    prompt_max_length, a_max_length, b_max_length = adjust(length, prompt_length, response_length)\n",
    "    prompt_ids = prompt_input_ids[:prompt_max_length] + templete_part4_input_ids\n",
    "    model_a_input_ids = model_a_input_ids[:a_max_length] + templete_part4_input_ids\n",
    "    model_b_input_ids = model_b_input_ids[:b_max_length] + templete_part4_input_ids\n",
    "    prompt_response_ids = prompt_ids + model_a_input_ids + model_b_input_ids\n",
    "    return prompt_response_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "66796657-13bd-4dc7-9ec8-484d4cbe87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_template(prompt_response_ids):\n",
    "    input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a1dc2-ab29-402b-8218-5fcb939f7c37",
   "metadata": {},
   "source": [
    "# make prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a5a2bfc-cc01-4d85-9fa0-dbd3c54cbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_3(data, max_length, if_train):\n",
    "    data = data.iloc[::-1].reset_index(drop = True)#ÂèçËΩ¨\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    #Âè™Êúâ‰∏ÄÁßçÂèØËÉΩ‰ºöË∂ÖÂá∫max lengthÔºö\n",
    "    #ÂçïÊù°ÁöÑpromptÂíåreponseÂä†Âú®‰∏ÄËµ∑Ë∂ÖÂá∫max length\n",
    "    \n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        # data['prompt_response_ids'] = use_in_prompt_1 + data['prompt_input_ids'] + use_in_prompt_2 + data['response_a_input_ids'] + use_in_prompt_3 + data['response_b_input_ids']\n",
    "        # text = row['prompt_response_ids']\n",
    "        text = use_in_prompt_1 + row['prompt_input_ids'] + use_in_prompt_2 + row['response_a_input_ids'] + use_in_prompt_3 + row['response_b_input_ids']\n",
    "        response_a = row['response_a_input_ids']\n",
    "        response_b = row['response_b_input_ids']\n",
    "        prompt = row['prompt_input_ids']\n",
    "        id = row['id']\n",
    "        \n",
    "        if if_train:\n",
    "            label = row['label_ids']\n",
    "        \n",
    "        if id not in ids:\n",
    "            #Á¨¨‰∏ÄÊ¨°Âá∫Áé∞\n",
    "            text_length = len(text)\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "            if text_length > max_length:\n",
    "                text = over_max_length(prompt_input_ids = prompt, model_a_input_ids = response_a, model_b_input_ids = response_b, max_length = max_length)\\\n",
    "                \n",
    "            text = add_template(text)\n",
    "            prompt_response.append(text)\n",
    "        \n",
    "        else:\n",
    "            text_length += len(text)\n",
    "            if text_length <= max_length:\n",
    "                #Âèñ‰∏ä‰∏Ä‰∏™textÂá∫Êù•ÔºåÂêàÂπ∂ÂêéÊõøÊç¢\n",
    "                text = text + templete_part4_input_ids + prompt_response[-1]\n",
    "                prompt_response[-1] = text\n",
    "                \n",
    "            else:\n",
    "                #Âè¶‰∏ÄËµ∑‰∏ÄË°å\n",
    "                text_length = len(text)\n",
    "                ids.append(id)\n",
    "                \n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "                    \n",
    "                #Âè¶Ëµ∑‰∏ÄË°å‰ΩÜË∂ÖÂá∫ÈïøÂ∫¶\n",
    "                if text_length > max_length:\n",
    "                    text = over_max_length(prompt_input_ids = prompt, model_a_input_ids = response_a, model_b_input_ids = response_b, max_length = max_length)\n",
    "                \n",
    "                text = add_template(text)\n",
    "                prompt_response.append(text)\n",
    "                    \n",
    "                \n",
    "                    \n",
    "    if if_train:           \n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response, \"label\": labels})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#ÂèçËΩ¨\n",
    "    else:\n",
    "        data = pd.DataFrame({'id': ids, 'prompt_response': prompt_response})\n",
    "        data = data.iloc[::-1].reset_index(drop = True)#ÂèçËΩ¨\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0f05e2cd-44d2-4794-b541-672844992cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 8356.32it/s]\n"
     ]
    }
   ],
   "source": [
    "final = prompt_3(data, max_length = 1900, if_train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e4e7ffc7-3779-4cf4-986c-d18d53ae59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['length'] = final['prompt_response'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93d2ce92-006b-415e-a952-03e5d1cc088b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2639720283</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235305]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>685334275</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235280]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1383698196</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235280]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>3837487706</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235280]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>3712274856</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235280]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>2581731284</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>3071276906</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235305]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>4097865015</td>\n",
       "      <td>[2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                    prompt_response     label  \\\n",
       "70   2639720283  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235305]   \n",
       "255   685334275  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235280]   \n",
       "376  1383698196  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235280]   \n",
       "466  3837487706  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235280]   \n",
       "827  3712274856  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235280]   \n",
       "851  2581731284  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235288]   \n",
       "858  3071276906  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235305]   \n",
       "976  4097865015  [2, 106, 1645, 108, 4858, 708, 1378, 2872, 235...  [235288]   \n",
       "\n",
       "     length  \n",
       "70     1953  \n",
       "255    1953  \n",
       "376    1953  \n",
       "466    1953  \n",
       "827    1953  \n",
       "851    1953  \n",
       "858    1953  \n",
       "976    1953  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = final['length'] == final['length'].max()\n",
    "final.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f5146e95-2b48-42d1-84e9-805f0fd4e947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "Here are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\n",
      "\n",
      "#Prompt\n",
      "What is discursive reasoning\n",
      "\n",
      "#Response\n",
      "##Model A\n",
      "Discursive reasoning is a type of reasoning that involves making arguments and defending them using logical reasoning. It involves constructing a series of statements or claims that can be challenged and supported by evidence. Discursive reasoning is often used in debates and discussions, and is a key part of critical thinking.\n",
      "\n",
      "##Model B\n",
      "Hello! I'm here to help answer your questions safely and helpfully. Discursive reasoning is a type of thinking and reasoning that involves evaluating and analyzing information, arguments, and beliefs in a systematic and logical way. It involves considering multiple perspectives, weighing evidence, and making connections between ideas.\n",
      "\n",
      "Discursive reasoning is an important skill for critical thinking, problem-solving, and effective communication. It can help you to make informed decisions, evaluate the validity of information, and understand complex issues from multiple angles.\n",
      "\n",
      "If you have any more questions or would like to know more about discursive reasoning, please don't hesitate to ask!\n",
      "###options\n",
      "A. Model A\n",
      "B. Model B\n",
      "C. Tie\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(final.prompt_response.values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ef9fe7-d8bc-47b0-8b21-4521e1e25063",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc = 'pandas bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538feeb4-06b4-4046-8e70-8056adbdcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df467948-9661-48d7-9508-d59768465bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas bar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55745/55745 [02:56<00:00, 315.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55745/55745 [00:19<00:00, 2818.03it/s]\n"
     ]
    }
   ],
   "source": [
    "tmp_train , _ = load_split_data(\"dataset/non_overlap/train_subset.json\", 3, 1900, True, False, False, False, 'last', 'google/gemma-2-9b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de766f88-fc6e-4908-9af7-c8924aa8471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train['length'] = tmp_train['prompt_response'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1678bab6-a168-4bf2-ad3e-788ad5617c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3254113</td>\n",
       "      <td>[235345, 55440, 108, 3611, 692, 1707, 3104, 48...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>35088788</td>\n",
       "      <td>[235345, 55440, 108, 24926, 5598, 476, 4866, 1...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>37697874</td>\n",
       "      <td>[235345, 55440, 108, 11071, 235292, 1646, 708,...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>43053669</td>\n",
       "      <td>[235345, 55440, 108, 156910, 889, 736, 5078, 2...</td>\n",
       "      <td>[235280]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>48531611</td>\n",
       "      <td>[235345, 55440, 108, 108, 235345, 1915, 664, 1...</td>\n",
       "      <td>[235305]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46553</th>\n",
       "      <td>4280501571</td>\n",
       "      <td>[235345, 55440, 108, 1638, 608, 7588, 8293, 61...</td>\n",
       "      <td>[235305]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46570</th>\n",
       "      <td>4281980776</td>\n",
       "      <td>[235345, 55440, 108, 90822, 573, 2412, 3409, 2...</td>\n",
       "      <td>[235280]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46637</th>\n",
       "      <td>4289338231</td>\n",
       "      <td>[235345, 55440, 108, 49688, 573, 2412, 2793, 7...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46648</th>\n",
       "      <td>4290839285</td>\n",
       "      <td>[235345, 55440, 108, 19584, 145739, 26399, 235...</td>\n",
       "      <td>[235305]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46681</th>\n",
       "      <td>4293704939</td>\n",
       "      <td>[235345, 55440, 108, 20700, 6555, 235260, 577,...</td>\n",
       "      <td>[235305]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                    prompt_response  \\\n",
       "39        3254113  [235345, 55440, 108, 3611, 692, 1707, 3104, 48...   \n",
       "416      35088788  [235345, 55440, 108, 24926, 5598, 476, 4866, 1...   \n",
       "447      37697874  [235345, 55440, 108, 11071, 235292, 1646, 708,...   \n",
       "497      43053669  [235345, 55440, 108, 156910, 889, 736, 5078, 2...   \n",
       "554      48531611  [235345, 55440, 108, 108, 235345, 1915, 664, 1...   \n",
       "...           ...                                                ...   \n",
       "46553  4280501571  [235345, 55440, 108, 1638, 608, 7588, 8293, 61...   \n",
       "46570  4281980776  [235345, 55440, 108, 90822, 573, 2412, 3409, 2...   \n",
       "46637  4289338231  [235345, 55440, 108, 49688, 573, 2412, 2793, 7...   \n",
       "46648  4290839285  [235345, 55440, 108, 19584, 145739, 26399, 235...   \n",
       "46681  4293704939  [235345, 55440, 108, 20700, 6555, 235260, 577,...   \n",
       "\n",
       "          label  length  \n",
       "39     [235288]    1916  \n",
       "416    [235288]    1916  \n",
       "447    [235288]    1916  \n",
       "497    [235280]    1916  \n",
       "554    [235305]    1916  \n",
       "...         ...     ...  \n",
       "46553  [235305]    1916  \n",
       "46570  [235280]    1916  \n",
       "46637  [235288]    1916  \n",
       "46648  [235305]    1916  \n",
       "46681  [235305]    1916  \n",
       "\n",
       "[706 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = tmp_train['length'] == tmp_train['length'].max()\n",
    "tmp_train.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8d7b7c-ca3b-4864-9dde-e28e6ed74d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"dataset/non_overlap/train_subset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b33f8614-8c8f-40b3-ac40-c8086019e811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please make it shorter, reddit style reply'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['id'] == 35088788].prompt.values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8262f96b-c552-43d0-8d83-cc701024b20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>35088788</td>\n",
       "      <td>[235345, 55440, 108, 24926, 5598, 476, 4866, 1...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>35088788</td>\n",
       "      <td>[235345, 55440, 108, 24926, 1501, 665, 25270, ...</td>\n",
       "      <td>[235288]</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                    prompt_response     label  \\\n",
       "416  35088788  [235345, 55440, 108, 24926, 5598, 476, 4866, 1...  [235288]   \n",
       "417  35088788  [235345, 55440, 108, 24926, 1501, 665, 25270, ...  [235288]   \n",
       "\n",
       "     length  \n",
       "416    1916  \n",
       "417     380  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train[tmp_train['id'] == 35088788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9185935-68f5-47b0-9581-6eefa795875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_train.prompt_response.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d10d30-abe2-4549-aa91-a077edff5129",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'google/gemma-2-9b-it'\n",
    "config = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True, truncation_side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8a13e3-6273-48b9-92ea-375e293cca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Prompt\n",
      "please make it shorter, reddit style reply\n",
      "\n",
      "#Response\n",
      "##Model A\n",
      "Hey [username], I feel the same way as you regarding XMR and BCH. While getting delisted can be tough, it could also spur innovation. Excited to see what new ideas emerge! And I couldn't agree more about XMR's focus on privacy aligning with the Cypherpunk's Manifesto. As someone who values privacy, I'm glad XMR is becoming less of a speculator's game. I'm also selling stuff on Monero Market now! [Insert link] Let's work together towards a future where privacy is a right, not a luxury. üôåüîíüîë #XMR #Cypherpunks #PrivacyMatters #AnonymityRocks\n",
      "\n",
      "P.S. If you're interested in buying any of my items on Monero Market, check them out! [Insert link]\n",
      "\n",
      "##Model B\n",
      "Hey!\n",
      "\n",
      "Totally vibing with your take on XMR's situation! Watching Bitcoin's journey had me worried too, especially seeing how the quick-buck mindset overshadowed the real essence of crypto. It's refreshing to see someone else who values privacy and the core principles laid out in \"A Cypherpunk's Manifesto.\"\n",
      "\n",
      "Your optimism about Monero facing challenges head-on and sparking innovation is contagious. It's a solid reminder that sometimes, being cornered is what drives us to break new ground. And honestly, your excitement has nudged me to finally dive into Monero, starting by selling my collection on MoneroMarket. It feels like we're getting back to what crypto was supposed to be about ‚Äì not speculation, but privacy and empowerment.\n",
      "\n",
      "Thanks for the inspiration! Let's see what amazing solutions this situation brings. Onward to a more private and decentralized future!\n",
      "\n",
      "Cheers!\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tmp_train.prompt_response.values[417]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
